# å¿«é€Ÿæµ‹è¯•é…ç½® - è§£å†³æä½å­¦ä¹ ç‡å¯¼è‡´çš„æ”¶æ•›é—®é¢˜
# ä½œè€…ï¼šAIç®—æ³•å›¢é˜Ÿ
# æ—¥æœŸï¼š2025-08-25
# ç›®çš„ï¼šå¿«é€ŸéªŒè¯ç½‘ç»œèƒ½å¦æ­£ç¡®å­¦ä¹ æ˜ å°„

# ç½‘ç»œé…ç½®
network:
  input_channels: 7
  output_channels: 3
  patch_size: 128
  base_channels: 16
  use_attention: true
  use_boundary_aware: true

# æ•°æ®é…ç½®
data:
  data_root: "./output_motion_fix"
  batch_size: 2                     # å°æ‰¹æ¬¡å¿«é€Ÿæµ‹è¯•
  num_workers: 0
  
  # å¿«é€Ÿæµ‹è¯•è®¾ç½®
  max_epochs: 20                    # å°‘é‡epochå¿«é€Ÿæµ‹è¯•
  learning_rate: 0.001              # ğŸ”§ é«˜å­¦ä¹ ç‡å¿«é€Ÿæ”¶æ•›æµ‹è¯•
  weight_decay: 0.0001

# ä¼˜åŒ–å™¨é…ç½® - å¿«é€Ÿæ”¶æ•›
optimizer:
  type: "adam"
  lr: 0.001                         # é«˜å­¦ä¹ ç‡
  weight_decay: 0.0001
  betas: [0.9, 0.999]
  eps: 0.00000001

# è®­ç»ƒå™¨é…ç½® - å¿«é€Ÿæµ‹è¯•
trainer:
  accumulate_grad_batches: 1        # ä¸ç´¯ç§¯ï¼Œç›´æ¥æ›´æ–°
  precision: 32
  gradient_clip_val: 2.0            # æ”¾å®½æ¢¯åº¦è£å‰ª
  
  # é¢‘ç¹æ£€æŸ¥è¿›å±•
  val_check_interval: 0.5           # æ¯åŠä¸ªepochæ£€æŸ¥
  check_val_every_n_epoch: 1        # æ¯ä¸ªepochéªŒè¯
  
  # å¿«é€Ÿcheckpoint
  save_every_n_epochs: 5
  save_top_k: 3

# æŸå¤±é…ç½®
loss:
  lambda_l1: 1.0
  lambda_perceptual: 0.1
  lambda_edge: 0.1
  lambda_boundary: 0.2

# å­¦ä¹ ç‡è°ƒåº¦å™¨ - å¿«é€Ÿæ”¶æ•›æµ‹è¯•
scheduler:
  type: "cosine"
  max_epochs: 20
  eta_min: 0.00001
  warmup_epochs: 2

# å¯è§†åŒ–é…ç½® - å¯†é›†ç›‘æ§
visualization:
  log_every_n_steps: 10             # æ¯10æ­¥è®°å½•
  save_images: true
  save_predictions: true
  
# æ—©åœé…ç½® - å¿«é€ŸéªŒè¯
early_stopping:
  monitor: "val_loss"
  patience: 5
  mode: "min"
  
# æµ‹è¯•è¯´æ˜
description: |
  å¿«é€Ÿæµ‹è¯•é…ç½®ç”¨äºéªŒè¯ç½‘ç»œå­¦ä¹ èƒ½åŠ›
  - é«˜å­¦ä¹ ç‡(1e-3)å¿«é€Ÿæ”¶æ•›æµ‹è¯•
  - å°æ‰¹æ¬¡å’ŒçŸ­epochå¿«é€Ÿåé¦ˆ
  - å¯†é›†çš„ç›‘æ§å’Œå¯è§†åŒ–
  - ç›®æ ‡ï¼šåœ¨5-10ä¸ªepochå†…çœ‹åˆ°æ˜æ˜¾çš„é¢„æµ‹æ”¹å–„