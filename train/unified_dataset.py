#!/usr/bin/env python3
"""
Unified dataset loader for 10-channel preprocessed NoiseBase data.
Loads training_data generated by preprocessing scripts.
"""

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
import numpy as np
from pathlib import Path
from typing import Tuple, List
import random


class UnifiedNoiseBaseDataset(Dataset):
    """
    Unified dataset for preprocessed 10-channel NoiseBase data.
    
    Data format [10, H, W]:
    - [0:3]   warped_image (forward projected with holes)
    - [3:4]   semantic_holes (non-geometric hole mask)
    - [4:5]   occlusion (dynamic occlusion areas)
    - [5:7]   residual_mv (motion prediction error vectors)
    - [7:10]  target_rgb (ground truth RGB)
    
    Advantages: Single I/O, minimal memory allocation, optimized caching
    """
    
    def __init__(self,
                 data_root: str,
                 split: str = 'train',
                 augmentation: bool = False):
        """Initialize unified dataset.
        
        Args:
            data_root: Data root directory
            split: Data split ('train', 'val', 'test')
            augmentation: Whether to use data augmentation (currently disabled)
        """
        self.data_root = Path(data_root)
        self.split = split
        self.augmentation = augmentation
        
        # Check training_data directory
        self.training_data_dir = self.data_root / 'training_data'
        
        if not self.training_data_dir.exists():
            raise FileNotFoundError(f"Training data directory not found: {self.training_data_dir}")
        
        # Split data
        self.frame_names = self._split_data()
        
        print(f"=== Unified NoiseBase Dataset ({split}) ===")
        print(f"Data root: {data_root}")
        print(f"Training data directory: {self.training_data_dir}")
        print(f"Frame samples: {len(self.frame_names)}")
        
        # Validate data integrity
        self._validate_data()
    
    def _split_data(self) -> List[str]:
        """数据分割"""
        # 扫描training_data目录获取所有.npy文件
        training_files = list(self.training_data_dir.glob('*.npy'))
        all_frames = [f.stem for f in training_files]
        
        # 按文件名排序确保一致性
        all_frames.sort()
        
        if len(all_frames) == 0:
            raise FileNotFoundError(f"在 {self.training_data_dir} 中未找到训练数据文件")
        
        # 数据分割 (80% train, 10% val, 10% test)
        total_frames = len(all_frames)
        train_end = int(0.8 * total_frames)
        val_end = int(0.9 * total_frames)
        
        if self.split == 'train':
            return all_frames[:train_end]
        elif self.split == 'val':
            return all_frames[train_end:val_end]
        elif self.split == 'test':
            return all_frames[val_end:]
        else:
            raise ValueError(f"Unsupported split: {self.split}")
    
    def _validate_data(self):
        """验证数据完整性"""
        # 检查前几个样本的数据格式
        for i, frame_name in enumerate(self.frame_names[:3]):
            try:
                data_path = self.training_data_dir / f'{frame_name}.npy'
                data = np.load(data_path)
                
                expected_shape = (10, None, None)  # [10, H, W]
                if data.ndim != 3 or data.shape[0] != 10:
                    print(f"警告: {frame_name} 数据形状异常: {data.shape}, 期望: [10, H, W]")
                    return False
                
                if i == 0:
                    H, W = data.shape[1], data.shape[2]
                    print(f"数据验证: 形状=[10, {H}, {W}], 范围=[{data.min():.3f}, {data.max():.3f}]")
                    
            except Exception as e:
                print(f"警告: 无法加载 {frame_name}: {e}")
                return False
        
        print("SUCCESS: Data format validation passed")
        return True
    
    def __len__(self) -> int:
        return len(self.frame_names)
    
    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        获取数据样本
        
        Returns:
            input_tensor: 7通道输入 [7, H, W] (warped_RGB + holes + occlusion + residual_mv)
            target_tensor: 3通道目标 [3, H, W] (target_RGB)
        """
        frame_name = self.frame_names[idx]
        data_path = self.training_data_dir / f'{frame_name}.npy'
        
        try:
            # 加载10通道数据（1次I/O）
            full_data = np.load(data_path)  # [10, H, W]
            
            # 分离输入和目标
            input_data = full_data[:7]      # [7, H, W] - 输入数据
            target_data = full_data[7:10]   # [3, H, W] - 目标RGB
            
            # 转换为PyTorch张量
            input_tensor = torch.from_numpy(input_data).float()    # [7, H, W]
            target_tensor = torch.from_numpy(target_data).float()  # [3, H, W]
            
            # 数据归一化: HDR -> [-1, 1] (匹配网络Tanh输出)
            input_tensor = self._normalize_to_tanh_range(input_tensor)
            target_tensor = self._normalize_to_tanh_range(target_tensor)
            
            return input_tensor, target_tensor
            
        except Exception as e:
            print(f"错误加载数据 {frame_name}: {e}")
            # 返回零张量作为fallback
            return torch.zeros(7, 270, 480), torch.zeros(3, 270, 480)
    
    def _normalize_to_tanh_range(self, tensor: torch.Tensor) -> torch.Tensor:
        """
        归一化到Tanh范围 [-1, 1]
        
        修复颜色映射混乱问题：
        - 使用固定的全局归一化参数，避免per-image的分位数归一化导致颜色映射不一致
        - HDR数据简单clamp到合理范围，然后线性映射
        """
        normalized = tensor.clone()
        
        # RGB通道处理（前3通道或全部通道）
        if tensor.shape[0] >= 3:
            rgb_channels = tensor[:3] if tensor.shape[0] > 3 else tensor
            
            # FIX: Use log1p nonlinear normalization to improve HDR data distribution
            # 原始数据分析：范围[0, 154.156]，75%分位数仅1.65-4.60
            # 线性归一化导致大部分数据压缩到[-1, -0.93]极小区间
            # log1p(x)能压缩高值，保持低值区分度，改善网络学习
            
            # Step 1: log1p变换 - 改善数据分布
            rgb_log_transformed = torch.log1p(rgb_channels)  # log(1+x)
            
            # Step 2: 确定log变换后的范围
            log_min_val = 0.0                    # log1p(0) = 0
            log_max_val = 5.023574285781275      # log1p(151.0) = log(152.0) ≈ 5.024
            
            # Step 3: clamp并映射到[-1,1]
            rgb_clamped_log = torch.clamp(rgb_log_transformed, log_min_val, log_max_val)
            rgb_normalized_log = (rgb_clamped_log - log_min_val) / (log_max_val - log_min_val)  # [0, 1]
            rgb_normalized_log = rgb_normalized_log * 2.0 - 1.0  # [-1, 1]
            
            rgb_normalized = rgb_normalized_log
            
            if tensor.shape[0] > 3:
                normalized[:3] = rgb_normalized
            else:
                normalized = rgb_normalized
        
        # 掩码通道处理（第4-5通道）
        # FIX: Masks should remain in [0,1] range, not converted to [-1,1]
        if tensor.shape[0] >= 5:
            for i in range(3, 5):
                mask = tensor[i]
                mask = torch.clamp(mask, 0.0, 1.0)  # 确保掩码在[0,1]范围
                normalized[i] = mask  # 保持[0,1]范围，不进行[-1,1]转换
        
        # 运动矢量通道处理（第6-7通道）
        if tensor.shape[0] >= 7:
            mv_channels = tensor[5:7]
            
            # 使用分位数方法，更稳定
            mv_abs_max = torch.quantile(torch.abs(mv_channels), 0.95)  # 95%分位数
            
            if mv_abs_max > 1e-6:
                # 归一化到[-1, 1]范围
                normalized[5:7] = torch.clamp(mv_channels / mv_abs_max, -1.0, 1.0)
            else:
                # 如果运动很小，保持原值
                normalized[5:7] = mv_channels
        
        return normalized
    
    def denormalize_for_display(self, normalized_tensor: torch.Tensor) -> torch.Tensor:
        """
        反归一化用于TensorBoard显示
        与 _normalize_to_tanh_range 保持严格一致
        
        Args:
            normalized_tensor: [-1, 1] 范围的归一化张量
            
        Returns:
            display_tensor: [0, 1] 范围的LDR张量，适合TensorBoard显示
        """
        
        # 只处理RGB通道（前3通道）
        if normalized_tensor.shape[0] >= 3:
            rgb_normalized = normalized_tensor[:3] if normalized_tensor.shape[0] > 3 else normalized_tensor
            
            # FIX: Denormalization: strictly corresponding to the inverse process of log1p normalization
            # Step 1: [-1, 1] -> [0, 1]
            rgb_01 = (rgb_normalized + 1.0) / 2.0
            
            # Step 2: [0, 1] -> log空间 [0, 5.024]
            log_min_val = 0.0
            log_max_val = 5.023574285781275  # 与归一化参数保持严格一致
            log_values = rgb_01 * (log_max_val - log_min_val) + log_min_val
            
            # Step 3: log空间 -> HDR空间 (使用expm1作为log1p的逆运算)
            hdr_rgb = torch.expm1(log_values)  # expm1(x) = exp(x) - 1
            
            # Step 4: HDR -> LDR tone mapping 用于显示
            # 使用Reinhard tone mapping
            ldr_rgb = hdr_rgb / (1.0 + hdr_rgb)
            
            # 确保在[0, 1]范围内
            display_rgb = torch.clamp(ldr_rgb, 0.0, 1.0)
            
            return display_rgb
        else:
            # 非RGB通道直接简单变换
            return torch.clamp((normalized_tensor + 1.0) / 2.0, 0.0, 1.0)


def create_unified_dataloader(data_root: str,
                            split: str = 'train',
                            batch_size: int = 1,
                            num_workers: int = 0,
                            shuffle: bool = True) -> DataLoader:
    """
    创建统一数据集的DataLoader
    
    Args:
        data_root: 数据根目录 (output_motion_fix)
        split: 数据分割
        batch_size: 批次大小  
        num_workers: 工作线程数（推荐0以减少内存占用）
        shuffle: 是否打乱数据
    """
    dataset = UnifiedNoiseBaseDataset(
        data_root=data_root,
        split=split,
        augmentation=False  # 暂时禁用数据增强
    )
    
    dataloader = DataLoader(
        dataset,
        batch_size=batch_size,
        shuffle=shuffle,
        num_workers=num_workers,
        pin_memory=True if torch.cuda.is_available() else False,
        persistent_workers=False,  # 减少内存占用
        prefetch_factor=1 if num_workers > 0 else None  # 减少预取缓冲
    )
    
    return dataloader


if __name__ == "__main__":
    # 测试统一数据集
    print("测试统一数据集...")
    
    try:
        dataset = UnifiedNoiseBaseDataset(
            data_root="./output_motion_fix",
            split='train'
        )
        
        print(f"数据集大小: {len(dataset)}")
        
        # 测试加载第一个样本
        input_tensor, target_tensor = dataset[0]
        print(f"输入形状: {input_tensor.shape}")
        print(f"目标形状: {target_tensor.shape}")
        print(f"输入范围: [{input_tensor.min():.3f}, {input_tensor.max():.3f}]")
        print(f"目标范围: [{target_tensor.min():.3f}, {target_tensor.max():.3f}]")
        
        print("SUCCESS: Unified dataset test passed!")
        
    except Exception as e:
        print(f"ERROR: Unified dataset test failed: {e}")
        print("请确保预处理脚本已经运行并生成了training_data目录")