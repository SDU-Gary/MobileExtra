#!/usr/bin/env python3
"""
Patch-based training framework for PyTorch Lightning.

Features:
- Patch-aware training loops with boundary handling
- Multi-scale loss computation
- Adaptive performance optimization  
- Integrated visualization system
- Progressive training strategies

Compatible with existing FrameInterpolationTrainer architecture.
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
import pytorch_lightning as pl
import torch.nn.functional as F
import numpy as np
from typing import Dict, Any, Optional, Tuple, List, Union
import logging
from dataclasses import dataclass
from torch.nn.functional import smooth_l1_loss

# Import existing components
try:
    from training_framework import (
        PerceptualLoss, DistillationLoss, FrameInterpolationTrainer,
        CombinedLoss, EdgeLoss, TemporalConsistencyLoss
    )
except ImportError as e:
    print(f"Training framework import warning: {e}")
    class PerceptualLoss(nn.Module):
        """ UPGRADED: çœŸæ­£çš„VGGæ„ŸçŸ¥æŸå¤±å®ç°"""
        def __init__(self):
            super().__init__()
            
            # å°è¯•åŠ è½½VGG16è¿›è¡Œæ„ŸçŸ¥æŸå¤±è®¡ç®—
            try:
                import torchvision.models as models
                # åŠ è½½é¢„è®­ç»ƒVGG16
                vgg = models.vgg16(pretrained=True)
                self.vgg_features = vgg.features[:30]  # åˆ°relu5_3
                
                # å†»ç»“VGGå‚æ•°
                for param in self.vgg_features.parameters():
                    param.requires_grad = False
                    
                # ImageNetæ ‡å‡†åŒ–å‚æ•°
                self.register_buffer('mean', torch.tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1))
                self.register_buffer('std', torch.tensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1))
                
                # ç‰¹å¾æå–å±‚ç´¢å¼•
                self.feature_layers = [3, 8, 15, 22, 29]
                self.use_vgg = True
                
                print(" VGGæ„ŸçŸ¥æŸå¤±åˆå§‹åŒ–æˆåŠŸ")
                
            except Exception as e:
                print(f" VGGæ„ŸçŸ¥æŸå¤±åˆå§‹åŒ–å¤±è´¥ï¼Œä½¿ç”¨SSIMæ›¿ä»£: {e}")
                self.use_vgg = False
                # SSIMçª—å£
                self.register_buffer('ssim_window', self._create_ssim_window(11, 3))
                
        def _create_ssim_window(self, window_size: int, channel: int) -> torch.Tensor:
            """åˆ›å»ºSSIMé«˜æ–¯çª—å£"""
            import numpy as np
            sigma = 1.5
            gauss = torch.Tensor([
                np.exp(-(x - window_size//2)**2/float(2*sigma**2)) 
                for x in range(window_size)
            ])
            gauss = gauss / gauss.sum()
            
            _1D_window = gauss.unsqueeze(1)
            _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)
            
            window = _2D_window.expand(channel, 1, window_size, window_size).contiguous()
            return window
            
        def _normalize_for_vgg(self, x: torch.Tensor) -> torch.Tensor:
            """æ ‡å‡†åŒ–è¾“å…¥åˆ°VGGèŒƒå›´"""
            # å‡è®¾è¾“å…¥æ˜¯[-1, 1] æˆ– [0, 1] èŒƒå›´
            if x.min() < 0:
                x = (x + 1.0) / 2.0  # [-1,1] -> [0,1]
            
            # ImageNetæ ‡å‡†åŒ–
            return (x - self.mean) / self.std
            
        def _extract_vgg_features(self, x: torch.Tensor) -> list:
            """æå–VGGç‰¹å¾"""
            x = self._normalize_for_vgg(x)
            features = []
            
            for i, layer in enumerate(self.vgg_features):
                x = layer(x)
                if i in self.feature_layers:
                    features.append(x)
                    
            return features
            
        def _compute_ssim(self, pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:
            """è®¡ç®—SSIMä½œä¸ºVGGçš„æ›¿ä»£"""
            window = self.ssim_window.to(pred.device)
            
            # è®¡ç®—å‡å€¼
            mu1 = F.conv2d(pred, window, padding=5, groups=3)
            mu2 = F.conv2d(target, window, padding=5, groups=3)
            
            mu1_sq = mu1.pow(2)
            mu2_sq = mu2.pow(2)
            mu1_mu2 = mu1 * mu2
            
            # æ–¹å·®å’Œåæ–¹å·®
            sigma1_sq = F.conv2d(pred * pred, window, padding=5, groups=3) - mu1_sq
            sigma2_sq = F.conv2d(target * target, window, padding=5, groups=3) - mu2_sq
            sigma12 = F.conv2d(pred * target, window, padding=5, groups=3) - mu1_mu2
            
            # SSIMè®¡ç®—
            C1 = 0.01**2
            C2 = 0.03**2
            
            ssim = ((2*mu1_mu2 + C1)*(2*sigma12 + C2)) / ((mu1_sq + mu2_sq + C1)*(sigma1_sq + sigma2_sq + C2))
            
            return 1 - ssim.mean()  # è½¬æ¢ä¸ºæŸå¤± (è¶Šå°è¶Šå¥½)
        
        def forward(self, pred, target):
            """æ„ŸçŸ¥æŸå¤±è®¡ç®—"""
            if not self.use_vgg:
                # ä½¿ç”¨SSIMä½œä¸ºæ›¿ä»£
                return self._compute_ssim(pred, target)
            
            try:
                # VGGæ„ŸçŸ¥æŸå¤±
                pred_features = self._extract_vgg_features(pred)
                target_features = self._extract_vgg_features(target)
                
                perceptual_loss = 0.0
                layer_weights = [1.5, 1.5, 2.0, 2.0, 1.5]  # æ¯å±‚æƒé‡
                
                for i, (pred_feat, target_feat) in enumerate(zip(pred_features, target_features)):
                    if i < len(layer_weights):
                        # ä½¿ç”¨L1æŸå¤±æ¯”è¾ƒç‰¹å¾
                        layer_loss = smooth_l1_loss(pred_feat, target_feat, beta=0.001)
                        perceptual_loss += layer_weights[i] * layer_loss
                
                return perceptual_loss
                
            except Exception as e:
                print(f" VGGæ„ŸçŸ¥æŸå¤±è®¡ç®—å¤±è´¥ï¼Œä½¿ç”¨SSIMæ›¿ä»£: {e}")
                # é™çº§åˆ°SSIM
                return self._compute_ssim(pred, target)
    
    class DistillationLoss(nn.Module):
        def __init__(self):
            super().__init__()
        def forward(self, student, teacher, target):
            # è¿”å›é›¶æŸå¤±ä½†ä¸å½±å“è®­ç»ƒï¼ˆé€šè¿‡requires_grad=Falseï¼‰
            return torch.tensor(0.0, requires_grad=False), {}
    
    class EdgeLoss(nn.Module):
        def __init__(self):
            super().__init__()
        def forward(self, pred, target):
            # ä½¿ç”¨ç®€å•çš„æ¢¯åº¦å·®å¼‚ä½œä¸ºè¾¹ç¼˜æŸå¤±
            return torch.nn.functional.l1_loss(
                torch.diff(pred, dim=-1), 
                torch.diff(target, dim=-1)
            ) + torch.nn.functional.l1_loss(
                torch.diff(pred, dim=-2), 
                torch.diff(target, dim=-2)
            )
    
    class FrameInterpolationTrainer:
        pass
    class CombinedLoss:
        pass
    class TemporalConsistencyLoss:
        pass

try:
    from training_monitor import TrainingMonitor, create_training_monitor
except ImportError:
    try:
        from train.training_monitor import TrainingMonitor, create_training_monitor
    except ImportError:
        print("Training monitor module import warning")
        class TrainingMonitor:
            def __init__(self, log_dir, config):
                pass
            def log_training_progress(self, progress_dict):
                pass
        def create_training_monitor(config, model=None):
            return TrainingMonitor(config.get('log_dir', './logs'), config)

# Import patch components
import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'src', 'npu', 'networks'))
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'src', 'npu'))

# Use absolute imports to avoid relative import issues
try:
    from src.npu.networks.patch_inpainting import PatchBasedInpainting, PatchInpaintingConfig
    from src.npu.networks.mobile_inpainting_network import MobileInpaintingNetwork
except ImportError:
    # Alternative import method
    sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))
    from src.npu.networks.patch_inpainting import PatchBasedInpainting, PatchInpaintingConfig
    from src.npu.networks.mobile_inpainting_network import MobileInpaintingNetwork

# å¯¼å…¥patchæ•°æ®é›†
try:
    from patch_aware_dataset import PatchAwareDataset, PatchTrainingConfig
except ImportError:
    try:
        from train.patch_aware_dataset import PatchAwareDataset, PatchTrainingConfig
    except ImportError:
        print("Patchæ•°æ®é›†å¯¼å…¥è­¦å‘Š")
        class PatchAwareDataset:
            pass
        class PatchTrainingConfig:
            def __init__(self, **kwargs):
                for k, v in kwargs.items():
                    setattr(self, k, v)

# å¯¼å…¥patchå¯è§†åŒ–ç»„ä»¶
try:
    from patch_tensorboard_logger import create_patch_visualizer, PatchTensorBoardLogger
    TENSORBOARD_AVAILABLE = True
except ImportError:
    try:
        from train.patch_tensorboard_logger import create_patch_visualizer, PatchTensorBoardLogger
        TENSORBOARD_AVAILABLE = True
        print(" TensorBoardå¯è§†åŒ–: trainæ¨¡å—å¯¼å…¥æˆåŠŸ")
    except ImportError as e:
        print(f"âš ï¸ Patch TensorBoardå¯è§†åŒ–å¯¼å…¥è­¦å‘Š: {e}")
        TENSORBOARD_AVAILABLE = False
        
        #  FIX: æä¾›å®Œæ•´çš„fallbackå®ç°ä»¥ç¡®ä¿è®­ç»ƒä¸ä¸­æ–­
        def create_patch_visualizer(log_dir, config=None):
            """Fallbackå¯è§†åŒ–å™¨ - æä¾›åŸºæœ¬åŠŸèƒ½ä½†ä¸æ‰§è¡Œå®é™…è®°å½•"""
            class FallbackVisualizer:
                def __init__(self, log_dir, config):
                    self.log_dir = log_dir
                    self.config = config or {}
                    self.vis_frequency = config.get('visualization_frequency', 100) if config else 100
                    self.save_frequency = config.get('save_frequency', 500) if config else 500
                    print(f"ğŸ”„ ä½¿ç”¨Fallbackå¯è§†åŒ–å™¨: {log_dir}")
                
                def should_visualize(self, step):
                    return step % self.vis_frequency == 0
                
                def log_patch_visualization(self, *args, **kwargs):
                    pass
                
                def log_patch_comparison(self, *args, **kwargs):
                    pass
                
                def log_training_step(self, *args, **kwargs):
                    pass
                
                def log_validation_step(self, *args, **kwargs):
                    pass
                
                def log_training_progress(self, *args, **kwargs):
                    pass
                
                def close(self):
                    pass
            
            return FallbackVisualizer(log_dir, config)
        
        class PatchTensorBoardLogger:
            def __init__(self, *args, **kwargs):
                print("ğŸ”„ ä½¿ç”¨Fallback TensorBoard Logger")
            def log_patch_visualization(self, *args, **kwargs):
                pass
            def log_patch_comparison(self, *args, **kwargs):
                pass
            def log_training_step(self, *args, **kwargs):
                pass
            def log_validation_step(self, *args, **kwargs):
                pass


@dataclass
class PatchTrainingScheduleConfig:
    """Patchè®­ç»ƒè°ƒåº¦é…ç½®"""
    # è®­ç»ƒé˜¶æ®µé…ç½®
    patch_warmup_epochs: int = 20           # patchæ¨¡å¼çƒ­èº«é˜¶æ®µ
    mixed_training_epochs: int = 50         # æ··åˆè®­ç»ƒé˜¶æ®µ
    full_fine_tuning_epochs: int = 30       # å…¨å›¾fine-tuningé˜¶æ®µ
    
    # æ¨¡å¼åˆ‡æ¢ç­–ç•¥
    initial_patch_probability: float = 0.9   # åˆå§‹patchæ¦‚ç‡
    final_patch_probability: float = 0.3     # æœ€ç»ˆpatchæ¦‚ç‡
    
    # è‡ªé€‚åº”è°ƒåº¦
    enable_adaptive_scheduling: bool = True  # å¯ç”¨è‡ªé€‚åº”è°ƒåº¦
    loss_patience: int = 5                   # æŸå¤±æ— æ”¹å–„å®¹å¿epochs
    
    # æ€§èƒ½é˜ˆå€¼
    patch_efficiency_threshold: float = 1.5  # patchæ•ˆç‡é˜ˆå€¼ï¼ˆç›¸æ¯”fullæ¨¡å¼ï¼‰
    quality_drop_threshold: float = 0.05     # è´¨é‡ä¸‹é™å®¹å¿é˜ˆå€¼


class PatchAwareLoss(nn.Module):
    """
    Patch-AwareæŸå¤±å‡½æ•°ç³»ç»Ÿ
    
    åŠŸèƒ½ï¼š
    1. Multi-scaleæŸå¤±ï¼špatch-level + image-level
    2. Boundary-awareå¤„ç†ï¼špatchè¾¹ç•Œçš„ç‰¹æ®ŠæŸå¤±
    3. ConsistencyæŸå¤±ï¼špatchèåˆä¸€è‡´æ€§
    4. è‡ªé€‚åº”æƒé‡ï¼šåŸºäºè®­ç»ƒé˜¶æ®µçš„åŠ¨æ€æƒé‡è°ƒæ•´
    """
    
    def __init__(self, 
                 lambda_patch: float = 1.0,
                 lambda_full: float = 1.0,
                 lambda_boundary: float = 0.5,
                 lambda_consistency: float = 0.3,
                 enable_adaptive_weights: bool = True):
        super(PatchAwareLoss, self).__init__()
        
        # æŸå¤±æƒé‡
        self.lambda_patch = lambda_patch
        self.lambda_full = lambda_full
        self.lambda_boundary = lambda_boundary
        self.lambda_consistency = lambda_consistency
        self.enable_adaptive_weights = enable_adaptive_weights
        
        # åŸºç¡€æŸå¤±å‡½æ•°
        self.l1_loss = nn.L1Loss()
        self.mse_loss = nn.MSELoss()
        self.perceptual_loss = PerceptualLoss()
        self.edge_loss = EdgeLoss()
        
        # patchä¸“ç”¨æŸå¤±
        self.boundary_kernel = self._create_boundary_kernel()
        
    def _create_boundary_kernel(self) -> torch.Tensor:
        """åˆ›å»ºè¾¹ç•Œæ£€æµ‹å·ç§¯æ ¸"""
        kernel = torch.tensor([
            [-1, -1, -1],
            [-1,  8, -1],
            [-1, -1, -1]
        ], dtype=torch.float32).unsqueeze(0).unsqueeze(0)
        return kernel
    
    def forward(self, 
                predictions: Dict[str, torch.Tensor],
                targets: Dict[str, torch.Tensor],
                mode: str,
                epoch: int = 0,
                metadata: Optional[Dict] = None) -> Tuple[torch.Tensor, Dict[str, torch.Tensor]]:
        """
        è®¡ç®—patch-awareæŸå¤±
        
        Args:
            predictions: é¢„æµ‹ç»“æœå­—å…¸
            targets: ç›®æ ‡ç»“æœå­—å…¸
            mode: 'patch' (ç°åœ¨åªæ”¯æŒpatchæ¨¡å¼)
            epoch: å½“å‰epochï¼ˆç”¨äºè‡ªé€‚åº”æƒé‡ï¼‰
            metadata: é¢å¤–å…ƒæ•°æ®
            
        Returns:
            total_loss: æ€»æŸå¤±
            loss_dict: åˆ†é¡¹æŸå¤±å­—å…¸
        """
        losses = {}
        total_loss = 0.0
        
        # è®¡ç®—è‡ªé€‚åº”æƒé‡
        if self.enable_adaptive_weights:
            weights = self._compute_adaptive_weights(epoch, mode)
        else:
            weights = {
                'patch': self.lambda_patch,
                'full': self.lambda_full,
                'boundary': self.lambda_boundary,
                'consistency': self.lambda_consistency
            }
        
        # Patchæ¨¡å¼æŸå¤±
        if 'patch' in predictions:
            patch_pred = predictions['patch']  # [N, 3, 128, 128]
            patch_target = targets['patch']    # [N, 3, 128, 128]
            
            # åŸºç¡€patchæŸå¤±
            patch_l1 = self.l1_loss(patch_pred, patch_target)
            patch_perceptual = self.perceptual_loss(patch_pred, patch_target)
            patch_edge = self.edge_loss(patch_pred, patch_target)
            
            # è¾¹ç•Œæ„ŸçŸ¥æŸå¤±
            boundary_loss = self._compute_boundary_loss(
                patch_pred, patch_target, metadata.get('patch_metadata', []) if metadata else []
            )
            
            losses['patch_l1'] = patch_l1
            losses['patch_perceptual'] = patch_perceptual
            losses['patch_edge'] = patch_edge
            losses['patch_boundary'] = boundary_loss
            
            # patchæ€»æŸå¤±
            patch_total = (patch_l1 + 1.2 * patch_perceptual + 
                          0.5 * patch_edge + weights['boundary'] * boundary_loss)
            total_loss += weights['patch'] * patch_total
        
        # æ³¨æ„ï¼šåˆ é™¤äº†Fullæ¨¡å¼æŸå¤±å’Œä¸€è‡´æ€§æŸå¤±ï¼Œç°åœ¨åªä¸“æ³¨äºpatchè®­ç»ƒ
        
        losses['total'] = total_loss
        return total_loss, losses
    
    def _compute_adaptive_weights(self, epoch: int, mode: str) -> Dict[str, float]:
        """è®¡ç®—è‡ªé€‚åº”æŸå¤±æƒé‡ - ç®€åŒ–ä¸ºåªæ”¯æŒpatchæ¨¡å¼"""
        # åŸºäºè®­ç»ƒè¿›åº¦è°ƒæ•´æƒé‡
        progress = min(epoch / 100.0, 1.0)  # å‡è®¾100 epochä¸ºå®Œæ•´è®­ç»ƒ
        
        # ç°åœ¨åªæœ‰patchæ¨¡å¼ï¼šearlyé‡patchï¼Œlateré‡boundary
        patch_weight = 1.0
        boundary_weight = 0.7
        
        return {
            'patch': patch_weight,
            'boundary': boundary_weight,
            'consistency': 0.0,  # ä¸å†ä½¿ç”¨ä¸€è‡´æ€§æŸå¤±
            'full': 0.0  # ä¸å†ä½¿ç”¨å…¨å›¾æŸå¤±
        }
    
    def _compute_boundary_loss(self, pred: torch.Tensor, target: torch.Tensor, 
                              patch_metadata: List[Dict]) -> torch.Tensor:
        """è®¡ç®—è¾¹ç•Œæ„ŸçŸ¥æŸå¤± -  FIXED: è‡ªé€‚åº”è¾¹ç•Œæ£€æµ‹ï¼Œä¸ä¾èµ–metadata"""
        batch_size = pred.shape[0]
        
        if batch_size == 0:
            return torch.tensor(0.0, device=pred.device)
        
        #  NEW: è‡ªåŠ¨è¾¹ç•Œæ£€æµ‹ï¼Œä¸ä¾èµ–å¤–éƒ¨metadata
        total_boundary_loss = 0.0
        
        # ç¡®ä¿boundary_kernelåœ¨æ­£ç¡®è®¾å¤‡ä¸Š
        if self.boundary_kernel.device != pred.device:
            self.boundary_kernel = self.boundary_kernel.to(pred.device)
        
        for i in range(batch_size):
            # å¯¹æ¯ä¸ªpatchè®¡ç®—è¾¹ç•ŒæŸå¤±
            patch_pred = pred[i:i+1]  # [1, 3, H, W]
            patch_target = target[i:i+1]  # [1, 3, H, W]
            
            #  NEW: å¤šç§è¾¹ç•Œæ£€æµ‹ç­–ç•¥ç»„åˆ
            # 1. åŸºäºç›®æ ‡å›¾åƒçš„è¾¹ç¼˜æ£€æµ‹
            target_gray = torch.mean(patch_target, dim=1, keepdim=True)  # [1, 1, H, W]
            target_edges = F.conv2d(target_gray, self.boundary_kernel, padding=1)
            target_boundary_map = torch.sigmoid(torch.abs(target_edges) * 2.0)
            
            # 2. åŸºäºé¢„æµ‹å›¾åƒçš„è¾¹ç¼˜æ£€æµ‹
            pred_gray = torch.mean(patch_pred, dim=1, keepdim=True)  # [1, 1, H, W]
            pred_edges = F.conv2d(pred_gray, self.boundary_kernel, padding=1)
            pred_boundary_map = torch.sigmoid(torch.abs(pred_edges) * 1.0)
            
            # 3. ç»„åˆè¾¹ç•Œå›¾ï¼šå–ä¸¤è€…çš„æœ€å¤§å€¼
            combined_boundary_map = torch.max(target_boundary_map, pred_boundary_map)
            
            # 4. æ·»åŠ patchè¾¹ç¼˜åŒºåŸŸï¼ˆpatchçš„å››å‘¨è¾¹ç•Œï¼‰
            H, W = patch_pred.shape[2], patch_pred.shape[3]
            edge_margin = 8  # è¾¹ç¼˜åŒºåŸŸå®½åº¦
            edge_mask = torch.zeros_like(combined_boundary_map)
            
            # è®¾ç½®è¾¹ç¼˜åŒºåŸŸ
            edge_mask[:, :, :edge_margin, :] = 0.5  # é¡¶éƒ¨
            edge_mask[:, :, -edge_margin:, :] = 0.5  # åº•éƒ¨
            edge_mask[:, :, :, :edge_margin] = 0.5  # å·¦ä¾§
            edge_mask[:, :, :, -edge_margin:] = 0.5  # å³ä¾§
            
            # 5. æœ€ç»ˆè¾¹ç•Œæƒé‡å›¾
            final_boundary_map = torch.clamp(combined_boundary_map + edge_mask, 0.0, 2.0)
            
            # 6. åœ¨è¾¹ç•ŒåŒºåŸŸåŠ æƒL1æŸå¤±
            boundary_weighted_loss = torch.mean(
                F.l1_loss(patch_pred, patch_target, reduction='none') * 
                (1.0 + final_boundary_map)  # è¾¹ç•ŒåŒºåŸŸæƒé‡å¢å¼º (1.0-3.0å€)
            )
            
            total_boundary_loss += boundary_weighted_loss
        
        # è¿”å›å¹³å‡è¾¹ç•ŒæŸå¤±
        return total_boundary_loss / batch_size
    


class PatchTrainingScheduler:
    """
    Patchè®­ç»ƒè°ƒåº¦å™¨
    
    åŠŸèƒ½ï¼š
    1. è®­ç»ƒé˜¶æ®µç®¡ç†
    2. æ¨¡å¼æ¦‚ç‡åŠ¨æ€è°ƒæ•´
    3. è‡ªé€‚åº”æ€§èƒ½ä¼˜åŒ–
    4. æ—©åœå’Œè´¨é‡ç›‘æ§
    """
    
    def __init__(self, config: PatchTrainingScheduleConfig):
        self.config = config
        self.current_epoch = 0
        self.patch_performance_history = []
        self.full_performance_history = []
        
    def get_patch_probability(self, epoch: int, recent_losses: Optional[List[float]] = None) -> float:
        """è·å–å½“å‰epochåº”è¯¥ä½¿ç”¨çš„patchæ¨¡å¼æ¦‚ç‡"""
        self.current_epoch = epoch
        
        # åŸºç¡€è°ƒåº¦ç­–ç•¥
        if epoch < self.config.patch_warmup_epochs:
            # çƒ­èº«é˜¶æ®µï¼šé«˜patchæ¦‚ç‡
            base_prob = self.config.initial_patch_probability
        elif epoch < self.config.patch_warmup_epochs + self.config.mixed_training_epochs:
            # æ··åˆè®­ç»ƒé˜¶æ®µï¼šçº¿æ€§ä¸‹é™
            progress = (epoch - self.config.patch_warmup_epochs) / self.config.mixed_training_epochs
            base_prob = (self.config.initial_patch_probability - 
                        (self.config.initial_patch_probability - self.config.final_patch_probability) * progress)
        else:
            # Fine-tuningé˜¶æ®µï¼šä½patchæ¦‚ç‡
            base_prob = self.config.final_patch_probability
        
        # è‡ªé€‚åº”è°ƒæ•´
        if self.config.enable_adaptive_scheduling and recent_losses:
            base_prob = self._adaptive_adjustment(base_prob, recent_losses)
        
        return np.clip(base_prob, 0.1, 0.9)
    
    def _adaptive_adjustment(self, base_prob: float, recent_losses: List[float]) -> float:
        """åŸºäºæœ€è¿‘æŸå¤±å†å²çš„è‡ªé€‚åº”è°ƒæ•´"""
        if len(recent_losses) < 3:
            return base_prob
        
        # æ£€æŸ¥æŸå¤±è¶‹åŠ¿
        recent_trend = recent_losses[-1] - recent_losses[-3]
        
        if recent_trend > 0:  # æŸå¤±ä¸Šå‡
            # å¢åŠ patchæ¦‚ç‡ï¼ˆpatchè®­ç»ƒé€šå¸¸æ›´ç¨³å®šï¼‰
            adjustment = 0.1
        else:  # æŸå¤±ä¸‹é™
            # ä¿æŒå½“å‰ç­–ç•¥
            adjustment = 0.0
        
        return base_prob + adjustment
    
    def should_switch_strategy(self, current_metrics: Dict[str, float]) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥åˆ‡æ¢è®­ç»ƒç­–ç•¥"""
        if not self.config.enable_adaptive_scheduling:
            return False
        
        # åŸºäºæ€§èƒ½æŒ‡æ ‡å†³å®šç­–ç•¥åˆ‡æ¢
        # è¿™é‡Œå¯ä»¥æ·»åŠ æ›´å¤æ‚çš„é€»è¾‘
        return False


class PatchFrameInterpolationTrainer(pl.LightningModule):
    """
    Patch-Basedå¸§æ’å€¼è®­ç»ƒå™¨
    
    ç»§æ‰¿è‡ªPyTorch Lightningï¼Œæ”¯æŒpatch-awareè®­ç»ƒï¼š
    1. æ™ºèƒ½æ¨¡å¼è°ƒåº¦
    2. åŠ¨æ€batchå¤„ç†  
    3. å¤šå°ºåº¦æŸå¤±ä¼˜åŒ–
    4. è‡ªé€‚åº”æ€§èƒ½è°ƒä¼˜
    5. å®Œæ•´çš„ç›‘æ§å’Œæ—¥å¿—
    """
    
    def __init__(self,
                 model_config: Dict[str, Any],
                 training_config: Dict[str, Any],
                 patch_config: Optional[PatchTrainingConfig] = None,
                 schedule_config: Optional[PatchTrainingScheduleConfig] = None,
                 teacher_model_path: Optional[str] = None,
                 full_config: Optional[Dict[str, Any]] = None):
        super(PatchFrameInterpolationTrainer, self).__init__()
        
        self.save_hyperparameters()
        
        # é…ç½®
        self.model_config = model_config
        self.training_config = training_config
        self.patch_config = patch_config or PatchTrainingConfig()
        self.schedule_config = schedule_config or PatchTrainingScheduleConfig()
        
        # åˆ›å»ºpatch-basedç½‘ç»œ
        inpainting_config = model_config.get('inpainting_network', {})
        patch_inpainting_config = PatchInpaintingConfig(
            enable_patch_mode=self.patch_config.enable_patch_mode,
            patch_network_channels=24  #  REVERT: å›é€€åˆ°ç¨³å®šçš„24é€šé“é…ç½®
        )
        
        self.student_model = PatchBasedInpainting(
            input_channels=inpainting_config.get('input_channels', 7),
            output_channels=inpainting_config.get('output_channels', 3),
            config=patch_inpainting_config
        )
        
        #  NEW: å¯åŠ¨æ—¶è¾“å‡ºæ¨¡å‹é…ç½®ä¿¡æ¯
        self._print_model_architecture_info(inpainting_config, patch_inpainting_config)
        
        # æ³¨æ„ï¼šåˆ é™¤äº†fallbackå…¨å›¾ç½‘ç»œï¼Œç°åœ¨åªä¸“æ³¨patchè®­ç»ƒ
        
        # åŠ è½½æ•™å¸ˆç½‘ç»œï¼ˆçŸ¥è¯†è’¸é¦ï¼‰
        self.teacher_model = None
        if teacher_model_path and os.path.exists(teacher_model_path):
            self.teacher_model = MobileInpaintingNetwork(
                input_channels=inpainting_config.get('input_channels', 7),
                output_channels=inpainting_config.get('output_channels', 3)
            )
            checkpoint = torch.load(teacher_model_path, map_location='cpu')
            if 'state_dict' in checkpoint:
                self.teacher_model.load_state_dict(checkpoint['state_dict'])
            else:
                self.teacher_model.load_state_dict(checkpoint)
            self.teacher_model.eval()
            for param in self.teacher_model.parameters():
                param.requires_grad = False
        
        # æŸå¤±å‡½æ•°
        self.patch_loss = PatchAwareLoss()
        
        # è®­ç»ƒä¾§ç»Ÿä¸€çš„è¾¹ç•Œæ£€æµ‹å·ç§¯æ ¸ï¼ˆä¸æŸå¤±å‡½æ•°ä¸€è‡´ï¼‰
        boundary_kernel = torch.tensor([
            [-1, -1, -1],
            [-1,  8, -1],
            [-1, -1, -1]
        ], dtype=torch.float32).unsqueeze(0).unsqueeze(0)
        self.register_buffer('boundary_kernel', boundary_kernel)
        
        if self.teacher_model is not None:
            self.distillation_loss = DistillationLoss()
        
        # è®­ç»ƒè°ƒåº¦å™¨
        self.scheduler = PatchTrainingScheduler(self.schedule_config)
        
        # æ€§èƒ½ç›‘æ§
        monitor_config = (full_config or {}).copy()
        monitor_config['log_dir'] = training_config.get('log_dir', './logs')
        self.training_monitor = create_training_monitor(
            config=monitor_config,
            model=self.student_model
        )
        
        # Patchä¸“ç”¨å¯è§†åŒ–ç³»ç»Ÿ
        viz_config = {
            'visualization_frequency': full_config.get('visualization', {}).get('visualization_frequency', 100),
            'save_frequency': full_config.get('visualization', {}).get('save_frequency', 500),
            'enable_visualization': full_config.get('visualization', {}).get('enable_visualization', True)
        }
        self.patch_visualizer = create_patch_visualizer(
            log_dir=training_config.get('log_dir', './logs'),
            config=viz_config
        ) if viz_config['enable_visualization'] else None
        
        # è®­ç»ƒç»Ÿè®¡
        self.training_stats = {
            'patch_steps': 0,
            'recent_losses': [],
            'best_val_loss': float('inf'),
            'patience_count': 0
        }
        
        # å¯è§†åŒ–æ­¥éª¤è®¡æ•°å™¨ï¼ˆé¿å…ä¸Lightningçš„global_stepå†²çªï¼‰
        self.visualization_step = 0
        
        print(f"Patch visualization system: {'ENABLED' if self.patch_visualizer else 'DISABLED'}")
    
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """å‰å‘ä¼ æ’­"""
        return self.student_model(x)
    
    def _validate_batch_data(self, batch: Dict[str, torch.Tensor]) -> None:
        """éªŒè¯batchæ•°æ®çš„å®Œæ•´æ€§å’Œæ ¼å¼"""
        try:
            # æ£€æŸ¥å¿…éœ€çš„å­—æ®µ
            if 'patch_input' not in batch:
                raise ValueError("Missing 'patch_input' in batch data")
            if 'patch_target_residual' not in batch:
                raise ValueError("Missing 'patch_target_residual' in batch data")  
            if 'patch_target_rgb' not in batch:
                raise ValueError("Missing 'patch_target_rgb' in batch data")
            
            # æ£€æŸ¥æ•°æ®ç»´åº¦
            patch_input = batch['patch_input']
            patch_target_residual = batch['patch_target_residual']
            patch_target_rgb = batch['patch_target_rgb']
            
            if patch_input.dim() != 4:
                raise ValueError(f"patch_input should be 4D tensor, got {patch_input.dim()}D")
            if patch_target_residual.dim() != 4:
                raise ValueError(f"patch_target_residual should be 4D tensor, got {patch_target_residual.dim()}D")
            if patch_target_rgb.dim() != 4:
                raise ValueError(f"patch_target_rgb should be 4D tensor, got {patch_target_rgb.dim()}D")
            
            # æ£€æŸ¥é€šé“æ•°
            if patch_input.shape[1] != 7:
                raise ValueError(f"patch_input should have 7 channels, got {patch_input.shape[1]}")
            if patch_target_residual.shape[1] != 3:
                raise ValueError(f"patch_target_residual should have 3 channels, got {patch_target_residual.shape[1]}")
            if patch_target_rgb.shape[1] != 3:
                raise ValueError(f"patch_target_rgb should have 3 channels, got {patch_target_rgb.shape[1]}")
            
            # æ£€æŸ¥æ‰¹æ¬¡å¤§å°ä¸€è‡´æ€§
            batch_size = patch_input.shape[0]
            if patch_target_residual.shape[0] != batch_size:
                raise ValueError(f"Batch size mismatch: input={batch_size}, target_residual={patch_target_residual.shape[0]}")
            if patch_target_rgb.shape[0] != batch_size:
                raise ValueError(f"Batch size mismatch: input={batch_size}, target_rgb={patch_target_rgb.shape[0]}")
            
            # æ£€æŸ¥patchå°ºå¯¸ä¸€è‡´æ€§
            if patch_input.shape[2:] != patch_target_residual.shape[2:]:
                raise ValueError(f"Spatial size mismatch: input={patch_input.shape[2:]}, target_residual={patch_target_residual.shape[2:]}")
            if patch_input.shape[2:] != patch_target_rgb.shape[2:]:
                raise ValueError(f"Spatial size mismatch: input={patch_input.shape[2:]}, target_rgb={patch_target_rgb.shape[2:]}")
            
            # æ£€æŸ¥æ•°æ®èŒƒå›´
            if torch.isnan(patch_input).any() or torch.isinf(patch_input).any():
                raise ValueError("patch_input contains NaN or Inf values")
            if torch.isnan(patch_target_residual).any() or torch.isinf(patch_target_residual).any():
                raise ValueError("patch_target_residual contains NaN or Inf values")
            if torch.isnan(patch_target_rgb).any() or torch.isinf(patch_target_rgb).any():
                raise ValueError("patch_target_rgb contains NaN or Inf values")
            
            # æ£€æŸ¥æ®‹å·®å­¦ä¹ æ•°æ®ä¸€è‡´æ€§
            try:
                from residual_learning_helper import ResidualLearningHelper
                warped_rgb = patch_input[:, :3]
                ResidualLearningHelper.validate_residual_data(patch_input, patch_target_residual, patch_target_rgb)
            except ImportError:
                pass
                
        except Exception as e:
            print(f"ERROR: Batchæ•°æ®éªŒè¯å¤±è´¥: {e}")
            #  FIX: æ·»åŠ ç±»å‹æ£€æŸ¥ï¼Œé¿å…å¯¹listè°ƒç”¨keys()
            if isinstance(batch, dict):
                print(f"Batch keys: {list(batch.keys())}")
                if 'patch_input' in batch:
                    print(f"patch_input shape: {batch['patch_input'].shape}")
                if 'patch_target_residual' in batch:
                    print(f"patch_target_residual shape: {batch['patch_target_residual'].shape}")
                if 'patch_target_rgb' in batch:
                    print(f"patch_target_rgb shape: {batch['patch_target_rgb'].shape}")
            else:
                print(f"Batch type: {type(batch)}, content: {batch}")
            raise e

    def training_step(self, batch: Dict[str, torch.Tensor], batch_idx: int) -> Dict[str, torch.Tensor]:
        """è®­ç»ƒæ­¥éª¤"""
        current_epoch = self.current_epoch
        
        # è·å–å½“å‰çš„patchæ¦‚ç‡
        patch_probability = self.scheduler.get_patch_probability(
            current_epoch, 
            self.training_stats['recent_losses'][-10:] if self.training_stats['recent_losses'] else None
        )
        
        # åŠ¨æ€è®¾ç½®patchæ¨¡å¼æ¦‚ç‡
        self.student_model.config.enable_patch_mode = True
        
        # å‡†å¤‡è¾“å…¥æ•°æ®
        predictions = {}
        targets = {}
        
        # æ•°æ®éªŒè¯å’Œæ®‹å·®å­¦ä¹ patchæ•°æ®å¤„ç†
        self._validate_batch_data(batch)
        
        if 'patch_input' in batch and len(batch['patch_input']) > 0:
            patch_input = batch['patch_input']                      # [N, 7, 270, 480]
            patch_target_residual = batch['patch_target_residual']  # [N, 3, 270, 480]
            patch_target_rgb = batch['patch_target_rgb']            # [N, 3, 270, 480]
            
            # è®­ç»ƒæ—¶åŸºäºç›®æ ‡å›¾åƒæ„å»ºè¾¹ç•Œå›¾å¹¶ä¼ å…¥ç½‘ç»œï¼ˆä¸æŸå¤±ä¾§è¯­ä¹‰ä¸€è‡´ï¼‰
            target_gray = torch.mean(patch_target_rgb, dim=1, keepdim=True)  # [N,1,H,W]
            # ç¡®ä¿å·ç§¯æ ¸åœ¨åŒä¸€è®¾å¤‡
            kernel = self.boundary_kernel
            if kernel.device != target_gray.device:
                kernel = kernel.to(target_gray.device)
            target_edges = F.conv2d(target_gray, kernel, padding=1)
            boundary_override = torch.sigmoid(torch.abs(target_edges) * 2.0)

            # Patchç½‘ç»œæ¨ç† - è¾“å‡ºæ®‹å·®é¢„æµ‹ï¼ˆä¼ å…¥ boundary_overrideï¼‰
            residual_pred = self.student_model.patch_network(patch_input, boundary_override=boundary_override)
            
            #  ä½¿ç”¨ç»Ÿä¸€çš„æ®‹å·®å­¦ä¹ å·¥å…·ç±»
            try:
                from residual_learning_helper import ResidualLearningHelper
            except ImportError:
                import sys
                sys.path.append('./train')
                from residual_learning_helper import ResidualLearningHelper
            
            # æ®‹å·®é¢„æµ‹è½¬æ¢ä¸ºå®Œæ•´å›¾åƒç”¨äºæŸå¤±è®¡ç®—
            warped_rgb = patch_input[:, :3]  # æå–è¾“å…¥çš„warped RGB
            patch_pred_full = ResidualLearningHelper.reconstruct_from_residual(warped_rgb, residual_pred)
            
            # æŸå¤±è®¡ç®—ä½¿ç”¨å®Œæ•´é‡å»ºå›¾åƒä¸ç›®æ ‡RGB
            predictions['patch'] = patch_pred_full
            targets['patch'] = patch_target_rgb
            
            self.training_stats['patch_steps'] += 1
        else:
            # å¦‚æœæ²¡æœ‰patchæ•°æ®ï¼Œè·³è¿‡è¿™ä¸ªbatch
            return {'loss': torch.tensor(0.0, requires_grad=True)}
        
        # ç°åœ¨åªæœ‰patchæ¨¡å¼
        mode = 'patch'
        
        # è®¡ç®—æŸå¤±
        loss, loss_dict = self.patch_loss(
            predictions, targets, mode, current_epoch,
            metadata=batch.get('batch_info', {})
        )
        
        # çŸ¥è¯†è’¸é¦æš‚æ—¶ç¦ç”¨ï¼Œå› ä¸ºåˆ é™¤äº†å…¨å›¾æ¨¡å¼
        
        # æ›´æ–°ç»Ÿè®¡
        self.training_stats['recent_losses'].append(loss.item())
        if len(self.training_stats['recent_losses']) > 20:
            self.training_stats['recent_losses'].pop(0)
        
        # æ—¥å¿—è®°å½•
        self.log_dict({
            'train_loss': loss,
            'patch_probability': patch_probability,
            'mode': 0,  # ç°åœ¨åªæœ‰patchæ¨¡å¼
            **{f'train_{k}': v for k, v in loss_dict.items() if k != 'total'}
        }, on_step=True, on_epoch=True, prog_bar=True)
        
        # Patchå¯è§†åŒ–è®°å½•ï¼ˆä½¿ç”¨Lightningçš„global_stepï¼‰
        current_global_step = self.global_step if hasattr(self, 'trainer') and self.trainer else self.visualization_step
        
        if self.patch_visualizer and self.patch_visualizer.should_visualize(current_global_step):
            try:
                #  è®°å½•patchå¯¹æ¯”ï¼ˆè¾“å…¥|ç›®æ ‡RGB|é‡å»ºå›¾åƒï¼‰- æ®‹å·®å­¦ä¹ ç‰ˆæœ¬
                if 'patch' in predictions and 'patch' in targets:
                    self.patch_visualizer.log_patch_comparison(
                        step=current_global_step,
                        patch_inputs=batch['patch_input'][:8],  # æœ€å¤šæ˜¾ç¤º8ä¸ªpatches
                        patch_targets=batch['patch_target_rgb'][:8],  # ä½¿ç”¨RGBç›®æ ‡è¿›è¡Œå¯è§†åŒ–
                        patch_predictions=predictions['patch'][:8],   # é‡å»ºçš„å®Œæ•´å›¾åƒ
                        tag=f'training_epoch_{current_epoch}'
                    )
                
                # è®°å½•è®­ç»ƒæ­¥éª¤ç»Ÿè®¡
                self.patch_visualizer.log_training_step(
                    step=current_global_step,
                    epoch=current_epoch,
                    mode=mode,
                    loss_dict=loss_dict,
                    batch_info=batch.get('batch_info', {}),
                    learning_rate=self.trainer.optimizers[0].param_groups[0]['lr'] if self.trainer.optimizers else None
                )
                
            except Exception as e:
                print(f"WARNING: Visualization logging failed: {e}")
        
        # æ›´æ–°å¯è§†åŒ–æ­¥éª¤è®¡æ•°ï¼ˆä»…åœ¨æ²¡æœ‰traineræ—¶ä½¿ç”¨ï¼‰
        if not hasattr(self, 'trainer') or not self.trainer:
            self.visualization_step += 1
        
        return {
            'loss': loss,
            'mode': mode,
            'batch_info': batch.get('batch_info', {}),
            'predictions': predictions,
            'targets': targets
        }
    
    def validation_step(self, batch: Dict[str, torch.Tensor], batch_idx: int) -> Dict[str, torch.Tensor]:
        """éªŒè¯æ­¥éª¤"""
        # éªŒè¯æ—¶ä½¿ç”¨æ··åˆæ¨¡å¼ï¼Œpatchæ¦‚ç‡å›ºå®šä¸º0.5
        predictions = {}
        targets = {}
        
        #  å¤„ç†æ®‹å·®å­¦ä¹ éªŒè¯æ•°æ®
        if 'patch_input' in batch and len(batch['patch_input']) > 0:
            patch_input = batch['patch_input']
            patch_target_rgb = batch['patch_target_rgb'] # è·å–ç›®æ ‡RGBç”¨äºç”Ÿæˆboundary_override

            target_gray = torch.mean(patch_target_rgb, dim=1, keepdim=True)  # [N,1,H,W]
            # ç¡®ä¿å·ç§¯æ ¸åœ¨åŒä¸€è®¾å¤‡
            kernel = self.boundary_kernel
            if kernel.device != target_gray.device:
                kernel = kernel.to(target_gray.device)
            target_edges = F.conv2d(target_gray, kernel, padding=1)
            boundary_override = torch.sigmoid(torch.abs(target_edges) * 2.0) 
            
            # ç½‘ç»œè¾“å‡ºæ®‹å·®é¢„æµ‹
            residual_pred = self.student_model.patch_network(batch['patch_input'], boundary_override=boundary_override)
            
            # ä½¿ç”¨ç»Ÿä¸€çš„æ®‹å·®å­¦ä¹ å·¥å…·ç±»è½¬æ¢ä¸ºå®Œæ•´å›¾åƒ
            try:
                from residual_learning_helper import ResidualLearningHelper
            except ImportError:
                import sys
                sys.path.append('./train')
                from residual_learning_helper import ResidualLearningHelper
            
            warped_rgb = batch['patch_input'][:, :3]
            patch_pred_full = ResidualLearningHelper.reconstruct_from_residual(warped_rgb, residual_pred)
            
            predictions['patch'] = patch_pred_full
            targets['patch'] = batch['patch_target_rgb']  # ä½¿ç”¨RGBç›®æ ‡
        
        # ç°åœ¨åªæœ‰patchæ¨¡å¼
        mode = 'patch'
        
        # è®¡ç®—éªŒè¯æŸå¤±
        val_loss, val_loss_dict = self.patch_loss(
            predictions, targets, mode, self.current_epoch
        )
        
        # æ—¥å¿—è®°å½•
        self.log_dict({
            'val_loss': val_loss,
            **{f'val_{k}': v for k, v in val_loss_dict.items() if k != 'total'}
        }, on_step=False, on_epoch=True, prog_bar=True)
        
        # éªŒè¯å¯è§†åŒ–è®°å½•
        current_global_step = self.global_step if hasattr(self, 'trainer') and self.trainer else self.visualization_step
        
        if self.patch_visualizer and self.current_epoch % 5 == 0:  # æ¯5ä¸ªepochè®°å½•éªŒè¯å›¾åƒ
            try:
                #  éªŒè¯å¯è§†åŒ– - æ®‹å·®å­¦ä¹ ç‰ˆæœ¬
                if 'patch' in predictions and 'patch' in targets:
                    self.patch_visualizer.log_patch_comparison(
                        step=current_global_step,
                        patch_inputs=batch['patch_input'][:4],  # éªŒè¯æ—¶æ˜¾ç¤º4ä¸ªpatches
                        patch_targets=batch['patch_target_rgb'][:4],  # ä½¿ç”¨RGBç›®æ ‡
                        patch_predictions=predictions['patch'][:4],   # é‡å»ºå›¾åƒ
                        tag=f'validation_epoch_{self.current_epoch}'
                    )
                
                # è®°å½•éªŒè¯æŸå¤±
                self.patch_visualizer.log_validation_step(
                    step=current_global_step,
                    val_loss_dict=val_loss_dict
                )
                
            except Exception as e:
                print(f"WARNING: Validation visualization logging failed: {e}")
        
        return {
            'val_loss': val_loss,
            'mode': mode,
            'predictions': predictions,
            'targets': targets
        }
    
    def configure_optimizers(self) -> Dict[str, Any]:
        """é…ç½®ä¼˜åŒ–å™¨å’Œå­¦ä¹ ç‡è°ƒåº¦å™¨"""
        # ä¼˜åŒ–å™¨é…ç½® - ç¡®ä¿ç±»å‹è½¬æ¢
        optimizer_config = self.training_config.get('optimizer', {})
        
        # å®‰å…¨çš„ç±»å‹è½¬æ¢
        learning_rate = float(optimizer_config.get('learning_rate', 1e-4))
        weight_decay = float(optimizer_config.get('weight_decay', 1e-5))
        
        print(f" ä¼˜åŒ–å™¨é…ç½®: lr={learning_rate}, weight_decay={weight_decay}")
        
        optimizer = optim.AdamW(
            self.student_model.parameters(),
            lr=learning_rate,
            weight_decay=weight_decay,
            betas=(0.9, 0.999)
        )
        
        # å­¦ä¹ ç‡è°ƒåº¦å™¨ - ç¡®ä¿ç±»å‹è½¬æ¢
        scheduler_config = self.training_config.get('scheduler', {})
        
        T_max = int(scheduler_config.get('T_max', 100))
        eta_min = float(scheduler_config.get('eta_min', 1e-6))
        
        print(f" è°ƒåº¦å™¨é…ç½®: T_max={T_max}, eta_min={eta_min}")
        
        scheduler = optim.lr_scheduler.CosineAnnealingLR(
            optimizer,
            T_max=T_max,
            eta_min=eta_min
        )
        
        return {
            'optimizer': optimizer,
            'lr_scheduler': {
                'scheduler': scheduler,
                'monitor': 'val_loss',
                'interval': 'epoch',
                'frequency': 1
            }
        }
    
    def on_epoch_end(self) -> None:
        """Epochç»“æŸæ—¶çš„å¤„ç†"""
        # æ›´æ–°è®­ç»ƒç›‘æ§
        if hasattr(self, 'training_monitor'):
            self.training_monitor.log_training_progress({
                'epoch': self.current_epoch,
                'patch_steps': self.training_stats['patch_steps']
            })
        
        # Patchè®­ç»ƒè¿›åº¦å¯è§†åŒ–
        if self.patch_visualizer and self.current_epoch % 10 == 0:  # æ¯10ä¸ªepochè®°å½•è®­ç»ƒè¿›åº¦
            try:
                current_global_step = self.global_step if hasattr(self, 'trainer') and self.trainer else self.visualization_step
                patch_stats = self.get_training_stats()
                self.patch_visualizer.log_training_progress(
                    step=current_global_step,
                    epoch=self.current_epoch,
                    patch_stats=patch_stats
                )
            except Exception as e:
                print(f"WARNING: Training progress visualization failed: {e}")
        
        # è‡ªé€‚åº”è°ƒæ•´
        current_val_loss = self.trainer.callback_metrics.get('val_loss', float('inf'))
        if current_val_loss < self.training_stats['best_val_loss']:
            self.training_stats['best_val_loss'] = current_val_loss
            self.training_stats['patience_count'] = 0
        else:
            self.training_stats['patience_count'] += 1
    
    def get_training_stats(self) -> Dict[str, Any]:
        """è·å–è®­ç»ƒç»Ÿè®¡ä¿¡æ¯"""
        total_steps = self.training_stats['patch_steps']
        
        # è·å–patchç½‘ç»œæ€§èƒ½ç»Ÿè®¡
        patch_network_stats = {}
        if hasattr(self.student_model, 'get_performance_stats'):
            try:
                patch_network_stats = self.student_model.get_performance_stats()
            except:
                pass
        
        return {
            **self.training_stats,
            'total_steps': total_steps,
            'patch_ratio': 1.0,  # ç°åœ¨åªæœ‰patchæ¨¡å¼
            'patch_mode_count': self.training_stats['patch_steps'],
            'avg_patches_per_image': patch_network_stats.get('avg_patches_per_image', 0),
            'total_patches_generated': patch_network_stats.get('total_patches_processed', 0),
            'cache_hit_rate': 0.0,  # å ä½ç¬¦ï¼Œå®é™…éœ€è¦ä»æ•°æ®é›†è·å–
            'processing_speed': 100.0  # å ä½ç¬¦
        }
    
    def _print_model_architecture_info(self, inpainting_config: Dict[str, Any], patch_inpainting_config) -> None:
        """ NEW: å¯åŠ¨æ—¶è¾“å‡ºæ¨¡å‹æ¶æ„ä¿¡æ¯ï¼Œä¾¿äºéªŒè¯é…ç½®æ­£ç¡®æ€§"""
        print("\n" + "="*70)
        print("ğŸ—ï¸  æ¨¡å‹æ¶æ„é…ç½®ä¿¡æ¯")
        print("="*70)
        
        # åŸºç¡€ç½‘ç»œé…ç½®
        input_channels = inpainting_config.get('input_channels', 7)
        output_channels = inpainting_config.get('output_channels', 3)
        base_channels = inpainting_config.get('base_channels', 64)
        patch_network_channels = patch_inpainting_config.patch_network_channels
        
        print(f" ç½‘ç»œç±»å‹: PatchBasedInpainting (patchè®­ç»ƒæ¡†æ¶)")
        print(f" è¾“å…¥é€šé“æ•°: {input_channels}")
        print(f" è¾“å‡ºé€šé“æ•°: {output_channels}")
        print(f" é…ç½®æ–‡ä»¶base_channels: {base_channels}")
        print(f" å®é™…patch_network_channels: {patch_network_channels}")
        
        # éªŒè¯é…ç½®ä¸€è‡´æ€§
        if base_channels == patch_network_channels:
            print(f" é…ç½®ä¸€è‡´æ€§æ£€æŸ¥: é€šè¿‡ (base_channels = patch_network_channels = {base_channels})")
        else:
            print(f"âš ï¸  é…ç½®ä¸ä¸€è‡´: base_channels={base_channels}, patch_network_channels={patch_network_channels}")
        
        # è¾“å‡ºå…·ä½“çš„PatchNetworkä¿¡æ¯
        if hasattr(self.student_model, 'patch_network'):
            patch_network = self.student_model.patch_network
            total_params = sum(p.numel() for p in patch_network.parameters())
            trainable_params = sum(p.numel() for p in patch_network.parameters() if p.requires_grad)
            
            print(f" PatchNetworkå‚æ•°ç»Ÿè®¡:")
            print(f"   - æ€»å‚æ•°é‡: {total_params:,}")
            print(f"   - å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
            print(f"   - å‚æ•°å¤§å°: {total_params * 4 / 1024 / 1024:.2f} MB")
            
            # å¦‚æœå¯ä»¥è®¿é—®ç½‘ç»œç»“æ„ï¼Œæ˜¾ç¤ºé€šé“é…ç½®
            if hasattr(patch_network, 'ch1'):
                print(f" Enhanced PatchNetworké€šé“æ¶æ„:")
                print(f"   - ch1 (Level 1): {patch_network.ch1}")
                print(f"   - ch2 (Level 2): {patch_network.ch2}")
                print(f"   - ch3 (Level 3): {patch_network.ch3}")
                print(f"   - ch4 (Level 4): {patch_network.ch4}")
                print(f"   - ch5 (Bottleneck): {patch_network.ch5}")
        
        # è®­ç»ƒæ¨¡å¼é…ç½®
        learning_mode = inpainting_config.get('learning_mode', 'residual')
        print(f" å­¦ä¹ æ¨¡å¼: {learning_mode}")
        
        # Patché…ç½®ä¿¡æ¯
        if hasattr(self, 'patch_config'):
            print(f" Patché…ç½®:")
            print(f"   - Patchæ¨¡å¼: {'å¯ç”¨' if self.patch_config.enable_patch_mode else 'ç¦ç”¨'}")
            if hasattr(self.patch_config, 'patch_size'):
                print(f"   - Patchå¤§å°: {self.patch_config.patch_size}x{self.patch_config.patch_size}")
        
        print("="*70 + "\n")
        
        # å¦‚æœå‘ç°é…ç½®é—®é¢˜ï¼Œç»™å‡ºè­¦å‘Š
        if base_channels != 64:
            print("âš ï¸  è­¦å‘Š: base_channelsä¸æ˜¯64ï¼Œå¯èƒ½ä¸é¢„æœŸé…ç½®ä¸ç¬¦")
        if patch_network_channels != 64:
            print("âš ï¸  è­¦å‘Š: patch_network_channelsä¸æ˜¯64ï¼Œè®­ç»ƒçš„æ¨¡å‹å°†æ— æ³•ä¸64é€šé“æ¨ç†è„šæœ¬å…¼å®¹")
        if base_channels != patch_network_channels:
            print("âš ï¸  è­¦å‘Š: base_channelsä¸patch_network_channelsä¸ä¸€è‡´ï¼Œè¯·æ£€æŸ¥é…ç½®")
        
        print("ğŸ’¡ æç¤º: å¦‚æœè¦ä¸ç°æœ‰æ¨ç†è„šæœ¬å…¼å®¹ï¼Œç¡®ä¿ä¸¤ä¸ªé€šé“æ•°éƒ½æ˜¯64")


def create_patch_trainer(model_config: Dict[str, Any],
                        training_config: Dict[str, Any],
                        patch_config: Optional[PatchTrainingConfig] = None,
                        schedule_config: Optional[PatchTrainingScheduleConfig] = None,
                        teacher_model_path: Optional[str] = None,
                        full_config: Optional[Dict[str, Any]] = None) -> PatchFrameInterpolationTrainer:
    """åˆ›å»ºPatchè®­ç»ƒå™¨çš„å·¥å‚å‡½æ•°"""
    
    trainer = PatchFrameInterpolationTrainer(
        model_config=model_config,
        training_config=training_config,
        patch_config=patch_config,
        schedule_config=schedule_config,
        teacher_model_path=teacher_model_path,
        full_config=full_config
    )
    
    # å¦‚æœtraineræœ‰å¯è§†åŒ–ç³»ç»Ÿï¼Œè¾“å‡ºå¯ç”¨çŠ¶æ€
    if hasattr(trainer, 'patch_visualizer') and trainer.patch_visualizer:
        print("SUCCESS: Patch visualization system integrated into training framework")
        print(f"   - å¯è§†åŒ–é¢‘ç‡: æ¯{trainer.patch_visualizer.vis_frequency}æ­¥")
        print(f"   - ä¿å­˜é¢‘ç‡: æ¯{trainer.patch_visualizer.save_frequency}æ­¥")
        print(f"   - æ—¥å¿—ç›®å½•: {trainer.patch_visualizer.log_dir}")
    
    return trainer


def test_patch_training_framework():
    """æµ‹è¯•Patchè®­ç»ƒæ¡†æ¶"""
    # é…ç½®
    model_config = {
        'inpainting_network': {
            'input_channels': 7,
            'output_channels': 3
        }
    }
    
    training_config = {
        'optimizer': {
            'learning_rate': 1e-4,
            'weight_decay': 1e-5
        },
        'scheduler': {
            'T_max': 100,
            'eta_min': 1e-6
        },
        'log_dir': './logs'
    }
    
    # åˆ›å»ºè®­ç»ƒå™¨
    try:
        trainer = create_patch_trainer(
            model_config=model_config,
            training_config=training_config
        )
        
        print("SUCCESS: PatchFrameInterpolationTrainer created successfully")
        print(f"Patchç½‘ç»œå‚æ•°: {sum(p.numel() for p in trainer.student_model.parameters()):,}")
        
        # æµ‹è¯•å‰å‘ä¼ æ’­
        test_input = torch.randn(1, 7, 270, 480)
        with torch.no_grad():
            output = trainer(test_input)
        print(f"å‰å‘ä¼ æ’­æµ‹è¯•: {test_input.shape} -> {output.shape}")
        
        return True
        
    except Exception as e:
        print(f"ERROR: Test failed: {e}")
        return False


def main():
    """ä¸»è®­ç»ƒå‡½æ•° - æ”¯æŒé…ç½®æ–‡ä»¶è®­ç»ƒ"""
    import argparse
    import yaml
    
    parser = argparse.ArgumentParser(description="Patch Training Framework")
    parser.add_argument('--config', type=str, required=True, 
                       help='Configuration file path')
    parser.add_argument('--test-only', action='store_true',
                       help='Run test only without training')
    
    args = parser.parse_args()
    
    if args.test_only:
        # è¿è¡Œæµ‹è¯•æ¨¡å¼
        success = test_patch_training_framework()
        print(f"\n{'SUCCESS: Patch training framework test passed!' if success else 'ERROR: Patch training framework test failed!'}")
        return 0 if success else 1
    
    # è®­ç»ƒæ¨¡å¼ - åŠ è½½é…ç½®æ–‡ä»¶
    try:
        print(f" åŠ è½½é…ç½®æ–‡ä»¶: {args.config}")
        
        if not os.path.exists(args.config):
            print(f" é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {args.config}")
            return 1
        
        with open(args.config, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        
        if config is None:
            print(" é…ç½®æ–‡ä»¶ä¸ºç©ºæˆ–æ ¼å¼é”™è¯¯")
            return 1
        
        print(" é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ")
        
        # å¯åŠ¨å®é™…è®­ç»ƒ
        success = run_patch_training(config)
        return 0 if success else 1
        
    except Exception as e:
        print(f" è®­ç»ƒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1

def run_patch_training(config: Dict[str, Any]) -> bool:
    """è¿è¡ŒPatchè®­ç»ƒæµç¨‹"""
    try:
        print(" å¯åŠ¨Patchè®­ç»ƒæµç¨‹...")
        
        # æå–é…ç½®sections
        network_config = config.get('network', {})
        training_config = config.get('training', {})
        patch_config_dict = config.get('patch', {})
        data_config = config.get('data', {})
        loss_config = config.get('loss', {})
        monitoring_config = config.get('monitoring', {})
        
        print(f" ç½‘ç»œé…ç½®: {network_config.get('type', 'Unknown')}")
        print(f" è®­ç»ƒæ‰¹æ¬¡: {training_config.get('batch_size', 'Unknown')}")
        print(f" Patchæ¨¡å¼: {'å¯ç”¨' if patch_config_dict.get('enable_patch_mode', False) else 'ç¦ç”¨'}")
        print(f" ç®€å•ç½‘æ ¼: {'å¯ç”¨' if patch_config_dict.get('use_simple_grid_patches', False) else 'ç¦ç”¨'}")
        
        # åˆ›å»ºè®­ç»ƒå™¨é…ç½®
        model_config = {
            'inpainting_network': {
                'input_channels': network_config.get('input_channels', 7),
                'output_channels': network_config.get('output_channels', 3),
                'base_channels': network_config.get('base_channels', 24)  #  REVERT: å›é€€åˆ°ç¨³å®šçš„24é€šé“
            }
        }
        
        trainer_config = {
            'optimizer': {
                'learning_rate': training_config.get('learning_rate', 1e-4),
                'weight_decay': training_config.get('weight_decay', 1e-5)
            },
            'scheduler': {
                'T_max': training_config.get('max_epochs', 100),
                'eta_min': 1e-6
            },
            'log_dir': monitoring_config.get('tensorboard_log_dir', './logs/patch_training'),
            'batch_size': training_config.get('batch_size', 4),
            'max_epochs': training_config.get('max_epochs', 100)
        }
        
        # åˆ›å»ºPatché…ç½®
        from patch_aware_dataset import PatchTrainingConfig
        
        patch_training_config = PatchTrainingConfig(
            enable_patch_mode=patch_config_dict.get('enable_patch_mode', True),
            patch_size=patch_config_dict.get('patch_size', 128),
            use_simple_grid_patches=patch_config_dict.get('use_simple_grid_patches', False),
            use_optimized_patches=patch_config_dict.get('use_optimized_patches', True),
            simple_grid_rows=patch_config_dict.get('simple_grid_rows', 4),
            simple_grid_cols=patch_config_dict.get('simple_grid_cols', 4),
            simple_expected_height=patch_config_dict.get('simple_expected_height', 1080),
            simple_expected_width=patch_config_dict.get('simple_expected_width', 1920),
            min_patches_per_image=patch_config_dict.get('min_patches_per_image', 8),
            max_patches_per_image=patch_config_dict.get('max_patches_per_image', 16)
        )
        
        # åˆ›å»ºè®­ç»ƒå™¨
        trainer = create_patch_trainer(
            model_config=model_config,
            training_config=trainer_config,
            patch_config=patch_training_config,
            full_config=config
        )
        
        print(" Patchè®­ç»ƒå™¨åˆ›å»ºæˆåŠŸ")
        print(f" ç½‘ç»œå‚æ•°: {sum(p.numel() for p in trainer.student_model.parameters()):,}")
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        success = setup_data_loaders(trainer, data_config, patch_training_config)
        if not success:
            print(" æ•°æ®åŠ è½½å™¨è®¾ç½®å¤±è´¥")
            return False
        
        # å¼€å§‹è®­ç»ƒ
        print(" å¼€å§‹è®­ç»ƒå¾ªç¯...")
        
        # åˆ›å»ºPyTorch Lightning Trainer
        max_epochs = trainer_config.get('max_epochs', 100)
        
        import pytorch_lightning as pl
        from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping
        from pytorch_lightning.loggers import TensorBoardLogger
        
        # åˆ›å»ºå›è°ƒ
        callbacks = []
        
        # æ¨¡å‹æ£€æŸ¥ç‚¹
        checkpoint_callback = ModelCheckpoint(
            dirpath=monitoring_config.get('model_save_dir', './models/colleague'),
            filename='patch-model-{epoch:02d}-{val_loss:.2f}',
            monitor='val_loss',
            save_top_k=3,
            mode='min',
            save_last=True
        )
        callbacks.append(checkpoint_callback)
        
        # æ—©åœ
        early_stop_callback = EarlyStopping(
            monitor='val_loss',
            patience=10,
            mode='min',
            verbose=True
        )
        # callbacks.append(early_stop_callback)
        
        # TensorBoardæ—¥å¿—è®°å½•å™¨
        tb_logger = TensorBoardLogger(
            save_dir=monitoring_config.get('tensorboard_log_dir', './logs/colleague_training'),
            name='patch_training'
        )
        
        # åˆ›å»ºLightning Trainer
        pl_trainer = pl.Trainer(
            max_epochs=max_epochs,
            logger=tb_logger,
            callbacks=callbacks,
            accelerator='auto',  # è‡ªåŠ¨æ£€æµ‹GPU/CPU
            devices='auto',      # è‡ªåŠ¨æ£€æµ‹è®¾å¤‡æ•°é‡
            precision=32,        # ä½¿ç”¨FP32ç²¾åº¦
            log_every_n_steps=10,
            check_val_every_n_epoch=1,
            gradient_clip_val=1.0,
            enable_progress_bar=True,
            enable_model_summary=True
        )
        
        print(f" Lightning Traineré…ç½®:")
        print(f"   æœ€å¤§è½®æ•°: {max_epochs}")
        print(f"   è®¾å¤‡: {pl_trainer.accelerator} ({pl_trainer.num_devices})")
        print(f"   æ—¥å¿—ç›®å½•: {monitoring_config.get('tensorboard_log_dir', './logs/colleague_training')}")
        print(f"   æ¨¡å‹ä¿å­˜: {monitoring_config.get('model_save_dir', './models/colleague')}")
        
        # å¯åŠ¨è®­ç»ƒ
        print(" å¯åŠ¨PyTorch Lightningè®­ç»ƒ...")
        pl_trainer.fit(
            model=trainer,
            train_dataloaders=trainer.train_loader,
            val_dataloaders=trainer.val_loader
        )
        
        print(" è®­ç»ƒå®Œæˆ!")
        return True
        
    except Exception as e:
        print(f" è®­ç»ƒè¿‡ç¨‹å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

class ColleaguePatchDataset(Dataset):
    """ColleagueDatasetAdapterçš„PatchåŒ…è£…å™¨"""
    
    def __init__(self, data_root: str, split: str, patch_config):
        from colleague_dataset_adapter import ColleagueDatasetAdapter
        
        # åˆ›å»ºåŸºç¡€æ•°æ®é›†
        self.base_dataset = ColleagueDatasetAdapter(
            data_root=data_root,
            split=split,
            augmentation=False
        )
        
        self.patch_config = patch_config
        
        # åˆå§‹åŒ–ç®€å•ç½‘æ ¼æå–å™¨
        if patch_config.use_simple_grid_patches:
            print(" åˆå§‹åŒ–SimplePatchExtractor")
            
            try:
                # å¯¼å…¥å¹¶åˆ›å»ºSimplePatchExtractor
                import sys
                import os
                sys.path.append(os.path.dirname(os.path.dirname(__file__)))
                
                from simple_patch_extractor import SimplePatchExtractor, SimpleGridConfig
                
                simple_config = SimpleGridConfig(
                    grid_rows=patch_config.simple_grid_rows,
                    grid_cols=patch_config.simple_grid_cols,
                    expected_height=patch_config.simple_expected_height,
                    expected_width=patch_config.simple_expected_width,
                    enable_debug_info=False
                )
                
                self.patch_extractor = SimplePatchExtractor(simple_config)
                self._using_simple_grid = True
                
                print(f"    ç½‘æ ¼é…ç½®: {patch_config.simple_grid_rows}x{patch_config.simple_grid_cols} = {patch_config.simple_grid_rows * patch_config.simple_grid_cols} patches")
                
            except ImportError as e:
                print(f" SimplePatchExtractorå¯¼å…¥å¤±è´¥: {e}")
                raise
        else:
            raise NotImplementedError("åªæ”¯æŒç®€å•ç½‘æ ¼ç­–ç•¥")
    
    def __len__(self):
        # æ¯ä¸ªå›¾åƒäº§ç”Ÿå›ºå®šæ•°é‡çš„patch
        return len(self.base_dataset) * self.patch_config.max_patches_per_image
    
    def __getitem__(self, idx):
        # è®¡ç®—æºå›¾åƒç´¢å¼•å’Œpatchç´¢å¼•
        patches_per_image = self.patch_config.max_patches_per_image
        image_idx = idx // patches_per_image
        patch_idx = idx % patches_per_image
        
        try:
            # è·å–æºå›¾åƒæ•°æ® - è¿™åº”è¯¥è¿”å› [C, H, W] æ ¼å¼çš„å¼ é‡
            input_tensor, target_residual, target_rgb = self.base_dataset[image_idx]
            
            # ç¡®ä¿æ•°æ®æ ¼å¼ä¸º [C, H, W]
            if input_tensor.shape != (7, 1080, 1920):
                print(f"  è¾“å…¥æ•°æ®å½¢çŠ¶å¼‚å¸¸: {input_tensor.shape}, æœŸæœ›: (7, 1080, 1920)")
                # å°è¯•ä¿®å¤å½¢çŠ¶
                if len(input_tensor.shape) == 3:
                    if input_tensor.shape[0] == 7:  # [C, H, W] ä½†Hå’ŒWä¸å¯¹
                        # è½¬ç½®æˆ–è€…å…¶ä»–å¤„ç†
                        pass
                    elif input_tensor.shape[2] == 7:  # [H, W, C]
                        input_tensor = input_tensor.permute(2, 0, 1)
                    elif input_tensor.shape[1] == 7:  # [H, C, W] - ä¸å¤ªå¯èƒ½
                        input_tensor = input_tensor.permute(1, 0, 2)
            
            # ç¡®ä¿ç›®æ ‡æ•°æ®ä¹Ÿæ˜¯æ­£ç¡®æ ¼å¼
            if target_residual.shape[0] != 3:
                if len(target_residual.shape) == 3 and target_residual.shape[2] == 3:
                    target_residual = target_residual.permute(2, 0, 1)
            
            if target_rgb.shape[0] != 3:
                if len(target_rgb.shape) == 3 and target_rgb.shape[2] == 3:
                    target_rgb = target_rgb.permute(2, 0, 1)
            
            # è½¬æ¢ä¸ºnumpyç”¨äºpatchæå– - æ³¨æ„ï¼šSimpleGridExtractorå¯èƒ½æœŸæœ›[H, W, C]æ ¼å¼
            # å…ˆå°è¯•ä¼ é€’[C, H, W]æ ¼å¼ï¼Œå¦‚æœå‡ºé”™å†è°ƒæ•´
            input_numpy = input_tensor.numpy()  # [7, 1080, 1920]
            target_residual_numpy = target_residual.numpy()  # [3, 1080, 1920]
            target_rgb_numpy = target_rgb.numpy()  # [3, 1080, 1920]
            
            # æ£€æŸ¥SimplePatchExtractoræœŸæœ›çš„æ ¼å¼
            # å¦‚æœå‡ºç°"Size mismatch"ï¼Œè¯´æ˜extractoræœŸæœ›[H, W, C]æ ¼å¼
            try:
                # å°è¯•ä½¿ç”¨[C, H, W]æ ¼å¼
                input_patches, positions = self.patch_extractor.extract_patches(input_numpy)
            except Exception as shape_error:
                if "Size mismatch" in str(shape_error):
                    # è½¬æ¢ä¸º[H, W, C]æ ¼å¼
                    if idx < 3:
                        print(f"[DEBUG] è½¬æ¢æ•°æ®æ ¼å¼: {input_numpy.shape} -> [H, W, C]")
                    input_numpy = input_numpy.transpose(1, 2, 0)  # [7, 1080, 1920] -> [1080, 1920, 7]
                    target_residual_numpy = target_residual_numpy.transpose(1, 2, 0)  # [3, 1080, 1920] -> [1080, 1920, 3]
                    target_rgb_numpy = target_rgb_numpy.transpose(1, 2, 0)  # [3, 1080, 1920] -> [1080, 1920, 3]
                    
                    # é‡æ–°å°è¯•æå–patches
                    input_patches, positions = self.patch_extractor.extract_patches(input_numpy)
                else:
                    raise shape_error
            
            # æå–ç›®æ ‡patches
            target_residual_patches, _ = self.patch_extractor.extract_patches(target_residual_numpy)
            target_rgb_patches, _ = self.patch_extractor.extract_patches(target_rgb_numpy)
            
            # æ£€æŸ¥patchæ•°é‡
            if patch_idx >= len(input_patches):
                patch_idx = len(input_patches) - 1
            
            # è·å–æŒ‡å®šçš„patch
            patch_input = input_patches[patch_idx]  # numpy array
            patch_target_residual = target_residual_patches[patch_idx]  # numpy array  
            patch_target_rgb = target_rgb_patches[patch_idx]  # numpy array
            
            # ç¡®ä¿patchæ ¼å¼ä¸º[C, H, W]
            if len(patch_input.shape) == 3:
                if patch_input.shape[2] == 7:  # [H, W, C] -> [C, H, W]
                    patch_input = patch_input.transpose(2, 0, 1)
                if patch_target_residual.shape[2] == 3:  # [H, W, C] -> [C, H, W]
                    patch_target_residual = patch_target_residual.transpose(2, 0, 1)
                if patch_target_rgb.shape[2] == 3:  # [H, W, C] -> [C, H, W]
                    patch_target_rgb = patch_target_rgb.transpose(2, 0, 1)
            
            # è½¬æ¢ä¸ºPyTorchå¼ é‡
            patch_input = torch.from_numpy(patch_input).float()
            patch_target_residual = torch.from_numpy(patch_target_residual).float()
            patch_target_rgb = torch.from_numpy(patch_target_rgb).float()
            
            #  UPDATED: å½¢çŠ¶éªŒè¯æ›´æ–°ä¸ºæ”¯æŒéæ­£æ–¹å½¢patch (270x480)
            expected_h, expected_w = 270, 480  # 4x4ç½‘æ ¼åˆ‡åˆ†åçš„patchå°ºå¯¸
            assert patch_input.shape[0] == 7, f"è¾“å…¥patché€šé“æ•°é”™è¯¯: {patch_input.shape[0]} (æœŸæœ›7)"
            assert patch_input.shape[1:] == (expected_h, expected_w), f"è¾“å…¥patchå°ºå¯¸é”™è¯¯: {patch_input.shape[1:]} (æœŸæœ›{expected_h}x{expected_w})"
            assert patch_target_residual.shape[0] == 3, f"æ®‹å·®ç›®æ ‡patché€šé“æ•°é”™è¯¯: {patch_target_residual.shape[0]} (æœŸæœ›3)"
            assert patch_target_residual.shape[1:] == (expected_h, expected_w), f"æ®‹å·®ç›®æ ‡patchå°ºå¯¸é”™è¯¯: {patch_target_residual.shape[1:]} (æœŸæœ›{expected_h}x{expected_w})"
            assert patch_target_rgb.shape[0] == 3, f"RGBç›®æ ‡patché€šé“æ•°é”™è¯¯: {patch_target_rgb.shape[0]} (æœŸæœ›3)"
            assert patch_target_rgb.shape[1:] == (expected_h, expected_w), f"RGBç›®æ ‡patchå°ºå¯¸é”™è¯¯: {patch_target_rgb.shape[1:]} (æœŸæœ›{expected_h}x{expected_w})"
            
            #  FIX: è¿”å›å­—å…¸æ ¼å¼è€Œä¸æ˜¯tupleï¼Œç¬¦åˆPyTorch LightningæœŸæœ›
            return {
                'patch_input': patch_input,
                'patch_target_residual': patch_target_residual,
                'patch_target_rgb': patch_target_rgb
            }
            
        except Exception as e:
            print(f" ColleaguePatchDatasetè·å–æ•°æ®å¤±è´¥ [idx={idx}, image_idx={image_idx}, patch_idx={patch_idx}]: {e}")
            import traceback
            traceback.print_exc()
            
            #  FIX: è¿”å›å­—å…¸æ ¼å¼çš„é›¶å¼ é‡ (270x480å°ºå¯¸)
            expected_h, expected_w = 270, 480  # 4x4ç½‘æ ¼åˆ‡åˆ†åçš„patchå°ºå¯¸
            return {
                'patch_input': torch.zeros(7, expected_h, expected_w),
                'patch_target_residual': torch.zeros(3, expected_h, expected_w),
                'patch_target_rgb': torch.zeros(3, expected_h, expected_w)
            }


def setup_data_loaders(trainer, data_config: Dict[str, Any], patch_config) -> bool:
    """è®¾ç½®æ•°æ®åŠ è½½å™¨"""
    try:
        print(" è®¾ç½®æ•°æ®åŠ è½½å™¨...")
        
        # æ ¹æ®dataset_typeé€‰æ‹©æ•°æ®é›†
        dataset_type = data_config.get('dataset_type', 'colleague')
        
        if dataset_type == 'colleague':
            # ä½¿ç”¨ColleagueDatasetAdapterçš„patchåŒ…è£…å™¨
            from colleague_dataset_adapter import ColleagueDatasetAdapter
            
            print(" ä½¿ç”¨ColleagueDatasetAdapter + ColleaguePatchDataset")
            
            # åˆ›å»ºColleaguePatchDatasetåŒ…è£…å™¨
            train_dataset = ColleaguePatchDataset(
                data_root=data_config.get('data_root', './data'),
                split='train',
                patch_config=patch_config
            )
            
            val_dataset = ColleaguePatchDataset(
                data_root=data_config.get('data_root', './data'),
                split='val',
                patch_config=patch_config
            )
            
            print(f" è®­ç»ƒæ ·æœ¬: {len(train_dataset)} patches")
            print(f" éªŒè¯æ ·æœ¬: {len(val_dataset)} patches")
            
        else:
            print(f" ä¸æ”¯æŒçš„æ•°æ®é›†ç±»å‹: {dataset_type}")
            return False
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨ - ä»æ­£ç¡®çš„é…ç½®ä½ç½®è·å–å‚æ•°
        training_section = trainer.training_config if hasattr(trainer, 'training_config') else {}
        batch_size = training_section.get('batch_size', 4)
        num_workers = 2  # å›ºå®šä¸º2ï¼Œé¿å…å¤šè¿›ç¨‹é—®é¢˜
        
        train_loader = DataLoader(
            train_dataset,
            batch_size=batch_size,
            shuffle=True,
            num_workers=num_workers,
            pin_memory=torch.cuda.is_available(),
            drop_last=True
        )
        
        val_loader = DataLoader(
            val_dataset,
            batch_size=batch_size,
            shuffle=False,
            num_workers=num_workers,
            pin_memory=torch.cuda.is_available(),
            drop_last=False
        )
        
        # è®¾ç½®è®­ç»ƒå™¨çš„æ•°æ®åŠ è½½å™¨
        trainer.train_loader = train_loader
        trainer.val_loader = val_loader
        
        print(" æ•°æ®åŠ è½½å™¨è®¾ç½®å®Œæˆ")
        return True
        
    except Exception as e:
        print(f" æ•°æ®åŠ è½½å™¨è®¾ç½®å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    import sys
    exit_code = main()
    sys.exit(exit_code)