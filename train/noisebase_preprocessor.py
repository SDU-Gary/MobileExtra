#!/usr/bin/env python3
"""
@file noisebase_preprocessor.py
@brief NoiseBaseæ•°æ®é›†é¢„å¤„ç†å™¨

åŠŸèƒ½æè¿°ï¼š
- ä»NoiseBase Zarræ•°æ®ç”Ÿæˆç½‘ç»œè®­ç»ƒæ‰€éœ€çš„6é€šé“è¾“å…¥
- å®ç°å‰å‘warpæŠ•å½±ç”Ÿæˆå¤–æ¨å¸§
- æ£€æµ‹ç©ºæ´å¹¶ç”Ÿæˆé®æŒ¡æ©ç 
- è®¡ç®—æŠ•å½±æ®‹å·®è¿åŠ¨çŸ¢é‡
- è¾“å‡ºé€‚é…MobileInpaintingNetworkçš„è®­ç»ƒæ•°æ®

å¤„ç†æµç¨‹ï¼š
1. åŠ è½½è¿ç»­å¸§çš„NoiseBaseæ•°æ®
2. ä½¿ç”¨è¿åŠ¨çŸ¢é‡è¿›è¡Œå‰å‘warpæŠ•å½±
3. æ£€æµ‹warpåçš„ç©ºæ´åŒºåŸŸ
4. è®¡ç®—æŠ•å½±æ®‹å·®
5. ç”Ÿæˆ6é€šé“è®­ç»ƒæ•°æ®

è¾“å‡ºæ ¼å¼ï¼š
- RGB: åŸå§‹å‚è€ƒå›¾åƒ [3, H, W]
- Mask: ç©ºæ´æ©ç  [1, H, W] 
- ResidualMV: æ®‹å·®è¿åŠ¨çŸ¢é‡ [2, H, W]

@author AIç®—æ³•å›¢é˜Ÿ
@date 2025-07-28
@version 1.0
"""

import os
import sys
import argparse
import numpy as np
import cv2
from pathlib import Path
from typing import Dict, Tuple, List, Optional
import tqdm

# å¯¼å…¥å…¼å®¹æ€§æ¨¡å—
try:
    # å°è¯•ç›¸å¯¹å¯¼å…¥
    from .zarr_compat import load_zarr_group, decompress_RGBE_compat as decompress_RGBE
    from .projective import screen_space_position, motion_vectors, log_depth
except ImportError:
    # å°è¯•ä»å½“å‰ç›®å½•å¯¼å…¥
    import sys
    from pathlib import Path
    
    # æ·»åŠ trainingç›®å½•åˆ°Pythonè·¯å¾„
    training_dir = Path(__file__).parent
    if str(training_dir) not in sys.path:
        sys.path.insert(0, str(training_dir))
    
    from zarr_compat import load_zarr_group, decompress_RGBE_compat as decompress_RGBE
    from projective import screen_space_position, motion_vectors, log_depth


class NoiseBasePreprocessor:
    """
    NoiseBaseæ•°æ®é›†é¢„å¤„ç†å™¨
    
    å°†NoiseBaseçš„Zarræ ¼å¼æ•°æ®è½¬æ¢ä¸ºé€‚åˆMobileInpaintingNetworkè®­ç»ƒçš„æ ¼å¼
    """
    
    def __init__(self, 
                 input_dir: str,
                 output_dir: str,
                 scene_name: str = "bistro1"):
        """
        åˆå§‹åŒ–é¢„å¤„ç†å™¨
        
        Args:
            input_dir: NoiseBaseæ•°æ®è¾“å…¥ç›®å½•
            output_dir: å¤„ç†åæ•°æ®è¾“å‡ºç›®å½•  
            scene_name: åœºæ™¯åç§°
        """
        self.input_dir = Path(input_dir)
        self.output_dir = Path(output_dir)
        self.scene_name = scene_name
        
        # åˆ›å»ºè¾“å‡ºç›®å½•ç»“æ„
        self.setup_output_dirs()
        
        # Warpå‚æ•°
        self.warp_method = 'forward_projection'  # å‰å‘æŠ•å½±æ–¹æ³•
        self.hole_threshold = 0.5  # ç©ºæ´æ£€æµ‹é˜ˆå€¼
        self.residual_threshold = 2.0  # æ®‹å·®é˜ˆå€¼
        
        print(f"=== NoiseBase Preprocessor ===")
        print(f"Input: {self.input_dir}")
        print(f"Output: {self.output_dir}")
        print(f"Scene: {scene_name}")
    
    def setup_output_dirs(self):
        """åˆ›å»ºè¾“å‡ºç›®å½•ç»“æ„"""
        dirs = [
            'rgb',           # åŸå§‹RGBå›¾åƒ
            'warped',        # Warpåçš„å›¾åƒ
            'masks',         # ç©ºæ´æ©ç 
            'residual_mv',   # æ®‹å·®è¿åŠ¨çŸ¢é‡
            'training_data', # æœ€ç»ˆè®­ç»ƒæ•°æ®
            'visualization'  # å¯è§†åŒ–ç»“æœ
        ]
        
        for dir_name in dirs:
            (self.output_dir / self.scene_name / dir_name).mkdir(parents=True, exist_ok=True)
    
    def load_frame_data(self, frame_idx: int) -> Dict:
        """
        åŠ è½½å•å¸§NoiseBaseæ•°æ®
        
        Args:
            frame_idx: å¸§ç´¢å¼•
        
        Returns:
            frame_data: å¸§æ•°æ®å­—å…¸
        """
        zip_path = self.input_dir / self.scene_name / f"frame{frame_idx:04d}.zip"
        
        if not zip_path.exists():
            raise FileNotFoundError(f"Frame data not found: {zip_path}")
        
        try:
            # åŠ è½½Zarræ•°æ®ï¼ˆä½¿ç”¨å…¼å®¹æ€§å‡½æ•°ï¼‰
            ds = load_zarr_group(str(zip_path))
            
            # æ£€æŸ¥å¹¶æå–å„ç§ç¼“å†²åŒºæ•°æ®
            def safe_extract_array(group, key, description):
                """å®‰å…¨æå–æ•°ç»„æ•°æ®"""
                try:
                    # æ–¹æ³•1: å°è¯•ä½œä¸ºå±æ€§è®¿é—®
                    if hasattr(group, key):
                        return np.array(getattr(group, key))
                    
                    # æ–¹æ³•2: å°è¯•ä½œä¸ºå­—å…¸é”®è®¿é—®
                    if hasattr(group, '__getitem__') and key in group:
                        return np.array(group[key])
                    
                    # æ–¹æ³•3: å°è¯•ç›´æ¥ç´¢å¼•è®¿é—®
                    try:
                        return np.array(group[key])
                    except (KeyError, TypeError):
                        pass
                    
                    # å¦‚æœéƒ½å¤±è´¥ï¼Œåˆ—å‡ºå¯ç”¨é”®
                    available_keys = []
                    if hasattr(group, 'keys'):
                        available_keys = list(group.keys())
                    elif hasattr(group, '__dict__'):
                        available_keys = [k for k in group.__dict__.keys() if not k.startswith('_')]
                    
                    raise KeyError(f"{description} ('{key}') not found. Available: {available_keys}")
                    
                except Exception as e:
                    raise RuntimeError(f"Failed to extract {description}: {e}")
        
        except Exception as e:
            raise RuntimeError(f"Error loading frame {frame_idx}: {e}")
        
        color_rgbe = safe_extract_array(ds, 'color', 'RGBEæ ¼å¼é¢œè‰²')
        diffuse = safe_extract_array(ds, 'diffuse', 'æ¼«åå°„')
        normal = safe_extract_array(ds, 'normal', 'æ³•çº¿')
        motion = safe_extract_array(ds, 'motion', 'ä¸–ç•Œç©ºé—´è¿åŠ¨çŸ¢é‡')
        position = safe_extract_array(ds, 'position', 'ä¸–ç•Œç©ºé—´ä½ç½®')
        reference = safe_extract_array(ds, 'reference', 'Ground Truthå‚è€ƒå›¾åƒ')
        
        # ç›¸æœºå‚æ•°
        camera_pos = safe_extract_array(ds, 'camera_position', 'ç›¸æœºä½ç½®')
        view_proj_mat = safe_extract_array(ds, 'view_proj_mat', 'è§†å›¾æŠ•å½±çŸ©é˜µ')
        exposure = safe_extract_array(ds, 'exposure', 'æ›å…‰å‚æ•°')
        
        # è§£å‹ç¼©é¢œè‰²æ•°æ®
        rgb_color = decompress_RGBE(color_rgbe, exposure)
        
        # å¯¹Monte Carloæ ·æœ¬æ±‚å¹³å‡çš„å®‰å…¨å‡½æ•°
        def safe_mean_samples(arr, name):
            """å®‰å…¨åœ°å¯¹æ ·æœ¬ç»´åº¦æ±‚å¹³å‡"""
            if arr.ndim == 4 and arr.shape[3] > 1:
                # æœ‰æ ·æœ¬ç»´åº¦ï¼Œæ±‚å¹³å‡
                result = arr.mean(axis=3)
                print(f"   {name}: {arr.shape} -> {result.shape} (å¹³å‡)")
                return result
            elif arr.ndim == 4 and arr.shape[3] == 1:
                # åªæœ‰ä¸€ä¸ªæ ·æœ¬ï¼Œç§»é™¤ç»´åº¦
                result = arr.squeeze(axis=3)
                print(f"   {name}: {arr.shape} -> {result.shape} (squeeze)")
                return result
            elif arr.ndim == 3:
                # æ²¡æœ‰æ ·æœ¬ç»´åº¦ï¼Œç›´æ¥ä½¿ç”¨
                print(f"   {name}: {arr.shape} (ç›´æ¥ä½¿ç”¨)")
                return arr
            else:
                print(f"   {name}: æœªé¢„æœŸçš„å½¢çŠ¶ {arr.shape}")
                return arr
        
        rgb_avg = safe_mean_samples(rgb_color, 'rgb_color')
        reference_avg = safe_mean_samples(reference, 'reference')
        motion_avg = safe_mean_samples(motion, 'motion')
        position_avg = safe_mean_samples(position, 'position')
        normal_avg = safe_mean_samples(normal, 'normal')
        diffuse_avg = safe_mean_samples(diffuse, 'diffuse')
        
        return {
            'rgb': rgb_avg,
            'reference': reference_avg,
            'motion': motion_avg,
            'position': position_avg,
            'normal': normal_avg,
            'diffuse': diffuse_avg,
            'camera_pos': camera_pos,
            'view_proj_mat': view_proj_mat,
            'frame_idx': frame_idx
        }
    
    def compute_screen_motion_vectors(self, 
                                    curr_frame: Dict, 
                                    prev_frame: Dict) -> np.ndarray:
        """
        è®¡ç®—å±å¹•ç©ºé—´è¿åŠ¨çŸ¢é‡
        
        Args:
            curr_frame: å½“å‰å¸§æ•°æ®
            prev_frame: å‰ä¸€å¸§æ•°æ®
        
        Returns:
            screen_mv: å±å¹•ç©ºé—´è¿åŠ¨çŸ¢é‡ [2, H, W]
        """
        # è·å–ä½ç½®å’Œè¿åŠ¨æ•°æ®
        curr_position = curr_frame['position']
        curr_motion = curr_frame['motion']
        
        # ç¡®ä¿æ•°æ®æœ‰æ ·æœ¬ç»´åº¦ (projective.pyæœŸæœ›3HWSæ ¼å¼)
        if curr_position.ndim == 3:
            # æ·»åŠ æ ·æœ¬ç»´åº¦ [3, H, W] -> [3, H, W, 1]
            curr_position = curr_position[..., np.newaxis]
        if curr_motion.ndim == 3:
            # æ·»åŠ æ ·æœ¬ç»´åº¦ [3, H, W] -> [3, H, W, 1]
            curr_motion = curr_motion[..., np.newaxis]
        
        height, width = curr_position.shape[1:3]
        
        # ä½¿ç”¨projective.pyä¸­çš„å‡½æ•°è®¡ç®—è¿åŠ¨çŸ¢é‡
        screen_mv = motion_vectors(
            w_position=curr_position,
            w_motion=curr_motion,
            pv=curr_frame['view_proj_mat'],
            prev_pv=prev_frame['view_proj_mat'],
            height=height,
            width=width
        )
        
        # ç§»é™¤æ ·æœ¬ç»´åº¦å¹¶è¿”å› [2, H, W, 1] -> [2, H, W]
        if screen_mv.ndim == 4 and screen_mv.shape[3] == 1:
            screen_mv = screen_mv.squeeze(axis=3)
        
        return screen_mv
    
    def forward_warp(self, 
                    source_image: np.ndarray,
                    motion_vectors: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """
        å‘é‡åŒ–çš„å‰å‘warpæŠ•å½±ï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼‰
        
        Args:
            source_image: æºå›¾åƒ [3, H, W]
            motion_vectors: è¿åŠ¨çŸ¢é‡ [2, H, W]
        
        Returns:
            warped_image: warpåå›¾åƒ [3, H, W]
            coverage_mask: è¦†ç›–æ©ç  [H, W] (1=æœ‰æ•ˆ, 0=ç©ºæ´)
        """
        C, H, W = source_image.shape
        
        # åˆå§‹åŒ–è¾“å‡º
        warped_image = np.zeros_like(source_image)
        coverage_mask = np.zeros((H, W), dtype=np.float32)
        
        # åˆ›å»ºåæ ‡ç½‘æ ¼
        y_coords, x_coords = np.meshgrid(np.arange(H), np.arange(W), indexing='ij')
        
        # è®¡ç®—ç›®æ ‡ä½ç½®
        target_x = x_coords + motion_vectors[0]  # [H, W]
        target_y = y_coords + motion_vectors[1]  # [H, W]
        
        # æœ‰æ•ˆåƒç´ æ©ç 
        valid_mask = (
            (target_x >= 0) & (target_x < W-1) &
            (target_y >= 0) & (target_y < H-1)
        )
        
        if not np.any(valid_mask):
            return warped_image, coverage_mask
        
        # æå–æœ‰æ•ˆåƒç´ 
        valid_y, valid_x = np.where(valid_mask)
        valid_target_x = target_x[valid_mask]
        valid_target_y = target_y[valid_mask]
        
        # åŒçº¿æ€§æ’å€¼çš„å››ä¸ªé‚»å±…
        x0 = np.floor(valid_target_x).astype(int)
        y0 = np.floor(valid_target_y).astype(int)
        x1 = x0 + 1
        y1 = y0 + 1
        
        # ç¡®ä¿åœ¨è¾¹ç•Œå†…
        boundary_mask = (x1 < W) & (y1 < H)
        if not np.any(boundary_mask):
            return warped_image, coverage_mask
        
        # è¿‡æ»¤è¾¹ç•Œå¤–çš„ç‚¹
        valid_y = valid_y[boundary_mask]
        valid_x = valid_x[boundary_mask]
        valid_target_x = valid_target_x[boundary_mask]
        valid_target_y = valid_target_y[boundary_mask]
        x0, y0, x1, y1 = x0[boundary_mask], y0[boundary_mask], x1[boundary_mask], y1[boundary_mask]
        
        # åŒçº¿æ€§æƒé‡
        wx = valid_target_x - x0
        wy = valid_target_y - y0
        
        weights = [
            (1-wx) * (1-wy),  # (x0, y0)
            wx * (1-wy),      # (x1, y0)
            (1-wx) * wy,      # (x0, y1)
            wx * wy           # (x1, y1)
        ]
        
        positions = [(x0, y0), (x1, y0), (x0, y1), (x1, y1)]
        
        # å‘é‡åŒ–åˆ†å¸ƒåƒç´ å€¼
        for (px, py), weight in zip(positions, weights):
            valid_weight_mask = weight > 1e-6
            if np.any(valid_weight_mask):
                # ä½¿ç”¨np.add.atè¿›è¡ŒåŸå­ç´¯åŠ 
                for c in range(C):
                    np.add.at(warped_image[c], (py[valid_weight_mask], px[valid_weight_mask]), 
                             source_image[c, valid_y[valid_weight_mask], valid_x[valid_weight_mask]] * weight[valid_weight_mask])
                np.add.at(coverage_mask, (py[valid_weight_mask], px[valid_weight_mask]), weight[valid_weight_mask])
        
        # å½’ä¸€åŒ–
        valid_pixels = coverage_mask > 1e-6
        for c in range(C):
            warped_image[c, valid_pixels] /= coverage_mask[valid_pixels]
        
        # ç”ŸæˆäºŒå€¼è¦†ç›–æ©ç 
        coverage_mask = (coverage_mask > self.hole_threshold).astype(np.float32)
        
        return warped_image, coverage_mask
    
    def detect_holes_and_occlusion(self,
                                 warped_image: np.ndarray,
                                 target_image: np.ndarray,
                                 coverage_mask: np.ndarray,
                                 curr_frame: Dict,
                                 prev_frame: Dict) -> Tuple[np.ndarray, np.ndarray]:
        """
        åˆ†åˆ«æ£€æµ‹ç©ºæ´å’Œé®æŒ¡æ©ç 
        
        Args:
            warped_image: warpåå›¾åƒ [3, H, W]
            target_image: ç›®æ ‡å›¾åƒ [3, H, W]
            coverage_mask: è¦†ç›–æ©ç  [H, W]
            curr_frame: å½“å‰å¸§æ•°æ®
            prev_frame: å‰ä¸€å¸§æ•°æ®
        
        Returns:
            hole_mask: ç©ºæ´æ©ç  [H, W] (1=ç©ºæ´, 0=æœ‰æ•ˆ)
            occlusion_mask: é®æŒ¡æ©ç  [H, W] (1=é®æŒ¡, 0=æ— é®æŒ¡)
        """
        H, W = coverage_mask.shape
        
        # === æ–¹æ³•1: å‡ ä½•ç©ºæ´æ£€æµ‹ ===
        # åŸºäºè¦†ç›–åº¦çš„çº¯å‡ ä½•ç©ºæ´
        hole_mask = (coverage_mask < self.hole_threshold).astype(np.float32)
        
        # å½¢æ€å­¦å¤„ç†ä¼˜åŒ–ç©ºæ´æ©ç 
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
        hole_mask = cv2.morphologyEx(hole_mask, cv2.MORPH_CLOSE, kernel)
        hole_mask = cv2.morphologyEx(hole_mask, cv2.MORPH_OPEN, kernel)
        
        # === æ–¹æ³•2: é®æŒ¡æ£€æµ‹ ===
        occlusion_mask = self.detect_occlusion_mask(curr_frame, prev_frame)
        
        return hole_mask, occlusion_mask
    
    def detect_occlusion_mask(self, curr_frame: Dict, prev_frame: Dict) -> np.ndarray:
        """
        åŸºäºæ·±åº¦å’Œå‡ ä½•å…³ç³»æ£€æµ‹é®æŒ¡æ©ç 
        
        Args:
            curr_frame: å½“å‰å¸§æ•°æ®
            prev_frame: å‰ä¸€å¸§æ•°æ®
            
        Returns:
            occlusion_mask: é®æŒ¡æ©ç  [H, W]
        """
        H, W = curr_frame['position'].shape[1:3]
        
        # è·å–æ·±åº¦ä¿¡æ¯ï¼ˆä»ä¸–ç•Œç©ºé—´ä½ç½®è®¡ç®—ï¼‰
        curr_depth = self.compute_depth_from_position(
            curr_frame['position'], curr_frame['camera_pos']
        )
        prev_depth = self.compute_depth_from_position(
            prev_frame['position'], prev_frame['camera_pos']
        )
        
        # æ–¹æ³•1: åŸºäºæ·±åº¦ä¸è¿ç»­æ€§æ£€æµ‹é®æŒ¡
        depth_gradient = np.gradient(curr_depth)
        depth_discontinuity = np.sqrt(depth_gradient[0]**2 + depth_gradient[1]**2)
        depth_occlusion = (depth_discontinuity > np.percentile(depth_discontinuity, 95))
        
        # æ–¹æ³•2: åŸºäºè¿åŠ¨ä¸ä¸€è‡´æ€§æ£€æµ‹é®æŒ¡
        # è®¡ç®—ç›¸é‚»åƒç´ çš„è¿åŠ¨çŸ¢é‡å·®å¼‚
        motion_x = curr_frame['motion'][0]
        motion_y = curr_frame['motion'][1]
        
        motion_grad_x = np.gradient(motion_x)
        motion_grad_y = np.gradient(motion_y)
        motion_discontinuity = np.sqrt(
            motion_grad_x[0]**2 + motion_grad_x[1]**2 + 
            motion_grad_y[0]**2 + motion_grad_y[1]**2
        )
        motion_occlusion = (motion_discontinuity > np.percentile(motion_discontinuity, 90))
        
        # ç»“åˆä¸¤ç§æ–¹æ³•
        occlusion_mask = (depth_occlusion | motion_occlusion).astype(np.float32)
        
        # å½¢æ€å­¦å¤„ç†
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
        occlusion_mask = cv2.morphologyEx(occlusion_mask, cv2.MORPH_CLOSE, kernel)
        occlusion_mask = cv2.morphologyEx(occlusion_mask, cv2.MORPH_OPEN, kernel)
        
        return occlusion_mask
    
    def compute_depth_from_position(self, world_position: np.ndarray, camera_pos: np.ndarray) -> np.ndarray:
        """
        ä»ä¸–ç•Œç©ºé—´ä½ç½®è®¡ç®—æ·±åº¦
        
        Args:
            world_position: ä¸–ç•Œç©ºé—´ä½ç½® [3, H, W]
            camera_pos: ç›¸æœºä½ç½® [3]
            
        Returns:
            depth: æ·±åº¦å›¾ [H, W]
        """
        # è®¡ç®—åˆ°ç›¸æœºçš„è·ç¦»ä½œä¸ºæ·±åº¦
        diff = world_position - camera_pos.reshape(3, 1, 1)
        depth = np.linalg.norm(diff, axis=0)
        return depth
    
    def compute_residual_motion_vectors(self,
                                      warped_image: np.ndarray,
                                      target_image: np.ndarray,
                                      coverage_mask: np.ndarray,
                                      motion_vectors: np.ndarray,
                                      hole_mask: np.ndarray) -> np.ndarray:
        """
        è®¡ç®—æ®‹å·®è¿åŠ¨çŸ¢é‡
        
        Args:
            warped_image: warpåå›¾åƒ [3, H, W]
            target_image: ç›®æ ‡å›¾åƒ [3, H, W]
            coverage_mask: è¦†ç›–æ©ç  [H, W]
            motion_vectors: åŸå§‹è¿åŠ¨çŸ¢é‡ [2, H, W]
            hole_mask: ç©ºæ´æ©ç  [H, W]
        
        Returns:
            residual_mv: æ®‹å·®è¿åŠ¨çŸ¢é‡ [2, H, W]
        """
        residual_mv = np.zeros_like(motion_vectors)
        
        # å¯¹äºæœ‰æ•ˆåŒºåŸŸï¼ˆéç©ºæ´ï¼‰ï¼Œè®¡ç®—warpè¯¯å·®
        valid_mask = (coverage_mask > self.hole_threshold) & (hole_mask < 0.5)
        if np.any(valid_mask):
            # åŸºäºé¢œè‰²å·®å¼‚è®¡ç®—æ®‹å·®
            color_error = np.linalg.norm(warped_image - target_image, axis=0)
            error_factor = np.clip(color_error / self.residual_threshold, 0, 1)
            
            # æ®‹å·®è¿åŠ¨çŸ¢é‡ä¸è¯¯å·®æˆæ¯”ä¾‹
            residual_mv[0][valid_mask] = motion_vectors[0][valid_mask] * error_factor[valid_mask] * 0.1
            residual_mv[1][valid_mask] = motion_vectors[1][valid_mask] * error_factor[valid_mask] * 0.1
        
        return residual_mv
    
    def create_training_sample(self,
                             rgb_image: np.ndarray,
                             hole_mask: np.ndarray,
                             occlusion_mask: np.ndarray,
                             residual_mv: np.ndarray) -> np.ndarray:
        """
        åˆ›å»º7é€šé“è®­ç»ƒæ ·æœ¬
        
        Args:
            rgb_image: RGBå›¾åƒ [3, H, W]  
            hole_mask: ç©ºæ´æ©ç  [H, W]
            occlusion_mask: é®æŒ¡æ©ç  [H, W]
            residual_mv: æ®‹å·®è¿åŠ¨çŸ¢é‡ [2, H, W]
        
        Returns:
            training_sample: 7é€šé“è®­ç»ƒæ•°æ® [7, H, W]
        """
        # æ‹¼æ¥7é€šé“æ•°æ®ï¼šRGB(3) + HoleMask(1) + OcclusionMask(1) + ResidualMV(2)
        training_sample = np.concatenate([
            rgb_image,                              # RGBé€šé“ [3, H, W]
            hole_mask[np.newaxis, :, :],           # ç©ºæ´æ©ç é€šé“ [1, H, W]  
            occlusion_mask[np.newaxis, :, :],      # é®æŒ¡æ©ç é€šé“ [1, H, W]
            residual_mv                            # æ®‹å·®MVé€šé“ [2, H, W]
        ], axis=0)
        
        return training_sample
    
    def save_frame_results(self, 
                          frame_idx: int,
                          rgb_image: np.ndarray,
                          warped_image: np.ndarray,
                          hole_mask: np.ndarray,
                          occlusion_mask: np.ndarray,
                          residual_mv: np.ndarray,
                          training_sample: np.ndarray):
        """
        ä¿å­˜å¸§å¤„ç†ç»“æœ
        
        Args:
            frame_idx: å¸§ç´¢å¼•
            rgb_image: åŸå§‹RGBå›¾åƒ
            warped_image: warpåå›¾åƒ
            hole_mask: ç©ºæ´æ©ç 
            occlusion_mask: é®æŒ¡æ©ç 
            residual_mv: æ®‹å·®è¿åŠ¨çŸ¢é‡
            training_sample: è®­ç»ƒæ ·æœ¬
        """
        base_path = self.output_dir / self.scene_name
        
        # è½¬æ¢ä¸ºå¯ä¿å­˜æ ¼å¼ (CHW -> HWC, å½’ä¸€åŒ–åˆ°[0,1])
        def prepare_for_save(img, is_mask=False):
            if len(img.shape) == 3:
                img = img.transpose(1, 2, 0)  # CHW -> HWC
            if not is_mask:
                img = np.clip((img + 1) / 2, 0, 1)  # [-1,1] -> [0,1]
            return (img * 255).astype(np.uint8)
        
        # ä¿å­˜å„ç§æ•°æ®
        frame_name = f"frame_{frame_idx:04d}"
        
        # RGBå›¾åƒ
        rgb_save = prepare_for_save(rgb_image)
        cv2.imwrite(str(base_path / 'rgb' / f"{frame_name}.png"), 
                   cv2.cvtColor(rgb_save, cv2.COLOR_RGB2BGR))
        
        # Warpåå›¾åƒ
        warped_save = prepare_for_save(warped_image)
        cv2.imwrite(str(base_path / 'warped' / f"{frame_name}.png"),
                   cv2.cvtColor(warped_save, cv2.COLOR_RGB2BGR))
        
        # ç©ºæ´æ©ç 
        hole_mask_save = (hole_mask * 255).astype(np.uint8)
        cv2.imwrite(str(base_path / 'masks' / f"{frame_name}_holes.png"), hole_mask_save)
        
        # é®æŒ¡æ©ç 
        occlusion_mask_save = (occlusion_mask * 255).astype(np.uint8)
        cv2.imwrite(str(base_path / 'masks' / f"{frame_name}_occlusion.png"), occlusion_mask_save)
        
        # æ®‹å·®è¿åŠ¨çŸ¢é‡ï¼ˆä¿å­˜ä¸ºNumPyæ•°ç»„ï¼‰
        np.save(str(base_path / 'residual_mv' / f"{frame_name}.npy"), residual_mv)
        
        # è®­ç»ƒæ ·æœ¬ï¼ˆä¿å­˜ä¸ºNumPyæ•°ç»„ï¼‰
        np.save(str(base_path / 'training_data' / f"{frame_name}.npy"), training_sample)
        
        # å¯è§†åŒ–ç»“æœ
        self.create_visualization(frame_idx, rgb_image, warped_image, hole_mask, occlusion_mask, residual_mv)
    
    def create_visualization(self,
                           frame_idx: int,
                           rgb_image: np.ndarray,
                           warped_image: np.ndarray, 
                           hole_mask: np.ndarray,
                           occlusion_mask: np.ndarray,
                           residual_mv: np.ndarray):
        """
        åˆ›å»ºå¯è§†åŒ–ç»“æœ
        
        Args:
            frame_idx: å¸§ç´¢å¼•
            rgb_image: åŸå§‹å›¾åƒ
            warped_image: warpåå›¾åƒ
            hole_mask: ç©ºæ´æ©ç 
            occlusion_mask: é®æŒ¡æ©ç 
            residual_mv: æ®‹å·®è¿åŠ¨çŸ¢é‡
        """
        import matplotlib.pyplot as plt
        
        fig, axes = plt.subplots(2, 4, figsize=(20, 10))
        
        # åŸå§‹å›¾åƒ
        rgb_vis = np.clip((rgb_image.transpose(1, 2, 0) + 1) / 2, 0, 1)
        axes[0, 0].imshow(rgb_vis)
        axes[0, 0].set_title('Original RGB')
        axes[0, 0].axis('off')
        
        # Warpåå›¾åƒ
        warped_vis = np.clip((warped_image.transpose(1, 2, 0) + 1) / 2, 0, 1)
        axes[0, 1].imshow(warped_vis)
        axes[0, 1].set_title('Warped Image')
        axes[0, 1].axis('off')
        
        # ç©ºæ´æ©ç 
        axes[0, 2].imshow(hole_mask, cmap='gray')
        axes[0, 2].set_title('Hole Mask')
        axes[0, 2].axis('off')
        
        # é®æŒ¡æ©ç 
        axes[0, 3].imshow(occlusion_mask, cmap='gray')
        axes[0, 3].set_title('Occlusion Mask')
        axes[0, 3].axis('off')
        
        # æ®‹å·®è¿åŠ¨çŸ¢é‡å¯è§†åŒ–
        mv_magnitude = np.sqrt(residual_mv[0]**2 + residual_mv[1]**2)
        axes[1, 0].imshow(mv_magnitude, cmap='jet')
        axes[1, 0].set_title('Residual MV Magnitude')
        axes[1, 0].axis('off')
        
        # è¿åŠ¨çŸ¢é‡æ–¹å‘
        mv_angle = np.arctan2(residual_mv[1], residual_mv[0])
        axes[1, 1].imshow(mv_angle, cmap='hsv')
        axes[1, 1].set_title('Residual MV Direction')
        axes[1, 1].axis('off')
        
        # ç©ºæ´è¦†ç›–ç»“æœ
        hole_overlay = rgb_vis.copy()
        hole_overlay[hole_mask > 0.5] = [1, 0, 0]  # çº¢è‰²æ ‡è®°ç©ºæ´
        axes[1, 2].imshow(hole_overlay)
        axes[1, 2].set_title('Holes Overlay')
        axes[1, 2].axis('off')
        
        # é®æŒ¡è¦†ç›–ç»“æœ
        occlusion_overlay = rgb_vis.copy()
        occlusion_overlay[occlusion_mask > 0.5] = [0, 1, 0]  # ç»¿è‰²æ ‡è®°é®æŒ¡
        axes[1, 3].imshow(occlusion_overlay)
        axes[1, 3].set_title('Occlusion Overlay')
        axes[1, 3].axis('off')
        
        plt.tight_layout()
        
        vis_path = self.output_dir / self.scene_name / 'visualization' / f"vis_{frame_idx:04d}.png"
        plt.savefig(str(vis_path), dpi=150, bbox_inches='tight')
        plt.close()
    
    def process_frame_pair(self, curr_idx: int, prev_idx: int):
        """
        å¤„ç†å¸§å¯¹
        
        Args:
            curr_idx: å½“å‰å¸§ç´¢å¼•
            prev_idx: å‰ä¸€å¸§ç´¢å¼•
        """
        # åŠ è½½è¿ç»­ä¸¤å¸§æ•°æ®
        curr_frame = self.load_frame_data(curr_idx)
        prev_frame = self.load_frame_data(prev_idx)
        
        # è®¡ç®—å±å¹•ç©ºé—´è¿åŠ¨çŸ¢é‡
        screen_mv = self.compute_screen_motion_vectors(curr_frame, prev_frame)
        
        # å‰å‘warpæŠ•å½±
        warped_image, coverage_mask = self.forward_warp(
            curr_frame['reference'], screen_mv
        )
        
        # åˆ†åˆ«æ£€æµ‹ç©ºæ´å’Œé®æŒ¡æ©ç 
        hole_mask, occlusion_mask = self.detect_holes_and_occlusion(
            warped_image, curr_frame['reference'], coverage_mask, curr_frame, prev_frame
        )
        
        # è®¡ç®—æ®‹å·®è¿åŠ¨çŸ¢é‡
        residual_mv = self.compute_residual_motion_vectors(
            warped_image, curr_frame['reference'], coverage_mask, screen_mv, hole_mask
        )
        
        # åˆ›å»ºè®­ç»ƒæ ·æœ¬
        training_sample = self.create_training_sample(
            curr_frame['reference'], hole_mask, occlusion_mask, residual_mv
        )
        
        # ä¿å­˜ç»“æœ
        self.save_frame_results(
            curr_idx, curr_frame['reference'], warped_image, 
            hole_mask, occlusion_mask, residual_mv, training_sample
        )
        
        return {
            'frame_idx': curr_idx,
            'hole_coverage': np.mean(hole_mask),
            'occlusion_coverage': np.mean(occlusion_mask),
            'mv_magnitude': np.mean(np.sqrt(residual_mv[0]**2 + residual_mv[1]**2))
        }
    
    def process_sequence(self, start_frame: int = 0, end_frame: int = None):
        """
        å¤„ç†æ•´ä¸ªåºåˆ—
        
        Args:
            start_frame: èµ·å§‹å¸§
            end_frame: ç»“æŸå¸§
        """
        # ç¡®å®šå¤„ç†èŒƒå›´
        if end_frame is None:
            # è‡ªåŠ¨æ£€æµ‹å¯ç”¨å¸§æ•°
            frame_count = 0
            while (self.input_dir / self.scene_name / f"frame{frame_count:04d}.zip").exists():
                frame_count += 1
            end_frame = frame_count - 1
        
        print(f"Processing frames {start_frame} to {end_frame} ({end_frame-start_frame+1} total)")
        
        # å¤„ç†ç»Ÿè®¡
        stats = {
            'processed_frames': 0,
            'total_hole_coverage': 0,
            'total_mv_magnitude': 0
        }
        
        # é€å¸§å¤„ç†
        with tqdm.tqdm(total=end_frame-start_frame, desc="Processing frames") as pbar:
            for i in range(start_frame + 1, end_frame + 1):  # ä»ç¬¬äºŒå¸§å¼€å§‹
                try:
                    result = self.process_frame_pair(i, i-1)
                    
                    # æ›´æ–°ç»Ÿè®¡
                    stats['processed_frames'] += 1
                    stats['total_hole_coverage'] += result['hole_coverage']
                    stats['total_mv_magnitude'] += result['mv_magnitude']
                    
                    pbar.set_postfix({
                        'Holes': f"{result['hole_coverage']:.3f}",
                        'MV': f"{result['mv_magnitude']:.3f}"
                    })
                    
                except Exception as e:
                    print(f"Error processing frame {i}: {e}")
                
                pbar.update(1)
        
        # æ‰“å°æœ€ç»ˆç»Ÿè®¡
        if stats['processed_frames'] > 0:
            avg_hole_coverage = stats['total_hole_coverage'] / stats['processed_frames']
            avg_mv_magnitude = stats['total_mv_magnitude'] / stats['processed_frames']
            
            print(f"\n=== Processing Statistics ===")
            print(f"Processed frames: {stats['processed_frames']}")
            print(f"Average hole coverage: {avg_hole_coverage:.3f}")
            print(f"Average MV magnitude: {avg_mv_magnitude:.3f}")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='NoiseBase Preprocessor')
    parser.add_argument('--input-dir', type=str, required=True,
                       help='NoiseBase data directory')
    parser.add_argument('--output-dir', type=str, required=True,
                       help='Output directory')
    parser.add_argument('--scene', type=str, default='bistro1',
                       help='Scene name (bistro1, kitchen)')
    parser.add_argument('--start-frame', type=int, default=0,
                       help='Start frame index')
    parser.add_argument('--end-frame', type=int, default=None,
                       help='End frame index')
    
    args = parser.parse_args()
    
    print("="*60)
    print("ğŸ”„ NoiseBase Preprocessing Started")
    print("="*60)
    print(f"Input: {args.input_dir}")
    print(f"Output: {args.output_dir}")
    print(f"Scene: {args.scene}")
    print("="*60)
    
    try:
        # åˆ›å»ºé¢„å¤„ç†å™¨
        preprocessor = NoiseBasePreprocessor(
            input_dir=args.input_dir,
            output_dir=args.output_dir,
            scene_name=args.scene
        )
        
        # å¤„ç†åºåˆ—
        preprocessor.process_sequence(
            start_frame=args.start_frame,
            end_frame=args.end_frame
        )
        
        print("\nğŸ‰ Preprocessing completed successfully!")
        print(f"Results saved to: {args.output_dir}")
        
    except Exception as e:
        print(f"\nâŒ Preprocessing failed: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()