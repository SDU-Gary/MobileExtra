#!/usr/bin/env python3
"""
ç»Ÿä¸€çš„NoiseBaseæ•°æ®é¢„å¤„ç†è„šæœ¬ - ç§»åŠ¨ç«¯å®æ—¶å¸§å¤–æ’ç³»ç»Ÿ
ä½œè€…ï¼šAIç®—æ³•å›¢é˜Ÿ
æ—¥æœŸï¼š2025-08-03

å®Œæ•´å®ç°ä»NoiseBaseæ•°æ®åˆ°ç½‘ç»œè®­ç»ƒæ•°æ®çš„è½¬æ¢ï¼š
1. æ­£ç¡®çš„zarr+zipæ•°æ®åŠ è½½å’ŒRGBEè§£å‹ç¼©
2. åŸºäºè¿åŠ¨çŸ¢é‡çš„å‰å‘æŠ•å½±(Forward Warp)
3. ç©ºæ´æ£€æµ‹å’Œé®æŒ¡æ©ç ç”Ÿæˆ
4. æ®‹å·®è¿åŠ¨çŸ¢é‡è®¡ç®—
5. 7é€šé“è®­ç»ƒæ•°æ®ç”Ÿæˆï¼šRGB(3) + HoleMask(1) + OcclusionMask(1) + ResidualMV(2)

ä½¿ç”¨æ–¹æ³•:
python unified_noisebase_preprocessor.py --data-root ./data --scene bistro1 --output ./processed_unified
"""

import os
import sys
import argparse
import json
import numpy as np
import cv2
import gc  # åƒåœ¾å›æ”¶

# è®¾ç½®matplotlibåç«¯ä¸ºAggï¼Œé¿å…tkinterçº¿ç¨‹å®‰å…¨é—®é¢˜
import matplotlib
matplotlib.use('Agg')  # å¿…é¡»åœ¨pyplotå¯¼å…¥ä¹‹å‰è®¾ç½®
import matplotlib.pyplot as plt
from pathlib import Path
from typing import Dict, Tuple, Optional, List
import zipfile
import tempfile
import shutil
import time
import warnings
from tqdm import tqdm

# ä¾èµ–åº“å¯¼å…¥å’Œå…¼å®¹æ€§å¤„ç†
try:
    import zarr
    HAS_ZARR = True
except ImportError:
    HAS_ZARR = False

try:
    from numba import jit, prange
    HAS_NUMBA = True
except ImportError:
    HAS_NUMBA = False

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„ä»¥å¯¼å…¥é¡¹ç›®æ¨¡å—
sys.path.insert(0, str(Path(__file__).parent))

# å°è¯•å¯¼å…¥zarrå…¼å®¹æ€§æ¨¡å—
try:
    from zarr_compat import load_zarr_group, decompress_RGBE_compat
    HAS_ZARR_COMPAT = True
except ImportError as e:
    HAS_ZARR_COMPAT = False


class UnifiedNoiseBasePreprocessor:
    """
    ç»Ÿä¸€çš„NoiseBaseæ•°æ®é¢„å¤„ç†å™¨
    
    æ•´åˆäº†æ‰€æœ‰å¿…è¦åŠŸèƒ½ï¼š
    - NoiseBaseæ•°æ®åŠ è½½ï¼ˆzip+zarræ ¼å¼ï¼‰
    - RGBEé¢œè‰²è§£å‹ç¼©å’Œå¤šé‡‡æ ·èšåˆ
    - Forward Warpå¤–æ¨å¸§ç”Ÿæˆ
    - ç©ºæ´æ£€æµ‹å’Œé®æŒ¡æ©ç ç”Ÿæˆ
    - è®­ç»ƒæ•°æ®æ ¼å¼åŒ–å’Œä¿å­˜
    """
    
    def __init__(self, 
                 data_root: str,
                 output_dir: str,
                 scene_name: str = "bistro1",
                 test_mode: bool = False,
                 **kwargs):
        """
        åˆå§‹åŒ–é¢„å¤„ç†å™¨
        
        Args:
            data_root: NoiseBaseæ•°æ®æ ¹ç›®å½•
            output_dir: å¤„ç†åæ•°æ®è¾“å‡ºç›®å½•
            scene_name: åœºæ™¯åç§°
            test_mode: æµ‹è¯•æ¨¡å¼ï¼Œè·³è¿‡æ•°æ®ç›®å½•éªŒè¯
            **kwargs: å…¶ä»–é…ç½®å‚æ•°
        """
        self.data_root = Path(data_root)
        self.output_dir = Path(output_dir)
        self.scene_name = scene_name
        self.test_mode = test_mode
        
        # éªŒè¯æ•°æ®ç›®å½•ï¼ˆæµ‹è¯•æ¨¡å¼ä¸‹è·³è¿‡ï¼‰
        if not test_mode:
            if not self.data_root.exists():
                raise FileNotFoundError(f"æ•°æ®ç›®å½•ä¸å­˜åœ¨: {self.data_root}")
            
            scene_dir = self.data_root / scene_name
            if not scene_dir.exists():
                available_scenes = [d.name for d in self.data_root.iterdir() if d.is_dir()]
                raise FileNotFoundError(f"åœºæ™¯ '{scene_name}' ä¸å­˜åœ¨ã€‚å¯ç”¨åœºæ™¯: {available_scenes}")
        else:
            pass  # æµ‹è¯•æ¨¡å¼ï¼šè·³è¿‡æ•°æ®ç›®å½•éªŒè¯
        
        # åˆ›å»ºè¾“å‡ºç›®å½•ç»“æ„
        self._setup_output_dirs()
        
        # ç®—æ³•å‚æ•°
        self.hole_threshold = kwargs.get('hole_threshold', 0.05)  # é™ä½é˜ˆå€¼æé«˜æ•æ„Ÿåº¦
        self.residual_threshold = kwargs.get('residual_threshold', 2.0)
        self.depth_discontinuity_threshold = kwargs.get('depth_discontinuity_threshold', 0.1)
        self.motion_discontinuity_threshold = kwargs.get('motion_discontinuity_threshold', 1.0)
        
        # è°ƒè¯•é€‰é¡¹
        self.debug_occlusion = kwargs.get('debug_occlusion', False)
        
        # æ€§èƒ½ä¼˜åŒ–è®¾ç½®
        self.use_numba = HAS_NUMBA and kwargs.get('use_numba', True)
        self.batch_processing = kwargs.get('batch_processing', False)
        
        # åˆå§‹åŒ–å®Œæˆ
    
    def _setup_output_dirs(self):
        """åˆ›å»ºè¾“å‡ºç›®å½•ç»“æ„"""
        dirs = [
            'rgb',           # ç›®æ ‡RGBå›¾åƒ
            'warped',        # å‰å‘æŠ•å½±åçš„å›¾åƒ
            'masks',         # æ©ç æ–‡ä»¶
            'residual_mv',   # æ®‹å·®è¿åŠ¨çŸ¢é‡
            'training_data', # 7é€šé“è®­ç»ƒæ•°æ®
            'visualization', # å¯è§†åŒ–ç»“æœ
            'debug'          # è°ƒè¯•ä¿¡æ¯
        ]
        
        for dir_name in dirs:
            (self.output_dir / dir_name).mkdir(parents=True, exist_ok=True)
    
    # ==================== æ•°æ®åŠ è½½æ¨¡å— ====================
    
    def load_frame_data(self, scene: str, frame_idx: int) -> Optional[Dict]:
        """
        åŠ è½½æŒ‡å®šå¸§çš„NoiseBaseæ•°æ®ï¼ˆèµ„æºç®¡ç†ç‰ˆæœ¬ï¼‰
        
        Args:
            scene: åœºæ™¯åç§°
            frame_idx: å¸§ç´¢å¼•
            
        Returns:
            frame_data: å¸§æ•°æ®å­—å…¸ï¼ŒåŒ…å«reference, position, motion, depthç­‰
        """
        try:
            zip_path = self.data_root / scene / f"frame{frame_idx:04d}.zip"
            
            if not zip_path.exists():
                return None
            
            # ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨ç¡®ä¿èµ„æºè‡ªåŠ¨æ¸…ç†
            if HAS_ZARR_COMPAT:
                with load_zarr_group(str(zip_path)) as ds:
                    return self._extract_frame_data(ds)
            else:
                ds = self._load_with_fallback(zip_path)
                if ds is None:
                    return None
                return self._extract_frame_data(ds)
                
        except Exception as e:
            import traceback
            traceback.print_exc()
            return None
    
    def _extract_frame_data(self, ds) -> Optional[Dict]:
        """
        ä»zarræ•°æ®æºæå–å¸§æ•°æ®
        
{{ ... }}
        Args:
            ds: zarræ•°æ®æº
            
        Returns:
            frame_data: æå–çš„å¸§æ•°æ®å­—å…¸
        """
        try:
            if ds is None:
                return None
            
            # æå–å’Œå¤„ç†æ•°æ®
            frame_data = {}
            
            # 1. å‚è€ƒå›¾åƒ - ä½¿ç”¨ç°ä»£zarr API
            reference_success = False
            
            # è·å–å¯ç”¨çš„æ•°æ®é”®
            available_keys = []
            try:
                if hasattr(ds, 'keys'):
                    available_keys = list(ds.keys())
                elif hasattr(ds, 'array_keys'):
                    available_keys = list(ds.array_keys())
            except Exception as e:
                pass
            
            # å°è¯•åŠ è½½referenceæ•°æ®
            if 'reference' in available_keys:
                try:
                    reference = np.array(ds['reference'])
                    reference = self._process_reference_data(reference)
                    frame_data['reference'] = reference
                    reference_success = True
                except Exception as e:
                    pass
            
            # å›é€€åˆ°color+exposureæ•°æ®
            if not reference_success and 'color' in available_keys and 'exposure' in available_keys:
                try:
                    color_data = ds['color']
                    exposure_data = ds['exposure']
                    color = self._process_color_data(color_data, exposure_data)
                    frame_data['reference'] = color
                    reference_success = True
                except Exception as e:
                    import traceback
                    traceback.print_exc()
            
            if not reference_success:
                raise ValueError(f"æ— æ³•è·å–ä»»ä½•é¢œè‰²æ•°æ® (referenceæˆ–color+exposure)")
            
            # 2. ä¸–ç•Œç©ºé—´ä½ç½®æ•°æ®
            if 'position' in available_keys:
                try:
                    position = self._process_position_data(ds['position'])
                    frame_data['position'] = position
                    # ä¿å­˜Zåˆ†é‡ä½œä¸ºæ·±åº¦ï¼Œç”¨äºç©ºæ´æ£€æµ‹çš„æ¢¯åº¦è®¡ç®—
                    # æ³¨æ„ï¼šè¿™ä¸ªæ·±åº¦ç”¨äºæ¢¯åº¦æ£€æµ‹ï¼Œä¸é€‚åˆç›´æ¥ç”¨äºé®æŒ¡æ£€æµ‹
                    frame_data['depth'] = position[2:3]  # Zåˆ†é‡ä½œä¸ºæ·±åº¦ï¼ˆç”¨äºç©ºæ´æ£€æµ‹ï¼‰
                except Exception as e:
                    pass
            
            # 3. è¿åŠ¨çŸ¢é‡æ•°æ®
            if 'motion' in available_keys:
                try:
                    motion = self._process_motion_data(ds['motion'])
                    frame_data['motion'] = motion
                except Exception as e:
                    pass
            
            # 4. æ³•çº¿æ•°æ®ï¼ˆç”¨äºé®æŒ¡æ£€æµ‹ï¼‰
            if 'normal' in available_keys:
                try:
                    normal = self._process_normal_data(ds['normal'])
                    frame_data['normal'] = normal
                except Exception as e:
                    pass
            
            # 5. ç›¸æœºå‚æ•°
            frame_data['camera_params'] = self._extract_camera_params(ds, available_keys)
            
            return frame_data
            
        except Exception as e:
            import traceback
            traceback.print_exc()
            return None
    
    def _load_with_fallback(self, zip_path: Path):
        """å¤‡ç”¨çš„zarræ•°æ®åŠ è½½æ–¹æ³•"""
        try:
            if HAS_ZARR:
                import zarr
                return zarr.group(store=zarr.ZipStore(str(zip_path), mode='r'))
            else:
                # è§£å‹åˆ°ä¸´æ—¶ç›®å½•
                temp_dir = tempfile.mkdtemp()
                with zipfile.ZipFile(zip_path, 'r') as zip_file:
                    zip_file.extractall(temp_dir)
                return zarr.open_group(temp_dir, mode='r')
        except Exception as e:
            return None
    
    def _process_color_data(self, color_data, exposure_data) -> np.ndarray:
        """å¤„ç†RGBEé¢œè‰²æ•°æ® - ä¿®å¤ä¸ºä½¿ç”¨detach.pyçš„æ­£ç¡®å¤„ç†é¡ºåº"""
        try:
            # å°†æ•°æ®è½¬æ¢ä¸ºnumpyæ•°ç»„
            color_data = np.array(color_data)
            exposure_data = np.array(exposure_data)
            
            print(f"   è°ƒè¯•: color_dataå½¢çŠ¶: {color_data.shape}, exposure: {exposure_data}")
            
            # å…ˆè¿›è¡ŒRGBEè§£å‹ç¼©ï¼ˆåœ¨å¤šé‡‡æ ·æ•°æ®ä¸Šï¼‰
            if HAS_ZARR_COMPAT:
                color = decompress_RGBE_compat(color_data, exposure_data)
            else:
                # ä½¿ç”¨ä¿®å¤åçš„RGBEè§£å‹ç¼©å®ç°
                color = self._decompress_RGBE_basic(color_data, exposure_data)
            
            print(f"   è°ƒè¯•: RGBEè§£å‹åå½¢çŠ¶: {color.shape}, èŒƒå›´: [{color.min():.6f}, {color.max():.6f}]")
            
            # ç„¶åè¿›è¡Œå¤šé‡‡æ ·èšåˆï¼ˆæŒ‰detach.pyæ–¹å¼ï¼‰
            if color.ndim == 4 and color.shape[-1] > 1:
                color = color.mean(axis=-1)
                print(f"   è°ƒè¯•: å¤šé‡‡æ ·èšåˆåå½¢çŠ¶: {color.shape}")
            
            # ç¡®ä¿æ ¼å¼ä¸ºCHWï¼ˆæŒ‰detach.pyçš„è½¬ç½®æ–¹å¼ï¼‰
            if color.ndim == 3:
                if color.shape[-1] == 3:  # HWC -> CHW
                    color = color.transpose(2, 0, 1)
                elif color.shape[0] == 3:  # å·²ç»æ˜¯CHW
                    pass
                else:
                    raise ValueError(f"æ— æ³•è¯†åˆ«çš„coloræ•°æ®æ ¼å¼: {color.shape}")
            
            print(f"   è°ƒè¯•: æœ€ç»ˆcolorå½¢çŠ¶: {color.shape}")
            
            return color.astype(np.float32)
            
        except Exception as e:
            print(f"é¢œè‰²æ•°æ®å¤„ç†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            raise
    
    def _decompress_RGBE_basic(self, color_rgbe: np.ndarray, exposure: np.ndarray) -> np.ndarray:
        """åŸºç¡€RGBEè§£å‹ç¼©å®ç° - ä¿®å¤ä¸ºä½¿ç”¨detach.pyçš„æ­£ç¡®ç®—æ³•"""
        # ä½¿ç”¨detach.pyä¸­çš„æ­£ç¡®RGBEè§£å‹ç¼©ç®—æ³•
        color_rgbe = np.array(color_rgbe)
        exposure = np.array(exposure)
        
        if color_rgbe.shape[0] != 4:
            raise ValueError(f"RGBEæ•°æ®åº”è¯¥æ˜¯4é€šé“åœ¨ç¬¬ä¸€ç»´ï¼Œå®é™…: {color_rgbe.shape}")
        
        # ä½¿ç”¨detach.pyçš„æ­£ç¡®RGBEè§£å‹ç¼©ç®—æ³•
        exponents = (color_rgbe.astype(np.float32)[3] + 1) / 256
        exponents = np.exp(exponents * (exposure[1] - exposure[0]) + exposure[0])
        color = color_rgbe.astype(np.float32)[:3] / 255 * exponents[np.newaxis]
        
        return color
    
    def _process_position_data(self, position_data) -> np.ndarray:
        """å¤„ç†ä¸–ç•Œç©ºé—´ä½ç½®æ•°æ®"""
        position = np.array(position_data)
        
        # å¤šé‡‡æ ·èšåˆ
        if position.ndim == 4:
            position = position.mean(axis=-1)
        
        # ç¡®ä¿æ ¼å¼ä¸ºCHW
        if position.shape[-1] == 3:
            position = position.transpose(2, 0, 1)
        
        return position.astype(np.float32)
    
    @staticmethod
    def screen_space_projection(world_pos: np.ndarray, 
                               view_proj_matrix: np.ndarray, 
                               height: int, 
                               width: int) -> np.ndarray:
        """
        å°†ä¸–ç•Œç©ºé—´ä½ç½®æŠ•å½±åˆ°å±å¹•ç©ºé—´åƒç´ åæ ‡
        
        Args:
            world_pos: ä¸–ç•Œç©ºé—´åæ ‡ (3, H, W)
            view_proj_matrix: è§†å›¾æŠ•å½±çŸ©é˜µ (4, 4)
            height, width: å›¾åƒå°ºå¯¸
            
        Returns:
            å±å¹•ç©ºé—´åæ ‡ (2, H, W)ï¼Œå•ä½ä¸ºåƒç´ 
        """
        C, H, W = world_pos.shape
        if C != 3:
            raise ValueError(f"world_pos å¿…é¡»æ˜¯3é€šé“ï¼Œå®é™…ä¸º {C}")

        # æ‰©å±•ä¸ºé½æ¬¡åæ ‡
        ones = np.ones((1, H, W), dtype=world_pos.dtype)
        homogeneous_pos = np.concatenate([world_pos, ones], axis=0)

        # çŸ©é˜µæŠ•å½±
        projected_pos = np.einsum('ij,jhw->ihw', view_proj_matrix, homogeneous_pos)
        
        # é€è§†é™¤æ³•
        w = projected_pos[3:4, :, :]
        epsilon = 1e-5
        w = np.where(w < epsilon, epsilon, w)
        ndc_pos = projected_pos[:2, :, :] / w

        # NDCåˆ°å±å¹•åæ ‡è½¬æ¢
        screen_pos_x = (ndc_pos[0] * 0.5 + 0.5) * width
        screen_pos_y = (-ndc_pos[1] * 0.5 + 0.5) * height

        return np.stack([screen_pos_x, screen_pos_y], axis=0)

    def _create_default_projection_matrix(self) -> np.ndarray:
        """åˆ›å»ºé»˜è®¤é€è§†æŠ•å½±çŸ©é˜µ"""
        fov = np.pi / 3  # 60åº¦
        aspect = 16.0 / 9.0
        near, far = 0.1, 100.0
        
        f = 1.0 / np.tan(fov / 2)
        
        projection = np.array([
            [f / aspect, 0, 0, 0],
            [0, f, 0, 0], 
            [0, 0, (far + near) / (near - far), (2 * far * near) / (near - far)],
            [0, 0, -1, 0]
        ], dtype=np.float32)
        
        return projection

    def _compute_screen_space_mv(self, curr_frame: Dict, prev_frame: Dict) -> np.ndarray:
        """
        ã€æ ¸å¿ƒä¿®å¤ã€‘è®¡ç®—å±å¹•ç©ºé—´è¿åŠ¨çŸ¢é‡
        åŸºäº3Då‡ ä½•æŠ•å½±ï¼Œå°†ä¸–ç•Œç©ºé—´è¿åŠ¨è½¬æ¢ä¸ºå±å¹•ç©ºé—´åƒç´ è¿åŠ¨
        """
        print("   ğŸš€ è®¡ç®—å±å¹•ç©ºé—´è¿åŠ¨çŸ¢é‡ï¼ˆ3D->2DæŠ•å½±ï¼‰")
        
        pos_t = curr_frame['position']
        motion_t = curr_frame['motion'][:3]
        
        # è·å–æŠ•å½±çŸ©é˜µ
        vp_mat_t = curr_frame.get('camera_params', {}).get('view_proj_mat')
        vp_mat_prev = prev_frame.get('camera_params', {}).get('view_proj_mat')
        
        if vp_mat_t is None or vp_mat_prev is None:
            print("   âš ï¸ ç¼ºå°‘æŠ•å½±çŸ©é˜µï¼Œä½¿ç”¨é»˜è®¤çŸ©é˜µ")
            default_proj = self._create_default_projection_matrix()
            vp_mat_t = vp_mat_t or default_proj
            vp_mat_prev = vp_mat_prev or default_proj
        else:
            vp_mat_t = vp_mat_t.T
            vp_mat_prev = vp_mat_prev.T

        H, W = pos_t.shape[1], pos_t.shape[2]

        # è®¡ç®—å‰ä¸€å¸§ä¸–ç•Œåæ ‡
        pos_prev = pos_t - motion_t

        # æŠ•å½±åˆ°å±å¹•ç©ºé—´
        screen_pos_t = self.screen_space_projection(pos_t, vp_mat_t, H, W)
        screen_pos_prev = self.screen_space_projection(pos_prev, vp_mat_prev, H, W)
        
        # è®¡ç®—å±å¹•ç©ºé—´è¿åŠ¨çŸ¢é‡
        screen_space_mv = screen_pos_prev - screen_pos_t
        
        # è°ƒè¯•ä¿¡æ¯
        mv_magnitude = np.sqrt(screen_space_mv[0]**2 + screen_space_mv[1]**2)
        print(f"    å±å¹•ç©ºé—´MV: å½¢çŠ¶={screen_space_mv.shape}")
        print(f"      åƒç´ è¿åŠ¨ç»Ÿè®¡: å¹³å‡={mv_magnitude.mean():.2f}px, æœ€å¤§={mv_magnitude.max():.2f}px")
        print(f"      éé›¶è¿åŠ¨åƒç´ æ¯”ä¾‹: {np.mean(mv_magnitude > 0.1):.3f}")
        
        return screen_space_mv.astype(np.float32)

    def _process_motion_data(self, motion_data) -> np.ndarray:
        """å¤„ç†ä¸–ç•Œç©ºé—´è¿åŠ¨çŸ¢é‡æ•°æ®ï¼ˆä»…åŠ è½½å’Œèšåˆï¼Œä¸è¿›è¡Œ2Dè½¬æ¢ï¼‰"""
        motion = np.array(motion_data)
        
        # å¤šé‡‡æ ·èšåˆ
        if motion.ndim == 4:
            motion = motion.mean(axis=-1)
        
        # ç¡®ä¿æ ¼å¼ä¸ºCHW
        if motion.shape[-1] == 3:
            motion = motion.transpose(2, 0, 1)

        print(f"   å·²åŠ è½½ä¸–ç•Œç©ºé—´motionæ•°æ®: {motion.shape}")
        return motion.astype(np.float32)
    def _process_normal_data(self, normal_data) -> np.ndarray:
        """å¤„ç†æ³•çº¿æ•°æ®"""
        normal = np.array(normal_data)
        
        # å¤šé‡‡æ ·èšåˆ
        if normal.ndim == 4:
            normal = normal.mean(axis=-1)
        
        # ç¡®ä¿æ ¼å¼ä¸ºCHW
        if normal.shape[-1] == 3:
            normal = normal.transpose(2, 0, 1)
        
        # æ³•çº¿å½’ä¸€åŒ–
        norm = np.sqrt(np.sum(normal**2, axis=0, keepdims=True))
        norm = np.maximum(norm, 1e-8)  # é¿å…é™¤é›¶
        normal = normal / norm
        
        return normal.astype(np.float32)
    
    def _process_reference_data(self, reference_data) -> np.ndarray:
        """å¤„ç†referenceå‚è€ƒå›¾åƒæ•°æ® - ä¿®å¤ä¸ºä½¿ç”¨detach.pyçš„æ­£ç¡®æ–¹å¼"""
        try:
            reference = np.array(reference_data)
            print(f"   è°ƒè¯•: åŸå§‹referenceå½¢çŠ¶: {reference.shape}, èŒƒå›´: [{reference.min():.6f}, {reference.max():.6f}]")
            
            # æŒ‰ç…§detach.pyçš„æ–¹å¼å¤„ç†ï¼šç›´æ¥è½¬ç½®ï¼Œæ— éœ€å¤šé‡‡æ ·èšåˆ
            # detach.py: ref = np.transpose(reference, (1, 2, 0))
            if reference.ndim == 3 and reference.shape[0] == 3:
                # CHW -> HWC for detach.py compatibility, then back to CHW
                reference_hwc = reference.transpose(1, 2, 0)
                reference = reference_hwc.transpose(2, 0, 1)  # Back to CHW for consistency
                print(f"   è°ƒè¯•: referenceè½¬ç½®åå½¢çŠ¶: {reference.shape}")
            elif reference.ndim == 4:
                # å¦‚æœæœ‰å¤šé‡‡æ ·ç»´åº¦ï¼Œå…ˆèšåˆå†è½¬ç½®ï¼ˆä½†detach.pyä¸­referenceé€šå¸¸æ²¡æœ‰å¤šé‡‡æ ·ï¼‰
                reference = reference.mean(axis=-1) if reference.shape[-1] > 1 else reference.squeeze(-1)
                if reference.ndim == 3 and reference.shape[-1] == 3:
                    reference = reference.transpose(2, 0, 1)
                print(f"   è°ƒè¯•: referenceå¤šé‡‡æ ·å¤„ç†åå½¢çŠ¶: {reference.shape}")
            elif reference.ndim == 2:
                # ç°åº¦å›¾åƒï¼Œè½¬æ¢ä¸º3é€šé“
                reference = np.stack([reference, reference, reference], axis=0)
            
            # ä¸å¼ºåˆ¶è½¬æ¢åˆ°[0,1]èŒƒå›´ï¼Œä¿æŒHDRæ•°æ®
            # detach.pyä¸­æ²¡æœ‰å¯¹referenceè¿›è¡ŒèŒƒå›´é™åˆ¶
            print(f"   è°ƒè¯•: æœ€ç»ˆreferenceå½¢çŠ¶: {reference.shape}, èŒƒå›´: [{reference.min():.6f}, {reference.max():.6f}]")
            
            return reference.astype(np.float32)
            
        except Exception as e:
            print(f"Referenceæ•°æ®å¤„ç†è¯¦ç»†é”™è¯¯: {e}")
            print(f"Referenceæ•°æ®å½¢çŠ¶: {reference_data.shape if hasattr(reference_data, 'shape') else 'unknown'}")
            import traceback
            traceback.print_exc()
            raise
    
    def _extract_camera_params(self, ds, available_keys: list) -> Dict:
        """æå–ç›¸æœºå‚æ•°"""
        params = {}
        
        try:
            # ä½¿ç”¨ç°ä»£zarr API
            if 'camera_position' in available_keys:
                params['camera_position'] = np.array(ds['camera_position'])
            if 'proj_mat' in available_keys:
                params['proj_mat'] = np.array(ds['proj_mat'])
            if 'view_proj_mat' in available_keys:
                params['view_proj_mat'] = np.array(ds['view_proj_mat'])
        except Exception as e:
            print(f"æå–ç›¸æœºå‚æ•°æ—¶å‡ºé”™: {e}")
        
        return params
    
    # ==================== Forward Warpæ¨¡å— ====================
    
    def forward_warp_frame(self, 
                          prev_frame: Dict, 
                          motion_vectors: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """
        å‰å‘æŠ•å½±ç®—æ³•å®ç°
        
        Args:
            prev_frame: å‰ä¸€å¸§æ•°æ®
            motion_vectors: è¿åŠ¨çŸ¢é‡ [2, H, W]
            
        Returns:
            warped_image: æŠ•å½±åå›¾åƒ [C, H, W]
            coverage_mask: è¦†ç›–æ©ç  [H, W]
        """
        source_image = prev_frame['reference']
        
        # ç¡®ä¿è¾“å…¥æ ¼å¼æ­£ç¡®
        if source_image.ndim == 3 and source_image.shape[2] in [1, 3]:
            source_image = source_image.transpose(2, 0, 1)
        
        if motion_vectors.ndim == 3 and motion_vectors.shape[2] == 2:
            motion_vectors = motion_vectors.transpose(2, 0, 1)
        
        C, H, W = source_image.shape
        
        # åˆå§‹åŒ–è¾“å‡º
        warped_image = np.zeros_like(source_image)
        coverage_mask = np.zeros((H, W), dtype=np.float32)
        
        # ä½¿ç”¨ä¼˜åŒ–çš„å‰å‘æŠ•å½±ç®—æ³•
        if self.use_numba and HAS_NUMBA:
            warped_image, coverage_mask = self._forward_splatting_numba(
                source_image, motion_vectors, warped_image, coverage_mask
            )
        else:
            warped_image, coverage_mask = self._forward_splatting_python(
                source_image, motion_vectors, warped_image, coverage_mask
            )
        
        # æ·±åº¦å†²çªè§£å†³ï¼ˆå¦‚æœæœ‰æ·±åº¦ä¿¡æ¯ï¼‰
        if 'depth' in prev_frame:
            warped_image = self._resolve_depth_conflicts(
                warped_image, coverage_mask, prev_frame['depth'], motion_vectors
            )
        
        return warped_image, coverage_mask
    
    def _forward_splatting_python(self, 
                                source_image: np.ndarray,
                                motion_vectors: np.ndarray,
                                warped_image: np.ndarray,
                                coverage_mask: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """çº¯Pythonå®ç°çš„å‰å‘æŠ•å½±"""
        C, H, W = source_image.shape
        
        # åˆ›å»ºåæ ‡ç½‘æ ¼
        y_coords, x_coords = np.mgrid[0:H, 0:W]
        
        # è®¡ç®—ç›®æ ‡åæ ‡
        target_x = x_coords + motion_vectors[0]
        target_y = y_coords + motion_vectors[1]
        
        # æœ‰æ•ˆåƒç´ æ©ç 
        valid_mask = (
            (target_x >= 0) & (target_x < W-1) & 
            (target_y >= 0) & (target_y < H-1)
        )
        
        # è·å–æœ‰æ•ˆåæ ‡
        valid_indices = np.where(valid_mask)
        src_y, src_x = valid_indices
        
        # è®¡ç®—ç›®æ ‡åæ ‡ï¼ˆæ•´æ•°ï¼‰
        tgt_x = np.round(target_x[valid_mask]).astype(np.int32)
        tgt_y = np.round(target_y[valid_mask]).astype(np.int32)
        
        # æŠ•å½±åƒç´ å€¼
        for i in range(len(src_y)):
            sy, sx = src_y[i], src_x[i]
            ty, tx = tgt_y[i], tgt_x[i]
            
            # ç´¯åŠ é¢œè‰²å€¼å’Œè¦†ç›–è®¡æ•°
            warped_image[:, ty, tx] += source_image[:, sy, sx]
            coverage_mask[ty, tx] += 1.0
        
        # å½’ä¸€åŒ–
        valid_coverage = coverage_mask > 0
        warped_image[:, valid_coverage] /= coverage_mask[valid_coverage]
        
        return warped_image, coverage_mask
    
    if HAS_NUMBA:
        @staticmethod
        @jit(nopython=True, parallel=True)
        def _forward_splatting_numba(source_image: np.ndarray,
                                   motion_vectors: np.ndarray,
                                   warped_image: np.ndarray,
                                   coverage_mask: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
            """Numbaä¼˜åŒ–çš„å‰å‘æŠ•å½±"""
            C, H, W = source_image.shape
            
            for y in prange(H):
                for x in range(W):
                    # è®¡ç®—ç›®æ ‡ä½ç½®
                    target_x = x + motion_vectors[0, y, x]
                    target_y = y + motion_vectors[1, y, x]
                    
                    # è¾¹ç•Œæ£€æŸ¥
                    if 0 <= target_x < W-1 and 0 <= target_y < H-1:
                        # æœ€è¿‘é‚»æŠ•å½±
                        tx = int(round(target_x))
                        ty = int(round(target_y))
                        
                        if 0 <= tx < W and 0 <= ty < H:
                            # ç´¯åŠ é¢œè‰²å€¼
                            for c in range(C):
                                warped_image[c, ty, tx] += source_image[c, y, x]
                            coverage_mask[ty, tx] += 1.0
            
            # å½’ä¸€åŒ–
            for y in prange(H):
                for x in range(W):
                    if coverage_mask[y, x] > 0:
                        for c in range(C):
                            warped_image[c, y, x] /= coverage_mask[y, x]
            
            return warped_image, coverage_mask
    else:
        def _forward_splatting_numba(self, *args):
            return self._forward_splatting_python(*args)
    
    def _resolve_depth_conflicts(self, 
                                warped_image: np.ndarray,
                                coverage_mask: np.ndarray,
                                depth: np.ndarray,
                                motion_vectors: np.ndarray) -> np.ndarray:
        """åŸºäºæ·±åº¦çš„å†²çªè§£å†³"""
        # ç®€åŒ–çš„æ·±åº¦å†²çªè§£å†³ - ä¿æŒè·ç¦»ç›¸æœºæœ€è¿‘çš„åƒç´ 
        # åœ¨å®é™…GPUå®ç°ä¸­ï¼Œè¿™ä¼šé€šè¿‡åŸå­æ·±åº¦æµ‹è¯•å®Œæˆ
        return warped_image
    
    # ==================== ç©ºæ´æ£€æµ‹å’Œé®æŒ¡åˆ†ææ¨¡å— ====================
    
    def detect_holes_and_occlusion(self, 
                                  warped_image: np.ndarray,
                                  target_image: np.ndarray,
                                  coverage_mask: np.ndarray,
                                  curr_frame: Dict,
                                  prev_frame: Dict,
                                  motion_vectors: Optional[np.ndarray] = None) -> Dict[str, np.ndarray]:
        """
        æ£€æµ‹å‡ ä½•ç©ºæ´ã€éå‡ ä½•ç©ºæ´å’Œè¯­ä¹‰é®æŒ¡
        
        Args:
            warped_image: å‰å‘æŠ•å½±å›¾åƒ
            target_image: ç›®æ ‡å›¾åƒ
            coverage_mask: è¦†ç›–æ©ç 
            curr_frame: å½“å‰å¸§æ•°æ®
            prev_frame: å‰ä¸€å¸§æ•°æ®
            motion_vectors: è¿åŠ¨çŸ¢é‡ (2, H, W)ï¼Œç”¨äºçœŸæ­£çš„é®æŒ¡æ£€æµ‹
            
        Returns:
            masks: åŒ…å«å„ç§æ©ç çš„å­—å…¸
        """
        masks = {}
        
        # 1. å‡ ä½•ç©ºæ´æ£€æµ‹ - åŸºäºè¦†ç›–åº¦
        masks['holes'] = self._detect_geometric_holes(coverage_mask)
        
        # 2. éå‡ ä½•ç©ºæ´æ£€æµ‹ - åŸºäºæ·±åº¦å’Œè¿åŠ¨ä¸è¿ç»­æ€§ï¼ˆç½‘ç»œè®­ç»ƒéœ€è¦ï¼‰
        masks['semantic_holes'] = self._detect_semantic_holes(curr_frame, prev_frame)
        
        # 3. çœŸæ­£çš„é®æŒ¡æ£€æµ‹ - åŸºäºæ·±åº¦æ¯”è¾ƒï¼ˆå­¦é•¿çš„æ–¹æ³•ï¼‰
        if motion_vectors is not None:
            masks['occlusion'] = self._detect_true_occlusion(
                curr_frame, prev_frame, warped_image, motion_vectors
            )
        else:
            # å¤‡ç”¨ï¼šä½¿ç”¨éå‡ ä½•ç©ºæ´ä½œä¸ºé®æŒ¡æ©ç 
            masks['occlusion'] = masks['semantic_holes']
        
        # 4. é™æ€å’ŒåŠ¨æ€ç©ºæ´åˆ†ç±»
        masks['static_holes'], masks['dynamic_holes'] = self._classify_holes(
            masks['holes'], curr_frame, prev_frame
        )
        
        print(f"   å‡ ä½•ç©ºæ´: {np.mean(masks['holes']):.3f} è¦†ç›–ç‡")
        print(f"   éå‡ ä½•ç©ºæ´: {np.mean(masks['semantic_holes']):.3f} è¦†ç›–ç‡")
        print(f"   é®æŒ¡æ£€æµ‹: {np.mean(masks['occlusion']):.3f} è¦†ç›–ç‡")
        
        return masks
    
    def _detect_geometric_holes(self, coverage_mask: np.ndarray) -> np.ndarray:
        """æ£€æµ‹å‡ ä½•ç©ºæ´"""
        # åŸºäºè¦†ç›–åº¦é˜ˆå€¼çš„ç©ºæ´æ£€æµ‹
        hole_mask = (coverage_mask < self.hole_threshold).astype(np.float32)
        
        # å½¢æ€å­¦æ“ä½œä¼˜åŒ–
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
        hole_mask = cv2.morphologyEx(hole_mask, cv2.MORPH_CLOSE, kernel)
        hole_mask = cv2.morphologyEx(hole_mask, cv2.MORPH_OPEN, kernel)
        
        return hole_mask
    
    def _detect_semantic_holes(self, curr_frame: Dict, prev_frame: Dict) -> np.ndarray:
        """
        æ£€æµ‹éå‡ ä½•ç©ºæ´ - åŸºäºæ·±åº¦å’Œè¿åŠ¨ä¸è¿ç»­æ€§ï¼ˆç½‘ç»œè®­ç»ƒéœ€è¦ï¼‰
        
        è¿™æ˜¯åŸæ¥çš„"è¯­ä¹‰é®æŒ¡"æ£€æµ‹æ–¹æ³•ï¼Œå®é™…ä¸Šæ˜¯ä¸€ç§éå‡ ä½•çš„ç©ºæ´æ£€æµ‹
        ç°åœ¨å•ç‹¬æå–å‡ºæ¥ï¼Œç”¨äºç½‘ç»œè®­ç»ƒæ•°æ®
        
        æ³¨æ„ï¼šè¿™é‡Œä½¿ç”¨Zåˆ†é‡æ·±åº¦è¿›è¡Œæ¢¯åº¦æ£€æµ‹ï¼Œä¸é®æŒ¡æ£€æµ‹ä½¿ç”¨çš„ç›¸æœºè·ç¦»æ·±åº¦ä¸åŒ
        """
        # åŸºäºæ·±åº¦ä¸è¿ç»­æ€§çš„æ£€æµ‹ï¼ˆä½¿ç”¨Zåˆ†é‡æ·±åº¦çš„æ¢¯åº¦ï¼‰
        depth_holes = np.zeros((curr_frame['reference'].shape[1], curr_frame['reference'].shape[2]), dtype=np.float32)
        
        if 'depth' in curr_frame:
            depth_holes = self._compute_depth_discontinuity(curr_frame['depth'])
        
        # åŸºäºè¿åŠ¨ä¸è¿ç»­æ€§çš„æ£€æµ‹
        motion_holes = np.zeros_like(depth_holes)
        
        if 'motion' in curr_frame:
            motion_holes = self._compute_motion_discontinuity(curr_frame['motion'])
        
        # ç»“åˆä¸¤ç§æ–¹æ³•
        semantic_holes = np.maximum(depth_holes, motion_holes)
        
        # å½¢æ€å­¦ä¼˜åŒ–
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
        semantic_holes = cv2.morphologyEx(semantic_holes, cv2.MORPH_CLOSE, kernel)
        
        return semantic_holes
    
    def _detect_semantic_occlusion(self, 
                                  curr_frame: Dict, 
                                  prev_frame: Dict,
                                  warped_frame: Optional[np.ndarray] = None,
                                  motion_vectors: Optional[np.ndarray] = None) -> np.ndarray:
        """
        æ£€æµ‹è¯­ä¹‰é®æŒ¡ - æ›´æ–°ä¸ºçœŸæ­£çš„é®æŒ¡æ£€æµ‹
        
        æ³¨æ„ï¼šè¿™ä¸ªæ–¹æ³•åä¿æŒä¸å˜ä»¥å…¼å®¹ç°æœ‰ä»£ç ï¼Œä½†ç°åœ¨å®ç°äº†çœŸæ­£çš„é®æŒ¡æ£€æµ‹
        ä¹‹å‰è¿™ä¸ªæ–¹æ³•å®é™…ä¸Šæ˜¯ç©ºæ´æ£€æµ‹ï¼Œç°åœ¨æ”¹ä¸ºæ­£ç¡®çš„é®æŒ¡æ£€æµ‹
        """
        # å¦‚æœæä¾›äº†warpç»“æœå’Œè¿åŠ¨çŸ¢é‡ï¼Œä½¿ç”¨åŸºäºæ·±åº¦æ¯”è¾ƒçš„çœŸæ­£é®æŒ¡æ£€æµ‹
        if warped_frame is not None and motion_vectors is not None:
            return self._detect_true_occlusion(curr_frame, prev_frame, warped_frame, motion_vectors)
        else:
            # å¤‡ç”¨æ–¹æ³•ï¼šåŸºäºæ¢¯åº¦çš„ä¼ ç»Ÿæ–¹æ³•
            return self._detect_semantic_occlusion_fallback(curr_frame, prev_frame)
    
    def _compute_depth_discontinuity(self, depth: np.ndarray) -> np.ndarray:
        """
        è®¡ç®—æ·±åº¦ä¸è¿ç»­æ€§ - ç”¨äºç©ºæ´æ£€æµ‹
        
        æ³¨æ„ï¼šè¿™é‡Œä½¿ç”¨çš„æ˜¯Zåˆ†é‡æ·±åº¦ï¼Œé€šè¿‡Sobelç®—å­æ£€æµ‹æ¢¯åº¦ä¸è¿ç»­æ€§
        ä¸é®æŒ¡æ£€æµ‹ä¸­çš„ç›¸æœºè·ç¦»æ·±åº¦æ˜¯ä¸åŒçš„æ¦‚å¿µ
        """
        if depth.ndim == 3:
            depth = depth[0]  # å–ç¬¬ä¸€ä¸ªé€šé“
        
        # è®¡ç®—æ¢¯åº¦
        grad_x = cv2.Sobel(depth, cv2.CV_32F, 1, 0, ksize=3)
        grad_y = cv2.Sobel(depth, cv2.CV_32F, 0, 1, ksize=3)
        
        # æ¢¯åº¦å¹…åº¦
        gradient_magnitude = np.sqrt(grad_x**2 + grad_y**2)
        
        # åŸºäºç™¾åˆ†ä½æ•°çš„é˜ˆå€¼
        threshold = np.percentile(gradient_magnitude, 98)
        
        discontinuity = (gradient_magnitude > threshold * self.depth_discontinuity_threshold).astype(np.float32)
        
        return discontinuity
    
    def _compute_motion_discontinuity(self, motion: np.ndarray) -> np.ndarray:
        """è®¡ç®—è¿åŠ¨ä¸è¿ç»­æ€§"""
        # è®¡ç®—è¿åŠ¨çŸ¢é‡çš„æ¢¯åº¦
        motion_x, motion_y = motion[0], motion[1]
        
        # Xæ–¹å‘è¿åŠ¨çš„æ¢¯åº¦
        grad_mx_x = cv2.Sobel(motion_x, cv2.CV_32F, 1, 0, ksize=3)
        grad_mx_y = cv2.Sobel(motion_x, cv2.CV_32F, 0, 1, ksize=3)
        
        # Yæ–¹å‘è¿åŠ¨çš„æ¢¯åº¦
        grad_my_x = cv2.Sobel(motion_y, cv2.CV_32F, 1, 0, ksize=3)
        grad_my_y = cv2.Sobel(motion_y, cv2.CV_32F, 0, 1, ksize=3)
        
        # æ€»æ¢¯åº¦å¹…åº¦
        total_gradient = np.sqrt(grad_mx_x**2 + grad_mx_y**2 + grad_my_x**2 + grad_my_y**2)
        
        # åŸºäºç™¾åˆ†ä½æ•°çš„é˜ˆå€¼
        threshold = np.percentile(total_gradient, 98)
        
        discontinuity = (total_gradient > threshold * self.motion_discontinuity_threshold).astype(np.float32)
        
        return discontinuity
    
    def _calculate_camera_depth(self, world_position: np.ndarray, camera_position: np.ndarray) -> np.ndarray:
        """
        è®¡ç®—ä¸–ç•Œåæ ‡ç‚¹åˆ°ç›¸æœºä½ç½®çš„è·ç¦»ï¼ˆå­¦é•¿æä¾›çš„my_log_depthå‡½æ•°ï¼‰
        
        Args:
            world_position: ä¸–ç•Œåæ ‡ä½ç½® (H, W, 3) æˆ– (3, H, W)
            camera_position: ç›¸æœºä½ç½® (3,)
            
        Returns:
            depth: å¯¹æ•°æ·±åº¦ (H, W)
        """
        # ç¡®ä¿world_positionæ˜¯(H, W, 3)æ ¼å¼
        if world_position.shape[0] == 3 and len(world_position.shape) == 3:
            # ä»(3, H, W)è½¬æ¢ä¸º(H, W, 3)
            world_position = world_position.transpose(1, 2, 0)
        
        # è®¡ç®—æ¬§å‡ é‡Œå¾—è·ç¦»
        d = np.linalg.norm(world_position - camera_position.reshape(1, 1, 3), axis=-1)
        
        # è¿‡æ»¤æ— æ•ˆè·ç¦»ï¼šå¤ªå°æˆ–å¤ªå¤§çš„è·ç¦»éƒ½è®¤ä¸ºæ— æ•ˆ
        valid_distance = (d > 1e-3) & (d < 1e6) & np.isfinite(d)
        
        # åº”ç”¨å¯¹æ•°å˜æ¢ï¼Œé¿å…é™¤é›¶é”™è¯¯
        safe_d = np.maximum(d, 1e-8)
        log_depth = np.log(1 + 1 / safe_d)
        
        # å°†æ— æ•ˆè·ç¦»å¯¹åº”çš„æ·±åº¦è®¾ä¸ºè´Ÿå€¼ï¼Œä¾¿äºåç»­è¿‡æ»¤
        log_depth[~valid_distance] = -1.0
        
        return log_depth
    
    def _detect_true_occlusion(self, 
                              curr_frame: Dict, 
                              prev_frame: Dict,
                              warped_frame: np.ndarray,
                              motion_vectors: np.ndarray,
                              depth_threshold: float = 0.05) -> np.ndarray:
        """
        æ£€æµ‹çœŸæ­£çš„é®æŒ¡æ©ç  - åŸºäºå­¦é•¿çš„æ·±åº¦æ¯”è¾ƒæ–¹æ³•
        
        Args:
            curr_frame: å½“å‰å¸§æ•°æ®
            prev_frame: å‰ä¸€å¸§æ•°æ®  
            warped_frame: warpåçš„å‰ä¸€å¸§
            motion_vectors: è¿åŠ¨çŸ¢é‡ (2, H, W)
            depth_threshold: æ·±åº¦å·®å¼‚é˜ˆå€¼
            
        Returns:
            occlusion_mask: é®æŒ¡æ©ç  (H, W)
        """
        H, W = curr_frame['reference'].shape[1], curr_frame['reference'].shape[2]
        
        # è·å–å½“å‰å¸§ä¸–ç•Œä½ç½®å’Œç›¸æœºä½ç½®
        if 'position' not in curr_frame or 'camera_params' not in curr_frame:
            print("   âš ï¸ ç¼ºå°‘ä½ç½®æˆ–ç›¸æœºå‚æ•°ï¼Œä½¿ç”¨åŸºäºæ¢¯åº¦çš„é®æŒ¡æ£€æµ‹")
            return self._detect_semantic_occlusion_fallback(curr_frame, prev_frame)
            
        current_position = curr_frame['position']  # å½“å‰å¸§ä¸–ç•Œåæ ‡
        camera_params = curr_frame['camera_params']
        
        if 'camera_position' not in camera_params:
            print("   âš ï¸ ç¼ºå°‘ç›¸æœºä½ç½®ï¼Œä½¿ç”¨å¤‡ç”¨é®æŒ¡æ£€æµ‹")
            return self._detect_semantic_occlusion_fallback(curr_frame, prev_frame)
            
        camera_position = camera_params['camera_position']
        
        # è®¡ç®—å½“å‰å¸§çš„ç›¸æœºæ·±åº¦ï¼ˆå­¦é•¿çš„æ­£ç¡®æ–¹æ³•ï¼‰
        # æ³¨æ„ï¼šè¿™é‡Œè®¡ç®—çš„æ˜¯ç›¸æœºåˆ°ä¸–ç•Œåæ ‡ç‚¹çš„æ¬§å‡ é‡Œå¾—è·ç¦»ï¼Œç”¨äºé®æŒ¡æ£€æµ‹
        # ä¸ç©ºæ´æ£€æµ‹ä¸­ä½¿ç”¨çš„Zåˆ†é‡æ·±åº¦ä¸åŒ
        current_depth = self._calculate_camera_depth(current_position, camera_position)
        
        # è®¡ç®—warpå¯¹åº”çš„å‰ä¸€å¸§ä¸–ç•Œåæ ‡ä½ç½®
        x, y = np.meshgrid(np.arange(W), np.arange(H))
        prev_x = x + motion_vectors[1]  # Xæ–¹å‘è¿åŠ¨
        prev_y = y + motion_vectors[0]  # Yæ–¹å‘è¿åŠ¨
        
        # è¾¹ç•Œæ£€æŸ¥
        valid_mask = ((prev_x >= 0) & (prev_x < W) & (prev_y >= 0) & (prev_y < H))
        
        # åŒçº¿æ€§æ’å€¼è·å–å‰ä¸€å¸§ä¸–ç•Œåæ ‡
        from scipy.ndimage import map_coordinates
        coords = np.stack([prev_y.ravel(), prev_x.ravel()], axis=-1)
        
        prev_world_pos = np.zeros((H, W, 3))
        if 'position' in prev_frame:
            prev_position = prev_frame['position']
            if prev_position.shape[0] == 3:  # (3, H, W)
                for i in range(3):
                    # ä½¿ç”¨ 'nearest' æ¨¡å¼é¿å…è¾¹ç•Œå¤„çš„é›¶å€¼é—®é¢˜
                    prev_world_pos[..., i] = map_coordinates(
                        prev_position[i], coords.T, order=1, mode='nearest', cval=0
                    ).reshape(H, W)
            
        # è®¡ç®—å‰ä¸€å¸§æŠ•å½±åˆ°å½“å‰ç›¸æœºçš„æœŸæœ›æ·±åº¦
        expected_depth = self._calculate_camera_depth(prev_world_pos, camera_position)
        
        # è°ƒè¯•ä¿¡æ¯
        print(f"   ğŸ” å½“å‰æ·±åº¦èŒƒå›´: [{current_depth.min():.3f}, {current_depth.max():.3f}]")
        print(f"   ğŸ” æœŸæœ›æ·±åº¦èŒƒå›´: [{expected_depth.min():.3f}, {expected_depth.max():.3f}]")
        print(f"   ğŸ” å½“å‰å¸§ä¸–ç•Œåæ ‡èŒƒå›´: X[{current_position[0].min():.1f}, {current_position[0].max():.1f}], Y[{current_position[1].min():.1f}, {current_position[1].max():.1f}], Z[{current_position[2].min():.1f}, {current_position[2].max():.1f}]")
        print(f"   ğŸ” ç›¸æœºä½ç½®: [{camera_position[0]:.1f}, {camera_position[1]:.1f}, {camera_position[2]:.1f}]")
        
        # åªè€ƒè™‘æœ‰æ•ˆæ·±åº¦å€¼çš„åŒºåŸŸ
        # å­¦é•¿çš„å¯¹æ•°æ·±åº¦å‡½æ•°: log(1 + 1/d) åº”è¯¥æ€»æ˜¯æ­£å€¼ï¼Œé™¤édæ— æ•ˆ
        # æˆ‘çš„å‡½æ•°å¯¹æ— æ•ˆè·ç¦»è¿”å›-1.0ï¼Œæ‰€ä»¥æ£€æŸ¥æ¡ä»¶æ”¹ä¸º >= 0
        valid_current = (current_depth >= 0) & np.isfinite(current_depth)
        valid_expected = (expected_depth >= 0) & np.isfinite(expected_depth)
        valid_depth_mask = valid_current & valid_expected
        
        # æ·±åº¦æ¯”è¾ƒæ£€æµ‹é®æŒ¡ï¼ˆåªåœ¨æœ‰æ•ˆåŒºåŸŸï¼‰
        depth_diff = np.abs(expected_depth - current_depth)
        
        # é®æŒ¡æ£€æµ‹é€»è¾‘æ”¹è¿›ï¼šåŸºäºå­¦é•¿åŸå§‹é€»è¾‘ä½†æ›´ä¿å®ˆ
        # å­¦é•¿çš„åŸå§‹é€»è¾‘æ˜¯æ£€æµ‹æ·±åº¦ä¸åŒ¹é…ï¼Œè¿™é‡Œæ”¹ä¸ºæ›´ä¸¥æ ¼çš„é®æŒ¡æ£€æµ‹
        
        # è®¡ç®—ç›¸å¯¹æ·±åº¦å·®å¼‚ï¼ˆå½’ä¸€åŒ–ï¼‰
        relative_diff = depth_diff / (np.maximum(current_depth, expected_depth) + 1e-8)
        
        # é®æŒ¡æ¡ä»¶ï¼š
        # 1. æ·±åº¦å·®å¼‚æ˜¾è‘— (ç›¸å¯¹å·®å¼‚ > é˜ˆå€¼)
        # 2. ä¸”æœŸæœ›æ·±åº¦ > å½“å‰æ·±åº¦ (å‰ä¸€å¸§çš„ç‰©ä½“è¢«å½“å‰å¸§é®æŒ¡)
        # 3. ä¸”éƒ½æ˜¯æœ‰æ•ˆæ·±åº¦
        significant_diff = (relative_diff > depth_threshold)  # ä½¿ç”¨ç›¸å¯¹é˜ˆå€¼
        depth_occlusion = (expected_depth > current_depth)   # æœŸæœ›æ·±åº¦æ›´è¿œ = è¢«é®æŒ¡
        
        occlusion_mask = np.zeros((H, W), dtype=np.float32)
        occlusion_condition = valid_depth_mask & significant_diff & depth_occlusion
        occlusion_mask[occlusion_condition] = 1.0
        
        # è¶…å‡ºè¾¹ç•Œçš„åŒºåŸŸä¸ç®—é®æŒ¡
        occlusion_mask[~valid_mask] = 0.0
        
        print(f"   ğŸ” é®æŒ¡åƒç´ æ¯”ä¾‹: {np.mean(occlusion_mask):.3f}")
        print(f"   ğŸ” æœ‰æ•ˆæ·±åº¦æ¯”ä¾‹: {np.mean(valid_depth_mask):.3f}")
        print(f"   ğŸ” å½“å‰æ·±åº¦æœ‰æ•ˆåƒç´ : {np.mean(valid_current):.3f}")
        print(f"   ğŸ” æœŸæœ›æ·±åº¦æœ‰æ•ˆåƒç´ : {np.mean(valid_expected):.3f}")
        
        if np.any(valid_depth_mask):
            print(f"   ğŸ” æ˜¾è‘—æ·±åº¦å·®å¼‚æ¯”ä¾‹: {np.mean(significant_diff[valid_depth_mask]):.3f}")
            print(f"   ğŸ” æ·±åº¦é®æŒ¡æ¡ä»¶æ¯”ä¾‹: {np.mean(depth_occlusion[valid_depth_mask]):.3f}")
            # æ˜¾ç¤ºæœ‰æ•ˆåŒºåŸŸçš„æ·±åº¦ç»Ÿè®¡
            print(f"   ğŸ” æœ‰æ•ˆåŒºåŸŸæ·±åº¦å·®å¼‚: min={depth_diff[valid_depth_mask].min():.3f}, max={depth_diff[valid_depth_mask].max():.3f}, mean={depth_diff[valid_depth_mask].mean():.3f}")
        else:
            print(f"   ğŸ” æ˜¾è‘—æ·±åº¦å·®å¼‚æ¯”ä¾‹: æ— æœ‰æ•ˆåƒç´ ")
            print(f"   ğŸ” æ·±åº¦é®æŒ¡æ¡ä»¶æ¯”ä¾‹: æ— æœ‰æ•ˆåƒç´ ")
        
        print(f"   ğŸ” è¾¹ç•Œå¤–åƒç´ æ¯”ä¾‹: {np.mean(~valid_mask):.3f}")
        
        # å½¢æ€å­¦ä¼˜åŒ–ï¼ˆåªæœ‰å½“é®æŒ¡åŒºåŸŸä¸ä¸ºç©ºæ—¶ï¼‰
        if np.any(occlusion_mask > 0):
            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
            occlusion_mask = cv2.morphologyEx(occlusion_mask, cv2.MORPH_OPEN, kernel)
        
        # è°ƒè¯•ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
        if hasattr(self, 'debug_occlusion') and self.debug_occlusion:
            self._debug_occlusion_detection(curr_frame, expected_depth, current_depth, occlusion_mask)
        
        return occlusion_mask
    
    def _debug_occlusion_detection(self, 
                                  curr_frame: Dict, 
                                  expected_depth: np.ndarray,
                                  current_depth: np.ndarray,
                                  occlusion_mask: np.ndarray) -> None:
        """è°ƒè¯•é®æŒ¡æ£€æµ‹ç»“æœ"""
        print("\n=== é®æŒ¡æ£€æµ‹è°ƒè¯•ä¿¡æ¯ ===")
        print(f"å½“å‰æ·±åº¦ç»Ÿè®¡: min={current_depth.min():.3f}, max={current_depth.max():.3f}, mean={current_depth.mean():.3f}")
        print(f"æœŸæœ›æ·±åº¦ç»Ÿè®¡: min={expected_depth.min():.3f}, max={expected_depth.max():.3f}, mean={expected_depth.mean():.3f}")
        
        # æ£€æŸ¥æ·±åº¦å€¼åˆ†å¸ƒ
        current_positive = np.sum(current_depth > 0)
        expected_positive = np.sum(expected_depth > 0)
        print(f"æ­£æ·±åº¦åƒç´ : å½“å‰={current_positive}, æœŸæœ›={expected_positive}, æ€»åƒç´ ={current_depth.size}")
        
        # æ£€æŸ¥æ·±åº¦å·®å¼‚åˆ†å¸ƒ
        valid_mask = (current_depth > 0) & (expected_depth > 0)
        if np.any(valid_mask):
            depth_diff = np.abs(expected_depth - current_depth)[valid_mask]
            print(f"æ·±åº¦å·®å¼‚ç»Ÿè®¡: min={depth_diff.min():.3f}, max={depth_diff.max():.3f}, mean={depth_diff.mean():.3f}")
            
            relative_diff = depth_diff / (np.maximum(current_depth[valid_mask], expected_depth[valid_mask]) + 1e-8)
            print(f"ç›¸å¯¹å·®å¼‚ç»Ÿè®¡: min={relative_diff.min():.3f}, max={relative_diff.max():.3f}, mean={relative_diff.mean():.3f}")
        
        print(f"æœ€ç»ˆé®æŒ¡æ©ç : {np.mean(occlusion_mask):.3f} çš„åƒç´ è¢«æ ‡è®°ä¸ºé®æŒ¡")
        print("=======================\n")
    
    def _detect_semantic_occlusion_fallback(self, curr_frame: Dict, prev_frame: Dict) -> np.ndarray:
        """
        å¤‡ç”¨é®æŒ¡æ£€æµ‹æ–¹æ³• - åŸºäºæ¢¯åº¦çš„æ–¹æ³•ï¼ˆåŸæ¥çš„å®ç°ï¼‰
        """
        # è¿™æ˜¯åŸæ¥çš„åŸºäºæ·±åº¦å’Œè¿åŠ¨ä¸è¿ç»­æ€§çš„æ–¹æ³•
        depth_occlusion = np.zeros((curr_frame['reference'].shape[1], curr_frame['reference'].shape[2]), dtype=np.float32)
        
        if 'depth' in curr_frame:
            depth_occlusion = self._compute_depth_discontinuity(curr_frame['depth'])
        
        motion_occlusion = np.zeros_like(depth_occlusion)
        
        if 'motion' in curr_frame:
            motion_occlusion = self._compute_motion_discontinuity(curr_frame['motion'])
        
        occlusion_mask = np.maximum(depth_occlusion, motion_occlusion)
        
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
        occlusion_mask = cv2.morphologyEx(occlusion_mask, cv2.MORPH_CLOSE, kernel)
        
        return occlusion_mask
    
    def _classify_holes(self, 
                       hole_mask: np.ndarray, 
                       curr_frame: Dict, 
                       prev_frame: Dict) -> Tuple[np.ndarray, np.ndarray]:
        """åˆ†ç±»é™æ€å’ŒåŠ¨æ€ç©ºæ´"""
        # ç®€åŒ–çš„åˆ†ç±»ï¼šåŸºäºè¿åŠ¨å¹…åº¦
        static_holes = hole_mask.copy()
        dynamic_holes = np.zeros_like(hole_mask)
        
        if 'motion' in curr_frame:
            motion_magnitude = np.sqrt(
                curr_frame['motion'][0]**2 + curr_frame['motion'][1]**2
            )
            
            # åŠ¨æ€åŒºåŸŸï¼šè¿åŠ¨å¹…åº¦å¤§çš„åŒºåŸŸ
            dynamic_threshold = np.percentile(motion_magnitude, 75)
            dynamic_regions = motion_magnitude > dynamic_threshold
            
            # é‡æ–°åˆ†é…ç©ºæ´ç±»å‹
            dynamic_holes = hole_mask * dynamic_regions.astype(np.float32)
            static_holes = hole_mask * (~dynamic_regions).astype(np.float32)
        
        return static_holes, dynamic_holes
    
    # ==================== è®­ç»ƒæ•°æ®ç”Ÿæˆæ¨¡å— ====================
    
    def generate_training_data(self, 
                             curr_frame: Dict, 
                             prev_frame: Dict,
                             next_frame_gt: Optional[Dict] = None,
                             extrapolation_factor: float = 1.0) -> Dict:
        """
        ç”Ÿæˆå®Œæ•´çš„è®­ç»ƒæ•°æ® - ã€å¤–æ’ä¿®å¤ç‰ˆã€‘
        
        Args:
            curr_frame: å½“å‰å¸§æ•°æ®
            prev_frame: å‰ä¸€å¸§æ•°æ®
            next_frame_gt: ä¸‹ä¸€å¸§Ground Truthæ•°æ®ï¼ˆå¤–æ’æ¨¡å¼ï¼‰
            extrapolation_factor: å¤–æ¨ç³»æ•°ï¼Œé»˜è®¤1.0è¡¨ç¤ºå®Œæ•´çš„ä¸‹ä¸€å¸§
            
        Returns:
            training_data: åŒ…å«æ‰€æœ‰è®­ç»ƒæ•°æ®çš„å­—å…¸
        """
        print(f"   ğŸ”§ ç”Ÿæˆè®­ç»ƒæ•°æ®ï¼Œå¤–æ¨ç³»æ•°: {extrapolation_factor}")
        
        # 1. è®¡ç®—æ­£ç¡®çš„å±å¹•ç©ºé—´è¿åŠ¨çŸ¢é‡
        base_mv = self._compute_screen_space_mv(curr_frame, prev_frame)
        
        # 2. åº”ç”¨å¤–æ¨ç³»æ•°
        extrapolated_mv = base_mv * extrapolation_factor
        
        # 3. å‰å‘æŠ•å½±
        if next_frame_gt is not None:
            # å¤–æ’æ¨¡å¼ï¼šä»å½“å‰å¸§å¤–æ¨åˆ°ä¸‹ä¸€å¸§
            print(f"   å¤–æ’æ¨¡å¼ï¼št -> t+{extrapolation_factor}")
            warped_image, coverage_mask = self.forward_warp_frame(
                curr_frame, extrapolated_mv
            )
            target_rgb = next_frame_gt['reference']
        else:
            # é‡æŠ•å½±æ¨¡å¼ï¼šä»å‰ä¸€å¸§æŠ•å½±åˆ°å½“å‰å¸§
            print(f"   é‡æŠ•å½±æ¨¡å¼ï¼št-1 -> t")
            warped_image, coverage_mask = self.forward_warp_frame(
                prev_frame, base_mv
            )
            target_rgb = curr_frame['reference']
        
        # 4. ç©ºæ´å’Œé®æŒ¡æ£€æµ‹
        if next_frame_gt is not None:
            # å¤–æ’æ¨¡å¼ï¼šä½¿ç”¨å¤–æ¨è¿åŠ¨çŸ¢é‡
            motion_vectors_for_occlusion = extrapolated_mv
        else:
            # é‡æŠ•å½±æ¨¡å¼ï¼šä½¿ç”¨åŸºç¡€è¿åŠ¨çŸ¢é‡
            motion_vectors_for_occlusion = base_mv
            
        masks = self.detect_holes_and_occlusion(
            warped_image, target_rgb, coverage_mask, curr_frame, prev_frame, motion_vectors_for_occlusion
        )
        
        # 5. æ®‹å·®è¿åŠ¨çŸ¢é‡è®¡ç®—
        if next_frame_gt is not None:
            # è®¡ç®—çœŸå®çš„t->t+1è¿åŠ¨çŸ¢é‡å¹¶è®¡ç®—æ®‹å·®
            try:
                gt_mv = self._compute_screen_space_mv(next_frame_gt, curr_frame)
                residual_mv = gt_mv - extrapolated_mv
            except:
                residual_mv = self._compute_residual_motion_vectors(
                    warped_image, target_rgb, extrapolated_mv, masks['holes']
                )
        else:
            residual_mv = self._compute_residual_motion_vectors(
                warped_image, target_rgb, base_mv, masks['holes']
            )
        
        # 6. ç»„è£…è®­ç»ƒæ•°æ®
        # ç½‘ç»œè®­ç»ƒéœ€è¦çš„æ•°æ®ï¼šwarped_RGB(3) + å‡ ä½•ç©ºæ´(1) + é®æŒ¡æ©ç (1) + æ®‹å·®MV(2) = 7é€šé“
        # ä¿®å¤å…³é”®é”™è¯¯ï¼šè¾“å…¥åº”è¯¥æ˜¯å¸¦ç©ºæ´çš„å¤–æ¨å›¾åƒï¼Œè€Œä¸æ˜¯çœŸå®RGBï¼
        training_sample = np.concatenate([
            warped_image,                                  # âœ… ä¿®å¤ï¼šä½¿ç”¨å¸¦ç©ºæ´çš„å¤–æ¨å›¾åƒ (3)
            masks['holes'][np.newaxis],                    # âœ… ä¿®å¤ï¼šä½¿ç”¨å‡ ä½•ç©ºæ´æ©ç  (1) - åŸºäºè¦†ç›–åº¦çš„å‡†ç¡®ç©ºæ´æ£€æµ‹
            masks['occlusion'][np.newaxis],                # é®æŒ¡æ©ç  (1)
            residual_mv,                                   # æ®‹å·®è¿åŠ¨çŸ¢é‡ (2)
            target_rgb                                     # ç›®æ ‡RGB (3)
        ], axis=0)
        
        return {
            'target_rgb': target_rgb,
            'warped_image': warped_image,
            'coverage_mask': coverage_mask,
            'hole_mask': masks['holes'],
            'semantic_holes': masks.get('semantic_holes', masks['holes']),  # éå‡ ä½•ç©ºæ´æ£€æµ‹ç»“æœ
            'occlusion_mask': masks['occlusion'],
            'static_holes': masks['static_holes'],
            'dynamic_holes': masks['dynamic_holes'],
            'residual_mv': residual_mv,
            'training_sample': training_sample,
            'base_mv': base_mv,
            'extrapolated_mv': extrapolated_mv,
            'extrapolation_factor': extrapolation_factor
        }
    
    def _compute_residual_motion_vectors(self, 
                                       warped_image: np.ndarray,
                                       target_image: np.ndarray,
                                       original_mv: np.ndarray,
                                       hole_mask: np.ndarray) -> np.ndarray:
        """è®¡ç®—æ®‹å·®è¿åŠ¨çŸ¢é‡"""
        # è®¡ç®—å¤–æ¨å›¾åƒä¸ç›®æ ‡å›¾åƒçš„é¢œè‰²å·®å¼‚
        color_diff = np.mean(np.abs(warped_image - target_image), axis=0)
        
        # åŸºäºé¢œè‰²å·®å¼‚å’Œç©ºæ´æ©ç è®¡ç®—æ®‹å·®æƒé‡
        residual_weight = np.minimum(color_diff / (color_diff.max() + 1e-8), 1.0)
        residual_weight = np.maximum(residual_weight, hole_mask * 0.5)
        
        # ç”Ÿæˆæ®‹å·®è¿åŠ¨çŸ¢é‡ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
        residual_mv = np.zeros_like(original_mv)
        
        # åœ¨ç©ºæ´åŒºåŸŸåº”ç”¨æ›´å¼ºçš„æ®‹å·®ï¼ˆç§»é™¤éšæœºå™ªå£°ç¡®ä¿è®­ç»ƒç¨³å®šæ€§ï¼‰
        residual_mv[0] = original_mv[0] * 0.1 * residual_weight
        residual_mv[1] = original_mv[1] * 0.1 * residual_weight
        
        # é™åˆ¶æ®‹å·®å¹…åº¦
        residual_magnitude = np.sqrt(residual_mv[0]**2 + residual_mv[1]**2)
        max_residual = self.residual_threshold
        
        mask = residual_magnitude > max_residual
        if np.any(mask):
            scale = max_residual / (residual_magnitude + 1e-8)
            residual_mv[0] = np.where(mask, residual_mv[0] * scale, residual_mv[0])
            residual_mv[1] = np.where(mask, residual_mv[1] * scale, residual_mv[1])
        
        return residual_mv
    
    # ==================== ä¸»å¤„ç†æµç¨‹ ====================
    
    def process_frame_pair(self, frame_idx: int) -> bool:
        """
        å¤„ç†å•ä¸ªå¸§å¯¹ï¼ˆé‡æŠ•å½±æ¨¡å¼ï¼‰
        
        Args:
            frame_idx: å½“å‰å¸§ç´¢å¼•ï¼ˆéœ€è¦å‰ä¸€å¸§ frame_idx-1ï¼‰
            
        Returns:
            success: å¤„ç†æ˜¯å¦æˆåŠŸ
        """
        try:
            # åŠ è½½å¸§æ•°æ®
            curr_frame = self.load_frame_data(self.scene_name, frame_idx)
            prev_frame = self.load_frame_data(self.scene_name, frame_idx - 1)
            
            if curr_frame is None or prev_frame is None:
                return False
            
            # ç”Ÿæˆè®­ç»ƒæ•°æ®ï¼ˆä¸ä½¿ç”¨å¤–æ¨ï¼Œç”¨äºéªŒè¯ï¼‰
            training_data = self.generate_training_data(
                curr_frame, prev_frame, next_frame_gt=None, extrapolation_factor=1.0
            )
            
            # ä¿å­˜ç»“æœ
            self._save_results(frame_idx, training_data)
            
            # åˆ›å»ºå¯è§†åŒ–
            self._create_visualization(frame_idx, training_data)
            
            # å¤„ç†å®Œæˆ
            
            # å¼ºåˆ¶åƒåœ¾å›æ”¶ï¼Œé‡Šæ”¾å†…å­˜å’Œä¸´æ—¶æ–‡ä»¶
            del curr_frame, prev_frame, training_data
            gc.collect()
            
            return True
            
        except Exception as e:
            import traceback
            traceback.print_exc()
            
            # å¼‚å¸¸æƒ…å†µä¸‹ä¹Ÿè¦å°è¯•åƒåœ¾å›æ”¶
            gc.collect()
            return False

    def process_frame_triplet(self, frame_idx_t: int, extrapolation_factor: float = 1.0) -> bool:
        """
        å¤„ç†å•ä¸ªå¸§ä¸‰å…ƒç»„ (t-1, t, t+1)ï¼Œä¸º t->t+x çš„å¤–æ’ç”Ÿæˆæ•°æ®ã€‚
        
        Args:
            frame_idx_t: å½“å‰å¸§(t)çš„ç´¢å¼•
            extrapolation_factor: å¤–æ¨ç³»æ•°ï¼Œé»˜è®¤1.0è¡¨ç¤ºå®Œæ•´å¤–æ¨åˆ°t+1
            
        Returns:
            success: å¤„ç†æ˜¯å¦æˆåŠŸ
        """
        try:
            # åŠ è½½ä¸‰å¸§æ•°æ®
            prev_frame = self.load_frame_data(self.scene_name, frame_idx_t - 1)
            curr_frame = self.load_frame_data(self.scene_name, frame_idx_t)
            next_frame_gt = self.load_frame_data(self.scene_name, frame_idx_t + 1)
            
            if prev_frame is None or curr_frame is None or next_frame_gt is None:
                print(f"æ— æ³•åŠ è½½å¸§ä¸‰å…ƒç»„ {frame_idx_t-1} -> {frame_idx_t} -> {frame_idx_t+1}")
                return False
            
            print(f"å¤„ç†å¸§ä¸‰å…ƒç»„: {frame_idx_t-1} -> {frame_idx_t} (é¢„æµ‹) -> {frame_idx_t+1} (GT)")
            
            # ç”Ÿæˆå¤–æ’è®­ç»ƒæ•°æ®
            training_data = self.generate_training_data(
                curr_frame, prev_frame, next_frame_gt, extrapolation_factor
            )
            
            # ä¿å­˜ç»“æœ (ä¿å­˜æ—¶ä»¥å½“å‰å¸§ t çš„ç´¢å¼•ä¸ºå)
            self._save_results(frame_idx_t, training_data)
            
            # åˆ›å»ºå¯è§†åŒ–
            self._create_visualization(frame_idx_t, training_data)
            
            print(f"å¸§ {frame_idx_t} çš„å¤–æ’æ•°æ®å¤„ç†å®Œæˆ")
            
            # å¼ºåˆ¶åƒåœ¾å›æ”¶
            del prev_frame, curr_frame, next_frame_gt, training_data
            gc.collect()
            
            return True
            
        except Exception as e:
            print(f"å¤„ç†å¸§ä¸‰å…ƒç»„ {frame_idx_t} å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        gc.collect()
        return False

    def process_scene(self, 
                     start_frame: int = 1,
                     end_frame: Optional[int] = None,
                     max_frames: Optional[int] = None,
                     mode: str = "triplet",
                     extrapolation_factor: float = 1.0) -> Dict:
        """
        å¤„ç†æ•´ä¸ªåœºæ™¯
        
        Args:
            start_frame: èµ·å§‹å¸§ï¼ˆé»˜è®¤ä»1å¼€å§‹ï¼Œå› ä¸ºéœ€è¦å‰ä¸€å¸§ï¼‰
            end_frame: ç»“æŸå¸§
            max_frames: æœ€å¤§å¤„ç†å¸§æ•°
            mode: å¤„ç†æ¨¡å¼ - "triplet"(å¤–æ’æ¨¡å¼) æˆ– "pair"(é‡æŠ•å½±æ¨¡å¼)
            extrapolation_factor: å¤–æ¨ç³»æ•°ï¼ˆä»…åœ¨tripletæ¨¡å¼ä¸‹ä½¿ç”¨ï¼‰
            
        Returns:
            results: å¤„ç†ç»“æœç»Ÿè®¡
        """
        print(f"å¼€å§‹å¤„ç†åœºæ™¯: {self.scene_name}")
        print(f"å¤„ç†æ¨¡å¼: {mode.upper()} ({'å¤–æ’' if mode == 'triplet' else 'é‡æŠ•å½±'})")
        if mode == "triplet":
            print(f"å¤–æ¨ç³»æ•°: {extrapolation_factor}")
        
        # ç¡®å®šå¤„ç†èŒƒå›´
        scene_dir = self.data_root / self.scene_name
        available_frames = sorted([
            int(f.stem.replace('frame', '')) 
            for f in scene_dir.glob('frame*.zip')
        ])
        
        if not available_frames:
            raise ValueError(f"åœºæ™¯ {self.scene_name} ä¸­æ²¡æœ‰æ‰¾åˆ°å¸§æ•°æ®")
        
        if end_frame is None:
            end_frame = max(available_frames)
        
        # æ ¹æ®æ¨¡å¼è°ƒæ•´å¤„ç†èŒƒå›´
        if mode == "triplet":
            # ä¸‰å…ƒç»„æ¨¡å¼ï¼šç¡®ä¿èµ·å§‹å¸§æœ‰å‰ä¸€å¸§ï¼Œç»“æŸå¸§æœ‰åä¸€å¸§
            start_frame = max(start_frame, min(available_frames) + 1)
            end_frame = min(end_frame, max(available_frames) - 1)
            print(f"ä¸‰å…ƒç»„æ¨¡å¼ï¼šéœ€è¦t-1, t, t+1ä¸‰å¸§æ•°æ®")
        else:
            # å¸§å¯¹æ¨¡å¼ï¼šç¡®ä¿èµ·å§‹å¸§æœ‰å‰ä¸€å¸§
            start_frame = max(start_frame, min(available_frames) + 1)
            end_frame = min(end_frame, max(available_frames))
            print(f"å¸§å¯¹æ¨¡å¼ï¼šéœ€è¦t-1, tä¸¤å¸§æ•°æ®")
        
        if max_frames:
            end_frame = min(end_frame, start_frame + max_frames - 1)
        
        print(f"å¤„ç†èŒƒå›´: frame {start_frame} åˆ° frame {end_frame} (ä½œä¸ºæ—¶é—´ç‚¹ t)")
        print(f"å¯ç”¨å¸§: {len(available_frames)} å¸§")
        
        # å¤„ç†ç»Ÿè®¡
        results = {
            'total_frames': end_frame - start_frame + 1,
            'successful_frames': 0,
            'failed_frames': 0,
            'start_time': time.time(),
            'mode': mode,
            'extrapolation_factor': extrapolation_factor
        }
        
        # é€å¸§å¤„ç†
        for frame_idx in tqdm(range(start_frame, end_frame + 1), desc=f"å¤„ç†å¸§({mode})"):
            if mode == "triplet":
                success = self.process_frame_triplet(frame_idx, extrapolation_factor)
            else:
                success = self.process_frame_pair(frame_idx)
                
            if success:
                results['successful_frames'] += 1
            else:
                results['failed_frames'] += 1
            
            # æ¯10å¸§å¼ºåˆ¶åƒåœ¾å›æ”¶ï¼Œé˜²æ­¢å†…å­˜ç´¯ç§¯
            if frame_idx % 10 == 0:
                gc.collect()
                print(f"ğŸ§¹ ç¬¬{frame_idx}å¸§: æ‰§è¡Œåƒåœ¾å›æ”¶")
        
        results['end_time'] = time.time()
        results['total_time'] = results['end_time'] - results['start_time']
        
        # è¾“å‡ºå¤„ç†ç»“æœç»Ÿè®¡
        print(f"\nğŸ“Š å¤„ç†å®Œæˆç»Ÿè®¡:")
        print(f"   æ¨¡å¼: {mode.upper()} ({'å¤–æ’' if mode == 'triplet' else 'é‡æŠ•å½±'})")
        if mode == "triplet":
            print(f"   å¤–æ¨ç³»æ•°: {extrapolation_factor}")
        print(f"   æ€»å¸§æ•°: {results['total_frames']}")
        print(f"   æˆåŠŸ: {results['successful_frames']}")
        print(f"   å¤±è´¥: {results['failed_frames']}")
        print(f"   æˆåŠŸç‡: {results['successful_frames']/results['total_frames']*100:.1f}%")
        print(f"   æ€»æ—¶é—´: {results['total_time']:.1f}ç§’")
        print(f"   å¹³å‡æ¯å¸§: {results['total_time']/results['total_frames']:.2f}ç§’")
        
        # ä¿å­˜å¤„ç†ç»Ÿè®¡
        stats_file = self.output_dir / f'processing_stats_{mode}.json'
        with open(stats_file, 'w') as f:
            json.dump(results, f, indent=2)
        
        return results
    
    # ==================== è¾“å‡ºå’Œå¯è§†åŒ–æ¨¡å— ====================
    
    def _save_results(self, frame_idx: int, training_data: Dict):
        """ä¿å­˜å¤„ç†ç»“æœ"""
        frame_name = f"frame_{frame_idx:06d}"
        
        # ä¿å­˜RGBå›¾åƒ
        rgb_path = self.output_dir / 'rgb' / f"{frame_name}.npy"
        np.save(rgb_path, training_data['target_rgb'])
        
        # ä¿å­˜å¤–æ¨å›¾åƒ
        warped_path = self.output_dir / 'warped' / f"{frame_name}.npy"
        np.save(warped_path, training_data['warped_image'])
        
        # ä¿å­˜æ©ç 
        masks_dir = self.output_dir / 'masks'
        # ä¿å­˜å‡ ä½•ç©ºæ´ï¼ˆåŸºäºè¦†ç›–åº¦çš„å‡†ç¡®ç©ºæ´æ£€æµ‹ï¼‰
        np.save(masks_dir / f"{frame_name}_holes.npy", training_data['hole_mask'])
        np.save(masks_dir / f"{frame_name}_occlusion.npy", training_data['occlusion_mask'])
        # ä¿å­˜é™æ€å’ŒåŠ¨æ€ç©ºæ´ï¼ˆåŸºäºå‡ ä½•ç©ºæ´çš„åˆ†ç±»ï¼Œä»…ä¾›å‚è€ƒï¼‰
        np.save(masks_dir / f"{frame_name}_static_holes.npy", training_data['static_holes'])
        np.save(masks_dir / f"{frame_name}_dynamic_holes.npy", training_data['dynamic_holes'])
        
        # ä¿å­˜æ®‹å·®è¿åŠ¨çŸ¢é‡
        residual_path = self.output_dir / 'residual_mv' / f"{frame_name}.npy"
        np.save(residual_path, training_data['residual_mv'])
        
        # ä¿å­˜7é€šé“è®­ç»ƒæ•°æ®
        training_path = self.output_dir / 'training_data' / f"{frame_name}.npy"
        np.save(training_path, training_data['training_sample'])
        
        # ä¿å­˜PNGæ ¼å¼çš„å¯è§†åŒ–å›¾åƒ
        self._save_visualization_images(frame_idx, training_data)
    
    def _save_visualization_images(self, frame_idx: int, training_data: Dict):
        """ä¿å­˜å¯è§†åŒ–å›¾åƒ - ä¿®å¤ä¸ºä¿å­˜HDRæ ¼å¼ï¼ˆEXRï¼‰å’Œå¯è§†åŒ–æ ¼å¼ï¼ˆPNGï¼‰"""
        frame_name = f"frame_{frame_idx:06d}"
        
        # ä¿å­˜HDRæ ¼å¼çš„RGBå›¾åƒï¼ˆEXRï¼‰- æŒ‰detach.pyæ–¹å¼
        try:
            rgb_hdr = training_data['target_rgb'].transpose(1, 2, 0)  # CHW -> HWC
            self._save_exr_image(self.output_dir / 'rgb' / f"{frame_name}.exr", rgb_hdr)
            print(f"   ä¿å­˜HDR RGB: {frame_name}.exr")
        except Exception as e:
            print(f"   HDR RGBä¿å­˜å¤±è´¥: {e}")
        
        # ä¿å­˜å¯è§†åŒ–ç”¨çš„PNGå›¾åƒï¼ˆè‰²è°ƒæ˜ å°„åï¼‰
        try:
            rgb = training_data['target_rgb'].transpose(1, 2, 0)
            # ç®€å•çš„è‰²è°ƒæ˜ å°„è€Œéç¡¬æˆªæ–­
            rgb_mapped = self._tone_map_for_display(rgb)
            rgb_uint8 = (rgb_mapped * 255).astype(np.uint8)
            cv2.imwrite(str(self.output_dir / 'rgb' / f"{frame_name}.png"), 
                       cv2.cvtColor(rgb_uint8, cv2.COLOR_RGB2BGR))
        except Exception as e:
            print(f"   PNG RGBä¿å­˜å¤±è´¥: {e}")
        
        # å¤–æ¨å›¾åƒä¹Ÿä¿å­˜HDRå’Œå¯è§†åŒ–ä¸¤ä¸ªç‰ˆæœ¬
        try:
            warped_hdr = training_data['warped_image'].transpose(1, 2, 0)
            self._save_exr_image(self.output_dir / 'warped' / f"{frame_name}.exr", warped_hdr)
            
            warped_mapped = self._tone_map_for_display(warped_hdr)
            warped_uint8 = (warped_mapped * 255).astype(np.uint8)
            cv2.imwrite(str(self.output_dir / 'warped' / f"{frame_name}.png"),
                       cv2.cvtColor(warped_uint8, cv2.COLOR_RGB2BGR))
        except Exception as e:
            print(f"   å¤–æ¨å›¾åƒä¿å­˜å¤±è´¥: {e}")
        
        # æ©ç å›¾åƒï¼ˆä¿æŒPNGæ ¼å¼ï¼‰
        try:
            masks_dir = self.output_dir / 'masks'
            # ä¿å­˜å‡ ä½•ç©ºæ´PNGï¼ˆåŸºäºè¦†ç›–åº¦çš„å‡†ç¡®ç©ºæ´æ£€æµ‹ï¼‰
            cv2.imwrite(str(masks_dir / f"{frame_name}_holes.png"), 
                       (training_data['hole_mask'] * 255).astype(np.uint8))
            cv2.imwrite(str(masks_dir / f"{frame_name}_occlusion.png"), 
                       (training_data['occlusion_mask'] * 255).astype(np.uint8))
        except Exception as e:
            print(f"   æ©ç ä¿å­˜å¤±è´¥: {e}")
    
    def _save_exr_image(self, file_path: Path, image_data: np.ndarray):
        """ä¿å­˜EXRæ ¼å¼å›¾åƒ - ä½¿ç”¨detach.pyçš„æ–¹æ³•"""
        try:
            import OpenEXR
            import Imath
            
            # ç¡®ä¿å›¾åƒæ•°æ®æ˜¯HWCæ ¼å¼çš„float32
            if image_data.shape[0] == 3:  # CHW -> HWC
                image_data = image_data.transpose(1, 2, 0)
            
            image_data = image_data.astype(np.float32)
            
            # åˆ›å»ºEXRæ–‡ä»¶å¤´
            header = OpenEXR.Header(image_data.shape[1], image_data.shape[0])
            header['channels'] = {name: Imath.Channel(Imath.PixelType(Imath.PixelType.FLOAT)) 
                                 for name in ['R', 'G', 'B']}
            
            # åˆ›å»ºè¾“å‡ºæ–‡ä»¶
            out_file = OpenEXR.OutputFile(str(file_path), header)
            
            # å†™å…¥é€šé“æ•°æ®
            patch_data = {}
            for i, channel_name in enumerate(['R', 'G', 'B']):
                patch_data[channel_name] = image_data[:, :, i].flatten().astype(np.float32).tobytes()
            
            out_file.writePixels(patch_data)
            out_file.close()
            
        except ImportError:
            print(f"   OpenEXRæœªå®‰è£…ï¼Œè·³è¿‡EXRä¿å­˜: {file_path}")
        except Exception as e:
            print(f"   EXRä¿å­˜å¤±è´¥: {e}")
    
    def _tone_map_for_display(self, hdr_image: np.ndarray) -> np.ndarray:
        """å¯¹HDRå›¾åƒè¿›è¡Œè‰²è°ƒæ˜ å°„ç”¨äºæ˜¾ç¤º"""
        # ç®€å•çš„Reinhardè‰²è°ƒæ˜ å°„
        return hdr_image / (1.0 + hdr_image)
    
    def _create_visualization(self, frame_idx: int, training_data: Dict):
        """åˆ›å»ºç»¼åˆå¯è§†åŒ–"""
        frame_name = f"frame_{frame_idx:06d}"
        
        # åˆ›å»ºå¤šå­å›¾å¯è§†åŒ–
        fig, axes = plt.subplots(2, 4, figsize=(16, 8))
        fig.suptitle(f'Frame {frame_idx} Processing Results', fontsize=16)
        
        # ç›®æ ‡RGB
        rgb = training_data['target_rgb'].transpose(1, 2, 0)
        rgb = np.clip(rgb, 0, 1)
        axes[0, 0].imshow(rgb)
        axes[0, 0].set_title('Target RGB')
        axes[0, 0].axis('off')
        
        # å¤–æ¨å›¾åƒ
        warped = training_data['warped_image'].transpose(1, 2, 0)
        warped = np.clip(warped, 0, 1)
        axes[0, 1].imshow(warped)
        axes[0, 1].set_title('Warped Image')
        axes[0, 1].axis('off')
        
        # è¦†ç›–æ©ç 
        im1 = axes[0, 2].imshow(training_data['coverage_mask'], cmap='viridis')
        axes[0, 2].set_title('Coverage Mask')
        axes[0, 2].axis('off')
        plt.colorbar(im1, ax=axes[0, 2], fraction=0.046)
        
        # å‡ ä½•ç©ºæ´
        axes[0, 3].imshow(training_data['hole_mask'], cmap='Reds')
        axes[0, 3].set_title('Geometric Holes')
        axes[0, 3].axis('off')
        
        # å‡ ä½•ç©ºæ´æ£€æµ‹ï¼ˆç½‘ç»œè®­ç»ƒè¾“å…¥ï¼‰
        axes[1, 0].imshow(training_data['hole_mask'], cmap='Blues')
        axes[1, 0].set_title('Geometric Holes (Network Input)')
        axes[1, 0].axis('off')
        
        # é™æ€ç©ºæ´
        axes[1, 1].imshow(training_data['static_holes'], cmap='Oranges')
        axes[1, 1].set_title('Static Holes(Geometric)')
        axes[1, 1].axis('off')
        
        # åŠ¨æ€ç©ºæ´
        axes[1, 2].imshow(training_data['dynamic_holes'], cmap='Purples')
        axes[1, 2].set_title('Dynamic Holes(Geometric)')
        axes[1, 2].axis('off')
        
        # æ®‹å·®è¿åŠ¨çŸ¢é‡å¹…åº¦
        residual_mag = np.sqrt(training_data['residual_mv'][0]**2 + training_data['residual_mv'][1]**2)
        im2 = axes[1, 3].imshow(residual_mag, cmap='plasma')
        axes[1, 3].set_title('Residual MV Magnitude')
        axes[1, 3].axis('off')
        plt.colorbar(im2, ax=axes[1, 3], fraction=0.046)
        
        plt.tight_layout()
        vis_path = self.output_dir / 'visualization' / f"{frame_name}_analysis.png"
        plt.savefig(vis_path, dpi=150, bbox_inches='tight')
        plt.close()


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='Unified NoiseBase Preprocessor')
    parser.add_argument('--data-root', type=str, required=True, 
                       help='NoiseBaseæ•°æ®æ ¹ç›®å½•')
    parser.add_argument('--output', type=str, required=True,
                       help='è¾“å‡ºç›®å½•')
    parser.add_argument('--scene', type=str, default='bistro1',
                       help='åœºæ™¯åç§°')
    parser.add_argument('--start-frame', type=int, default=1,
                       help='èµ·å§‹å¸§')
    parser.add_argument('--end-frame', type=int, default=None,
                       help='ç»“æŸå¸§')
    parser.add_argument('--max-frames', type=int, default=None,
                       help='æœ€å¤§å¤„ç†å¸§æ•°')
    parser.add_argument('--hole-threshold', type=float, default=0.3,
                       help='ç©ºæ´æ£€æµ‹é˜ˆå€¼')
    parser.add_argument('--use-numba', action='store_true',
                       help='ä½¿ç”¨NumbaåŠ é€Ÿ')
    parser.add_argument('--test-mode', action='store_true',
                       help='æµ‹è¯•æ¨¡å¼ï¼ˆåªå¤„ç†å‡ å¸§ï¼‰')
    
    args = parser.parse_args()
    
    try:
        # åˆ›å»ºé¢„å¤„ç†å™¨
        preprocessor = UnifiedNoiseBasePreprocessor(
            data_root=args.data_root,
            output_dir=args.output,
            scene_name=args.scene,
            hole_threshold=args.hole_threshold,
            use_numba=args.use_numba
        )
        
        # æµ‹è¯•æ¨¡å¼
        if args.test_mode:
            args.max_frames = 3
        
        # å¤„ç†åœºæ™¯
        results = preprocessor.process_scene(
            start_frame=args.start_frame,
            end_frame=args.end_frame,
            max_frames=args.max_frames
        )
        
        if results['successful_frames'] > 0:
            print(f"\né¢„å¤„ç†å®Œæˆï¼è¾“å‡ºç›®å½•: {args.output}")
            print(f"è®­ç»ƒæ•°æ®æ ¼å¼: 7é€šé“ [RGB(3) + HoleMask(1) + OcclusionMask(1) + ResidualMV(2)]")
        else:
            print("\né¢„å¤„ç†å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ•°æ®å’Œå‚æ•°")
            sys.exit(1)
            
    except Exception as e:
        print(f"\né¢„å¤„ç†å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()