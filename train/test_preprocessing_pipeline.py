#!/usr/bin/env python3
"""
@file test_preprocessing_pipeline.py
@brief æµ‹è¯•å®Œæ•´çš„NoiseBaseé¢„å¤„ç†å’Œè®­ç»ƒæµæ°´çº¿

åŠŸèƒ½æè¿°ï¼š
- æµ‹è¯•NoiseBaseæ•°æ®é¢„å¤„ç†æµç¨‹
- éªŒè¯6é€šé“è®­ç»ƒæ•°æ®ç”Ÿæˆ
- æµ‹è¯•æ•°æ®é›†åŠ è½½å’Œè®­ç»ƒæ¡†æ¶é›†æˆ
- æä¾›è¯¦ç»†çš„æ•°æ®è´¨é‡æŠ¥å‘Š

@author AIç®—æ³•å›¢é˜Ÿ
@date 2025-07-28
@version 1.0
"""

import os
import sys
import numpy as np
import torch
from pathlib import Path
from typing import Dict, Optional
import matplotlib.pyplot as plt

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / "training"))
sys.path.insert(0, str(project_root / "src"))

from training.noisebase_preprocessor import NoiseBasePreprocessor
from training.create_dataset_splits import DatasetSplitCreator
from training.datasets.noisebase_dataset import NoiseBaseDataset, create_noisebase_dataset
from src.npu.networks.mobile_inpainting_network import MobileInpaintingNetwork


class PreprocessingPipelineTester:
    """é¢„å¤„ç†æµæ°´çº¿æµ‹è¯•å™¨"""
    
    def __init__(self, 
                 input_dir: str = "./training",
                 output_dir: str = "./training/processed_test",
                 scene_name: str = "bistro1"):
        """
        åˆå§‹åŒ–æµ‹è¯•å™¨
        
        Args:
            input_dir: NoiseBaseåŸå§‹æ•°æ®ç›®å½•
            output_dir: é¢„å¤„ç†è¾“å‡ºç›®å½•
            scene_name: åœºæ™¯åç§°
        """
        self.input_dir = Path(input_dir)
        self.output_dir = Path(output_dir)
        self.scene_name = scene_name
        
        # æµ‹è¯•å‚æ•°
        self.test_frame_count = 10  # æµ‹è¯•å‰10å¸§
        self.patch_size = 64
        
        print("="*80)
        print("ğŸ§ª NoiseBaseé¢„å¤„ç†æµæ°´çº¿æµ‹è¯•")
        print("="*80)
        print(f"è¾“å…¥ç›®å½•: {self.input_dir}")
        print(f"è¾“å‡ºç›®å½•: {self.output_dir}")
        print(f"æµ‹è¯•åœºæ™¯: {self.scene_name}")
        print(f"æµ‹è¯•å¸§æ•°: {self.test_frame_count}")
        print("="*80)
    
    def test_data_availability(self) -> bool:
        """
        æµ‹è¯•åŸå§‹æ•°æ®å¯ç”¨æ€§
        
        Returns:
            available: æ•°æ®æ˜¯å¦å¯ç”¨
        """
        print("\nğŸ” Step 1: æ£€æŸ¥åŸå§‹æ•°æ®å¯ç”¨æ€§...")
        
        scene_dir = self.input_dir / self.scene_name
        if not scene_dir.exists():
            print(f"âŒ åœºæ™¯ç›®å½•ä¸å­˜åœ¨: {scene_dir}")
            return False
        
        # æ£€æŸ¥å‰å‡ å¸§æ•°æ®
        available_frames = 0
        for i in range(self.test_frame_count):
            frame_file = scene_dir / f"frame{i:04d}.zip"
            if frame_file.exists():
                available_frames += 1
            else:
                break
        
        print(f"âœ… æ‰¾åˆ° {available_frames} ä¸ªå¯ç”¨å¸§æ–‡ä»¶")
        
        if available_frames < 2:
            print("âŒ éœ€è¦è‡³å°‘2å¸§æ•°æ®è¿›è¡Œæµ‹è¯•")
            return False
        
        # æ›´æ–°å®é™…æµ‹è¯•å¸§æ•°
        self.test_frame_count = min(self.test_frame_count, available_frames)
        print(f"ğŸ“Š å°†æµ‹è¯•å‰ {self.test_frame_count} å¸§")
        
        return True
    
    def test_preprocessing(self) -> bool:
        """
        æµ‹è¯•æ•°æ®é¢„å¤„ç†
        
        Returns:
            success: é¢„å¤„ç†æ˜¯å¦æˆåŠŸ
        """
        print("\nâš™ï¸ Step 2: æµ‹è¯•æ•°æ®é¢„å¤„ç†...")
        
        try:
            # åˆ›å»ºé¢„å¤„ç†å™¨
            preprocessor = NoiseBasePreprocessor(
                input_dir=str(self.input_dir),
                output_dir=str(self.output_dir),
                scene_name=self.scene_name
            )
            
            # å¤„ç†æµ‹è¯•åºåˆ—
            preprocessor.process_sequence(
                start_frame=0,
                end_frame=self.test_frame_count - 1
            )
            
            print("âœ… é¢„å¤„ç†å®Œæˆ")
            return True
            
        except Exception as e:
            print(f"âŒ é¢„å¤„ç†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def test_data_quality(self) -> Dict:
        """
        æµ‹è¯•ç”Ÿæˆæ•°æ®çš„è´¨é‡
        
        Returns:
            quality_report: è´¨é‡æŠ¥å‘Š
        """
        print("\nğŸ“Š Step 3: åˆ†æç”Ÿæˆæ•°æ®è´¨é‡...")
        
        scene_path = self.output_dir / self.scene_name
        training_data_dir = scene_path / 'training_data'
        
        if not training_data_dir.exists():
            print("âŒ è®­ç»ƒæ•°æ®ç›®å½•ä¸å­˜åœ¨")
            return {}
        
        # åˆ†ææ‰€æœ‰è®­ç»ƒæ•°æ®æ–‡ä»¶
        training_files = list(training_data_dir.glob("*.npy"))
        
        if len(training_files) == 0:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°è®­ç»ƒæ•°æ®æ–‡ä»¶")
            return {}
        
        print(f"ğŸ“ æ‰¾åˆ° {len(training_files)} ä¸ªè®­ç»ƒæ•°æ®æ–‡ä»¶")
        
        quality_metrics = {
            'file_count': len(training_files),
            'shapes': [],
            'rgb_stats': [],
            'hole_ratios': [],
            'mv_magnitudes': []
        }
        
        # åˆ†ææ¯ä¸ªæ–‡ä»¶
        for file_path in training_files[:5]:  # åˆ†æå‰5ä¸ªæ–‡ä»¶
            try:
                data = np.load(file_path)  # [6, H, W]
                quality_metrics['shapes'].append(data.shape)
                
                # åˆ†ç¦»é€šé“
                rgb = data[:3]
                mask = data[3:4]
                residual_mv = data[4:6]
                
                # RGBç»Ÿè®¡
                rgb_mean = np.mean(rgb)
                rgb_std = np.std(rgb)
                rgb_range = (np.min(rgb), np.max(rgb))
                quality_metrics['rgb_stats'].append({
                    'mean': float(rgb_mean),
                    'std': float(rgb_std),
                    'range': rgb_range
                })
                
                # ç©ºæ´æ¯”ä¾‹
                hole_ratio = np.mean(mask)
                quality_metrics['hole_ratios'].append(float(hole_ratio))
                
                # è¿åŠ¨çŸ¢é‡å¹…åº¦
                mv_magnitude = np.sqrt(residual_mv[0]**2 + residual_mv[1]**2)
                avg_magnitude = np.mean(mv_magnitude)
                quality_metrics['mv_magnitudes'].append(float(avg_magnitude))
                
            except Exception as e:
                print(f"âš ï¸ åˆ†ææ–‡ä»¶ {file_path.name} æ—¶å‡ºé”™: {e}")
        
        # æ‰“å°è´¨é‡æŠ¥å‘Š
        if quality_metrics['shapes']:
            print(f"âœ… æ•°æ®å½¢çŠ¶: {quality_metrics['shapes'][0]} (æ‰€æœ‰æ–‡ä»¶)")
            print(f"âœ… RGBå‡å€¼èŒƒå›´: {np.min([s['mean'] for s in quality_metrics['rgb_stats']]):.3f} ~ {np.max([s['mean'] for s in quality_metrics['rgb_stats']]):.3f}")
            print(f"âœ… RGBæ ‡å‡†å·®èŒƒå›´: {np.min([s['std'] for s in quality_metrics['rgb_stats']]):.3f} ~ {np.max([s['std'] for s in quality_metrics['rgb_stats']]):.3f}")
            print(f"âœ… ç©ºæ´æ¯”ä¾‹èŒƒå›´: {np.min(quality_metrics['hole_ratios']):.3f} ~ {np.max(quality_metrics['hole_ratios']):.3f}")
            print(f"âœ… è¿åŠ¨çŸ¢é‡å¹…åº¦èŒƒå›´: {np.min(quality_metrics['mv_magnitudes']):.3f} ~ {np.max(quality_metrics['mv_magnitudes']):.3f}")
        
        return quality_metrics
    
    def test_dataset_splits(self) -> Optional[str]:
        """
        æµ‹è¯•æ•°æ®é›†åˆ†å‰²åˆ›å»º
        
        Returns:
            split_file_path: åˆ†å‰²æ–‡ä»¶è·¯å¾„
        """
        print("\nğŸ“‹ Step 4: æµ‹è¯•æ•°æ®é›†åˆ†å‰²åˆ›å»º...")
        
        try:
            # åˆ›å»ºåˆ†å‰²å™¨
            splitter = DatasetSplitCreator(
                data_root=str(self.output_dir),
                scene_name=self.scene_name
            )
            
            # åˆ›å»ºåˆ†å‰²
            split_file_path = splitter.create_splits()
            print(f"âœ… åˆ†å‰²æ–‡ä»¶åˆ›å»ºæˆåŠŸ: {split_file_path}")
            
            return split_file_path
            
        except Exception as e:
            print(f"âŒ åˆ†å‰²åˆ›å»ºå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def test_dataset_loading(self, split_file_path: str) -> bool:
        """
        æµ‹è¯•æ•°æ®é›†ç±»åŠ è½½
        
        Args:
            split_file_path: åˆ†å‰²æ–‡ä»¶è·¯å¾„
            
        Returns:
            success: åŠ è½½æ˜¯å¦æˆåŠŸ
        """
        print("\nğŸ’¿ Step 5: æµ‹è¯•æ•°æ®é›†ç±»åŠ è½½...")
        
        try:
            # åˆ›å»ºæ•°æ®é›†å®ä¾‹
            dataset = create_noisebase_dataset(
                data_root=str(self.output_dir),
                split_file=split_file_path,
                patch_size=self.patch_size,
                mode='train'
            )
            
            print(f"âœ… æ•°æ®é›†åˆ›å»ºæˆåŠŸï¼ŒåŒ…å« {len(dataset)} ä¸ªæ ·æœ¬")
            
            # æµ‹è¯•æ•°æ®åŠ è½½
            if len(dataset) > 0:
                sample = dataset[0]
                print(f"âœ… æ ·æœ¬åŠ è½½æˆåŠŸ")
                print(f"   è¾“å…¥å½¢çŠ¶: {sample['input'].shape}")
                print(f"   ç›®æ ‡å½¢çŠ¶: {sample['target'].shape}")
                print(f"   å…ƒæ•°æ®: {list(sample.keys())}")
                
                # éªŒè¯æ•°æ®æ ¼å¼
                if sample['input'].shape[0] == 6:
                    print("âœ… 6é€šé“è¾“å…¥æ ¼å¼æ­£ç¡®")
                else:
                    print(f"âŒ è¾“å…¥é€šé“æ•°é”™è¯¯: {sample['input'].shape[0]}, æœŸæœ›6")
                    return False
                
                if sample['target'].shape[0] == 3:
                    print("âœ… 3é€šé“ç›®æ ‡æ ¼å¼æ­£ç¡®")
                else:
                    print(f"âŒ ç›®æ ‡é€šé“æ•°é”™è¯¯: {sample['target'].shape[0]}, æœŸæœ›3")
                    return False
                
            return True
            
        except Exception as e:
            print(f"âŒ æ•°æ®é›†åŠ è½½å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def test_network_forward(self, split_file_path: str) -> bool:
        """
        æµ‹è¯•ç½‘ç»œå‰å‘ä¼ æ’­
        
        Args:
            split_file_path: åˆ†å‰²æ–‡ä»¶è·¯å¾„
            
        Returns:
            success: ç½‘ç»œæµ‹è¯•æ˜¯å¦æˆåŠŸ
        """
        print("\nğŸ§  Step 6: æµ‹è¯•ç½‘ç»œå‰å‘ä¼ æ’­...")
        
        try:
            # åˆ›å»ºç½‘ç»œ
            network = MobileInpaintingNetwork(
                input_channels=6,
                output_channels=3,
                base_channels=32
            )
            
            # åˆ›å»ºæ•°æ®é›†
            dataset = create_noisebase_dataset(
                data_root=str(self.output_dir),
                split_file=split_file_path,
                patch_size=self.patch_size,
                mode='train'
            )
            
            if len(dataset) == 0:
                print("âŒ æ•°æ®é›†ä¸ºç©º")
                return False
            
            # è·å–æµ‹è¯•æ ·æœ¬
            sample = dataset[0]
            input_tensor = sample['input'].unsqueeze(0)  # [1, 6, H, W]
            target_tensor = sample['target'].unsqueeze(0)  # [1, 3, H, W]
            
            print(f"ğŸ“Š è¾“å…¥å¼ é‡å½¢çŠ¶: {input_tensor.shape}")
            print(f"ğŸ“Š ç›®æ ‡å¼ é‡å½¢çŠ¶: {target_tensor.shape}")
            
            # å‰å‘ä¼ æ’­
            with torch.no_grad():
                output = network(input_tensor)
            
            print(f"âœ… ç½‘ç»œå‰å‘æˆåŠŸï¼Œè¾“å‡ºå½¢çŠ¶: {output.shape}")
            
            # éªŒè¯è¾“å‡º
            if output.shape == target_tensor.shape:
                print("âœ… è¾“å‡ºå½¢çŠ¶ä¸ç›®æ ‡åŒ¹é…")
            else:
                print(f"âŒ è¾“å‡ºå½¢çŠ¶ä¸åŒ¹é…: {output.shape} vs {target_tensor.shape}")
                return False
            
            # æ£€æŸ¥è¾“å‡ºæ•°å€¼èŒƒå›´
            output_min, output_max = output.min().item(), output.max().item()
            print(f"ğŸ“Š è¾“å‡ºæ•°å€¼èŒƒå›´: [{output_min:.3f}, {output_max:.3f}]")
            
            return True
            
        except Exception as e:
            print(f"âŒ ç½‘ç»œæµ‹è¯•å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def create_visualization(self, split_file_path: str):
        """
        åˆ›å»ºå¯è§†åŒ–ç»“æœ
        
        Args:
            split_file_path: åˆ†å‰²æ–‡ä»¶è·¯å¾„
        """
        print("\nğŸ¨ Step 7: åˆ›å»ºå¯è§†åŒ–ç»“æœ...")
        
        try:
            # åˆ›å»ºæ•°æ®é›†
            dataset = create_noisebase_dataset(
                data_root=str(self.output_dir),
                split_file=split_file_path,
                patch_size=self.patch_size,
                mode='train'
            )
            
            if len(dataset) == 0:
                print("âŒ æ•°æ®é›†ä¸ºç©ºï¼Œæ— æ³•åˆ›å»ºå¯è§†åŒ–")
                return
            
            # è·å–æ ·æœ¬
            sample = dataset[0]
            input_data = sample['input'].numpy()  # [6, H, W]
            target_data = sample['target'].numpy()  # [3, H, W]
            
            # åˆ†ç¦»è¾“å…¥é€šé“
            rgb = input_data[:3]        # RGB
            mask = input_data[3:4]      # Mask
            residual_mv = input_data[4:6]  # ResidualMV
            
            # åˆ›å»ºå¯è§†åŒ–
            fig, axes = plt.subplots(2, 3, figsize=(15, 10))
            
            # RGBè¾“å…¥
            rgb_vis = np.clip((rgb.transpose(1, 2, 0) + 1) / 2, 0, 1)
            axes[0, 0].imshow(rgb_vis)
            axes[0, 0].set_title('Input RGB')
            axes[0, 0].axis('off')
            
            # ç©ºæ´æ©ç 
            axes[0, 1].imshow(mask[0], cmap='gray')
            axes[0, 1].set_title('Hole Mask')
            axes[0, 1].axis('off')
            
            # æ®‹å·®è¿åŠ¨çŸ¢é‡
            mv_magnitude = np.sqrt(residual_mv[0]**2 + residual_mv[1]**2)
            axes[0, 2].imshow(mv_magnitude, cmap='jet')
            axes[0, 2].set_title('Residual MV Magnitude')
            axes[0, 2].axis('off')
            
            # ç›®æ ‡å›¾åƒ
            target_vis = np.clip((target_data.transpose(1, 2, 0) + 1) / 2, 0, 1)
            axes[1, 0].imshow(target_vis)
            axes[1, 0].set_title('Target Ground Truth')
            axes[1, 0].axis('off')
            
            # è¿åŠ¨çŸ¢é‡æ–¹å‘
            mv_angle = np.arctan2(residual_mv[1], residual_mv[0])
            axes[1, 1].imshow(mv_angle, cmap='hsv')
            axes[1, 1].set_title('Residual MV Direction')
            axes[1, 1].axis('off')
            
            # å åŠ æ˜¾ç¤º
            overlay = rgb_vis.copy()
            overlay[mask[0] > 0.5] = [1, 0, 0]  # çº¢è‰²æ ‡è®°ç©ºæ´
            axes[1, 2].imshow(overlay)
            axes[1, 2].set_title('RGB + Hole Overlay')
            axes[1, 2].axis('off')
            
            plt.tight_layout()
            
            # ä¿å­˜å¯è§†åŒ–
            vis_path = self.output_dir / f"{self.scene_name}_pipeline_test.png"
            plt.savefig(str(vis_path), dpi=150, bbox_inches='tight')
            plt.close()
            
            print(f"âœ… å¯è§†åŒ–å·²ä¿å­˜: {vis_path}")
            
        except Exception as e:
            print(f"âŒ å¯è§†åŒ–åˆ›å»ºå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    def run_complete_test(self) -> bool:
        """
        è¿è¡Œå®Œæ•´æµ‹è¯•æµæ°´çº¿
        
        Returns:
            success: æ‰€æœ‰æµ‹è¯•æ˜¯å¦é€šè¿‡
        """
        success_count = 0
        total_tests = 7
        
        # æµ‹è¯•æ­¥éª¤
        tests = [
            self.test_data_availability,
            self.test_preprocessing,
            self.test_data_quality,
            self.test_dataset_splits,
            lambda: self.test_dataset_loading(self.split_file_path) if hasattr(self, 'split_file_path') else False,
            lambda: self.test_network_forward(self.split_file_path) if hasattr(self, 'split_file_path') else False,
            lambda: self.create_visualization(self.split_file_path) if hasattr(self, 'split_file_path') else None
        ]
        
        # é€æ­¥æ‰§è¡Œæµ‹è¯•
        for i, test_func in enumerate(tests):
            try:
                if i == 3:  # dataset splits test
                    result = test_func()
                    if result:
                        self.split_file_path = result
                        success_count += 1
                elif i == 6:  # visualization 
                    test_func()
                    success_count += 1  # å¯è§†åŒ–ä¸ç®—å¤±è´¥
                else:
                    result = test_func()
                    if result:
                        success_count += 1
                    
            except Exception as e:
                print(f"âŒ æµ‹è¯•æ­¥éª¤ {i+1} å‡ºç°å¼‚å¸¸: {e}")
        
        # æ€»ç»“æŠ¥å‘Š
        print("\n" + "="*80)
        print("ğŸ“‹ æµ‹è¯•ç»“æœæ€»ç»“")
        print("="*80)
        print(f"âœ… é€šè¿‡æµ‹è¯•: {success_count}/{total_tests}")
        print(f"âŒ å¤±è´¥æµ‹è¯•: {total_tests - success_count}/{total_tests}")
        
        if success_count >= total_tests - 1:  # å…è®¸1ä¸ªæµ‹è¯•å¤±è´¥
            print("ğŸ‰ æ•´ä½“æµ‹è¯•é€šè¿‡ï¼æµæ°´çº¿è¿è¡Œæ­£å¸¸")
            print("\nğŸ“– ä¸‹ä¸€æ­¥æ“ä½œ:")
            print("1. è¿è¡Œå®Œæ•´é¢„å¤„ç†:")
            print(f"   python run_preprocessing.py --input-dir {self.input_dir} --output-dir {self.output_dir} --scene {self.scene_name}")
            print("2. å¼€å§‹è®­ç»ƒ:")
            if hasattr(self, 'split_file_path'):
                print(f"   python training/train_mobile_inpainting.py --data-root {self.output_dir} --split-file {self.split_file_path}")
            return True
        else:
            print("âŒ æµ‹è¯•æœªå®Œå…¨é€šè¿‡ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")
            return False


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='Test NoiseBase Preprocessing Pipeline')
    parser.add_argument('--input-dir', type=str, default='./training',
                       help='NoiseBase data directory')
    parser.add_argument('--output-dir', type=str, default='./training/processed_test',
                       help='Test output directory')
    parser.add_argument('--scene', type=str, default='bistro1',
                       help='Scene name to test')
    parser.add_argument('--test-frames', type=int, default=10,
                       help='Number of frames to test')
    
    args = parser.parse_args()
    
    # åˆ›å»ºæµ‹è¯•å™¨
    tester = PreprocessingPipelineTester(
        input_dir=args.input_dir,
        output_dir=args.output_dir,
        scene_name=args.scene
    )
    tester.test_frame_count = args.test_frames
    
    # è¿è¡Œæµ‹è¯•
    success = tester.run_complete_test()
    
    return 0 if success else 1


if __name__ == "__main__":
    exit(main())