#!/usr/bin/env python3
"""
ä¿®æ­£åçš„NoiseBaseæ•°æ®é¢„å¤„ç†è„šæœ¬

åŸºäºå­¦é•¿detach.pyè„šæœ¬çš„åˆ†æï¼Œä¿®æ­£äº†æ•°æ®åŠ è½½éƒ¨åˆ†ï¼š
- æ­£ç¡®å¤„ç†zip+zarræ ¼å¼çš„NoiseBaseæ•°æ®
- å®ç°RGBEé¢œè‰²è§£å‹ç¼©
- å¤„ç†å¤šé‡‡æ ·æ•°æ®èšåˆ
- è®¡ç®—æ­£ç¡®çš„å‡ ä½•ä¿¡æ¯

ä½¿ç”¨æ–¹æ³•:
python run_preprocessing_corrected.py --data-root ./data --scene bistro1 --output ./processed
"""

import os
import sys
import argparse
import json
from pathlib import Path
from typing import Dict, List
import numpy as np

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from noisebase_data_loader import NoiseBaseDataLoader
from noisebase_preprocessor_corrected import NoiseBasePreprocessorCorrected


class NoiseBasePreprocessorWithRealData(NoiseBasePreprocessorCorrected):
    """
    ä½¿ç”¨çœŸå®NoiseBaseæ•°æ®çš„é¢„å¤„ç†å™¨
    
    ç»§æ‰¿ä¿®æ­£åçš„é¢„å¤„ç†å™¨ï¼Œæ›¿æ¢æ•°æ®åŠ è½½éƒ¨åˆ†
    """
    
    def __init__(self, 
                 input_dir: str,
                 output_dir: str,
                 scene_name: str = "bistro1"):
        """
        åˆå§‹åŒ–é¢„å¤„ç†å™¨
        
        Args:
            input_dir: NoiseBaseæ•°æ®è¾“å…¥ç›®å½•
            output_dir: å¤„ç†åæ•°æ®è¾“å‡ºç›®å½•  
            scene_name: åœºæ™¯åç§°
        """
        super().__init__(input_dir, output_dir, scene_name)
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        self.data_loader = NoiseBaseDataLoader(input_dir)
        
        # éªŒè¯åœºæ™¯æ•°æ®
        available_scenes = self.data_loader.list_available_scenes()
        if scene_name not in available_scenes:
            raise ValueError(f"åœºæ™¯ '{scene_name}' ä¸å­˜åœ¨ã€‚å¯ç”¨åœºæ™¯: {available_scenes}")
        
        frame_count = self.data_loader.count_frames(scene_name)
        print(f"åœºæ™¯ '{scene_name}' åŒ…å« {frame_count} å¸§æ•°æ®")
        
        # éªŒè¯æ•°æ®å®Œæ•´æ€§
        validation = self.data_loader.validate_data_integrity(scene_name, max_frames=3)
        if validation['valid_frames'] == 0:
            raise ValueError(f"åœºæ™¯ '{scene_name}' æ²¡æœ‰æœ‰æ•ˆçš„å¸§æ•°æ®")
        
        print(f"æ•°æ®éªŒè¯é€šè¿‡: {validation['valid_frames']} å¸§æœ‰æ•ˆ")
    
    def load_frame_data(self, frame_idx: int) -> Dict:
        """
        åŠ è½½çœŸå®çš„NoiseBaseå¸§æ•°æ®
        
        Args:
            frame_idx: å¸§ç´¢å¼•
            
        Returns:
            frame_data: å¸§æ•°æ®å­—å…¸
        """
        # ä½¿ç”¨çœŸå®çš„æ•°æ®åŠ è½½å™¨
        frame_data = self.data_loader.load_frame_data(self.scene_name, frame_idx)
        
        if frame_data is None:
            return None
        
        # ç¡®ä¿æ•°æ®æ ¼å¼ç¬¦åˆé¢„å¤„ç†å™¨è¦æ±‚
        processed_data = {}
        
        # å‚è€ƒå›¾åƒ (ç›®æ ‡å›¾åƒ)
        if 'reference' in frame_data:
            processed_data['reference'] = frame_data['reference']
        elif 'color' in frame_data:
            # å¦‚æœæ²¡æœ‰referenceï¼Œä½¿ç”¨è§£å‹ç¼©åçš„colorä½œä¸ºå‚è€ƒ
            processed_data['reference'] = frame_data['color']
        else:
            raise ValueError(f"å¸§ {frame_idx} ç¼ºå°‘å‚è€ƒå›¾åƒæ•°æ®")
        
        # ä¸–ç•Œç©ºé—´ä½ç½®
        if 'position' in frame_data:
            processed_data['position'] = frame_data['position']
        else:
            raise ValueError(f"å¸§ {frame_idx} ç¼ºå°‘ä½ç½®æ•°æ®")
        
        # è¿åŠ¨çŸ¢é‡ (ä¼˜å…ˆä½¿ç”¨å±å¹•ç©ºé—´è¿åŠ¨çŸ¢é‡)
        if 'screen_motion' in frame_data:
            processed_data['motion'] = frame_data['screen_motion']
        elif 'motion' in frame_data:
            # å¦‚æœåªæœ‰ä¸–ç•Œç©ºé—´è¿åŠ¨ï¼Œéœ€è¦è½¬æ¢ä¸ºå±å¹•ç©ºé—´
            if 'view_proj_mat' in frame_data:
                screen_motion = self.data_loader.compute_screen_motion_vectors(
                    frame_data['position'],
                    frame_data['motion'], 
                    frame_data['view_proj_mat']
                )
                processed_data['motion'] = screen_motion
            else:
                # å¦‚æœæ— æ³•è½¬æ¢ï¼Œç›´æ¥ä½¿ç”¨å‰ä¸¤ä¸ªé€šé“
                processed_data['motion'] = frame_data['motion'][:2]
        else:
            raise ValueError(f"å¸§ {frame_idx} ç¼ºå°‘è¿åŠ¨æ•°æ®")
        
        # ç›¸æœºä½ç½®
        if 'camera_pos' in frame_data:
            processed_data['camera_pos'] = frame_data['camera_pos']
        else:
            # å¦‚æœæ²¡æœ‰ç›¸æœºä½ç½®ï¼Œä½¿ç”¨é»˜è®¤å€¼
            processed_data['camera_pos'] = np.array([0, 0, 5], dtype=np.float32)
            print(f"âš ï¸ å¸§ {frame_idx} ç¼ºå°‘ç›¸æœºä½ç½®ï¼Œä½¿ç”¨é»˜è®¤å€¼")
        
        # å…¶ä»–å¯é€‰æ•°æ®
        for key in ['normal', 'albedo', 'view_proj_mat', 'exposure']:
            if key in frame_data:
                processed_data[key] = frame_data[key]
        
        return processed_data
    
    def process_sequence(self, start_frame: int = 0, end_frame: int = None):
        """
        å¤„ç†å¸§åºåˆ—
        
        Args:
            start_frame: èµ·å§‹å¸§ç´¢å¼•
            end_frame: ç»“æŸå¸§ç´¢å¼• (Noneè¡¨ç¤ºå¤„ç†åˆ°æœ€åä¸€å¸§)
        """
        # ç¡®å®šå¤„ç†èŒƒå›´
        total_frames = self.data_loader.count_frames(self.scene_name)
        
        if end_frame is None:
            end_frame = total_frames - 1
        
        end_frame = min(end_frame, total_frames - 1)
        
        if start_frame >= total_frames:
            raise ValueError(f"èµ·å§‹å¸§ {start_frame} è¶…å‡ºæ•°æ®èŒƒå›´ (0-{total_frames-1})")
        
        print(f"ğŸš€ å¼€å§‹å¤„ç†å¸§åºåˆ—: {start_frame} -> {end_frame}")
        print(f"æ€»å…±éœ€è¦å¤„ç† {end_frame - start_frame + 1} å¸§")
        
        # å¤„ç†æ¯ä¸€å¸§ (ä»ç¬¬1å¸§å¼€å§‹ï¼Œå› ä¸ºéœ€è¦å‰ä¸€å¸§ä½œä¸ºå‚è€ƒ)
        success_count = 0
        error_count = 0
        
        for frame_idx in range(max(1, start_frame), end_frame + 1):
            print(f"\nğŸ“Š å¤„ç†å¸§ {frame_idx}/{end_frame}")
            
            try:
                success = self.process_frame_pair(frame_idx)
                
                if success:
                    success_count += 1
                    print(f"âœ… å¸§ {frame_idx} å¤„ç†æˆåŠŸ")
                else:
                    error_count += 1
                    print(f"âŒ å¸§ {frame_idx} å¤„ç†å¤±è´¥")
                    
            except Exception as e:
                error_count += 1
                print(f"âŒ å¸§ {frame_idx} å¤„ç†å¼‚å¸¸: {e}")
                import traceback
                traceback.print_exc()
        
        print(f"\nğŸ‰ åºåˆ—å¤„ç†å®Œæˆ!")
        print(f"   æˆåŠŸ: {success_count} å¸§")
        print(f"   å¤±è´¥: {error_count} å¸§")
        print(f"   æˆåŠŸç‡: {success_count/(success_count+error_count)*100:.1f}%")
        
        return success_count, error_count


def create_data_splits(output_dir: str, scene_name: str, total_frames: int) -> Dict[str, List[int]]:
    """
    åˆ›å»ºæ•°æ®é›†åˆ†å‰²
    
    Args:
        output_dir: è¾“å‡ºç›®å½•
        scene_name: åœºæ™¯åç§°
        total_frames: æ€»å¸§æ•°
    
    Returns:
        splits: åˆ†å‰²å­—å…¸
    """
    # åˆ†å‰²æ¯”ä¾‹ï¼šè®­ç»ƒ80%ï¼ŒéªŒè¯15%ï¼Œæµ‹è¯•5%
    train_ratio = 0.8
    val_ratio = 0.15
    test_ratio = 0.05
    
    # è®¡ç®—åˆ†å‰²ç‚¹
    train_end = int(total_frames * train_ratio)
    val_end = int(total_frames * (train_ratio + val_ratio))
    
    # åˆ›å»ºåˆ†å‰²åˆ—è¡¨ï¼ˆä»å¸§1å¼€å§‹ï¼Œå› ä¸ºéœ€è¦å‰ä¸€å¸§ä½œä¸ºå‚è€ƒï¼‰
    splits = {
        'train': list(range(1, train_end)),
        'val': list(range(train_end, val_end)),
        'test': list(range(val_end, total_frames))
    }
    
    # ä¿å­˜åˆ†å‰²æ–‡ä»¶
    split_file = Path(output_dir) / f"{scene_name}_splits.json"
    
    split_data = {
        'scene': scene_name,
        'total_frames': total_frames,
        'splits': splits,
        'statistics': {
            'train_samples': len(splits['train']),
            'val_samples': len(splits['val']),
            'test_samples': len(splits['test'])
        }
    }
    
    with open(split_file, 'w') as f:
        json.dump(split_data, f, indent=2)
    
    print(f"Data splits saved to: {split_file}")
    print(f"Train: {len(splits['train'])} samples")
    print(f"Val: {len(splits['val'])} samples") 
    print(f"Test: {len(splits['test'])} samples")
    
    return splits


def validate_preprocessing_results(output_dir: str, scene_name: str, expected_frames: int):
    """
    éªŒè¯é¢„å¤„ç†ç»“æœ
    
    Args:
        output_dir: è¾“å‡ºç›®å½•
        scene_name: åœºæ™¯åç§°
        expected_frames: é¢„æœŸå¸§æ•°
    """
    base_path = Path(output_dir) / scene_name
    
    # æ£€æŸ¥ç›®å½•ç»“æ„
    required_dirs = ['rgb', 'warped', 'masks', 'residual_mv', 'training_data', 'visualization']
    missing_dirs = []
    
    for dir_name in required_dirs:
        dir_path = base_path / dir_name
        if not dir_path.exists():
            missing_dirs.append(dir_name)
    
    if missing_dirs:
        print(f"âŒ Missing directories: {missing_dirs}")
        return False
    
    # æ£€æŸ¥æ–‡ä»¶æ•°é‡
    training_data_dir = base_path / 'training_data'
    training_files = list(training_data_dir.glob("*.npy"))
    
    print(f"âœ… Directory structure complete")
    print(f"âœ… Generated {len(training_files)} training samples")
    
    # æ£€æŸ¥æ ·æœ¬æ–‡ä»¶å¤§å°å’Œæ ¼å¼
    if training_files:
        sample_file = training_files[0]
        sample_data = np.load(sample_file)
        
        print(f"âœ… Sample data shape: {sample_data.shape}")
        
        if sample_data.shape[0] == 6:
            print("âœ… 6-channel format correct (RGB + OcclusionMask + ResidualMV)")
        else:
            print(f"âŒ Expected 6 channels, got {sample_data.shape[0]}")
            return False
    
    return True


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='Run NoiseBase Preprocessing with Real Data')
    parser.add_argument('--data-root', type=str, required=True,
                       help='NoiseBase data root directory')
    parser.add_argument('--output-dir', type=str, default='./processed_data',
                       help='Output directory')
    parser.add_argument('--scene', type=str, default='bistro1',
                       help='Scene name (bistro1, kitchen, etc.)')
    parser.add_argument('--start-frame', type=int, default=1,
                       help='Start frame index')
    parser.add_argument('--end-frame', type=int, default=None,
                       help='End frame index (auto-detect if None)')
    parser.add_argument('--create-splits', action='store_true',
                       help='Create train/val/test splits')
    parser.add_argument('--validate', action='store_true', default=True,
                       help='Validate preprocessing results')
    
    args = parser.parse_args()
    
    print("="*80)
    print("ğŸš€ NoiseBaseæ•°æ®é¢„å¤„ç†å¼€å§‹ (ä½¿ç”¨çœŸå®æ•°æ®)")
    print("="*80)
    print(f"æ•°æ®æ ¹ç›®å½•: {args.data_root}")
    print(f"è¾“å‡ºç›®å½•: {args.output_dir}")
    print(f"åœºæ™¯åç§°: {args.scene}")
    print(f"èµ·å§‹å¸§: {args.start_frame}")
    print(f"ç»“æŸå¸§: {args.end_frame if args.end_frame else 'auto-detect'}")
    print("="*80)
    
    try:
        # 1. åˆ›å»ºé¢„å¤„ç†å™¨
        print("\nğŸ“Š Step 1: åˆå§‹åŒ–é¢„å¤„ç†å™¨...")
        preprocessor = NoiseBasePreprocessorWithRealData(
            input_dir=args.data_root,
            output_dir=args.output_dir,
            scene_name=args.scene
        )
        
        # 2. è‡ªåŠ¨æ£€æµ‹å¸§æ•°èŒƒå›´
        if args.end_frame is None:
            total_frames = preprocessor.data_loader.count_frames(args.scene)
            args.end_frame = total_frames - 1
            print(f"æ£€æµ‹åˆ° {total_frames} å¸§æ•°æ®ï¼Œå¤„ç†åˆ°ç¬¬ {args.end_frame} å¸§")
        
        # 3. æ‰§è¡Œé¢„å¤„ç†
        print("\nğŸ”„ Step 2: æ‰§è¡Œæ•°æ®é¢„å¤„ç†...")
        success_count, error_count = preprocessor.process_sequence(
            start_frame=args.start_frame,
            end_frame=args.end_frame
        )
        
        # 4. åˆ›å»ºæ•°æ®åˆ†å‰²
        if args.create_splits:
            print("\nğŸ“‹ Step 3: åˆ›å»ºæ•°æ®é›†åˆ†å‰²...")
            total_processed = success_count
            splits = create_data_splits(args.output_dir, args.scene, total_processed)
        
        # 5. éªŒè¯ç»“æœ
        if args.validate:
            print("\nâœ… Step 4: éªŒè¯é¢„å¤„ç†ç»“æœ...")
            validation_success = validate_preprocessing_results(
                args.output_dir, args.scene, success_count
            )
            
            if validation_success:
                print("\nğŸ‰ é¢„å¤„ç†å®Œæˆï¼æ‰€æœ‰éªŒè¯é€šè¿‡")
            else:
                print("\nâš ï¸ é¢„å¤„ç†å®Œæˆï¼Œä½†éªŒè¯å‘ç°é—®é¢˜")
        
        # 6. è¾“å‡ºä½¿ç”¨æŒ‡å—
        print("\n" + "="*80)
        print("ğŸ“– ä½¿ç”¨æŒ‡å—")
        print("="*80)
        print("ä¸‹ä¸€æ­¥å¯ä»¥æ‰§è¡Œä»¥ä¸‹æ“ä½œï¼š")
        print("")
        print("1. æ£€æŸ¥å¤„ç†ç»“æœï¼š")
        print(f"   æŸ¥çœ‹ {args.output_dir}/{args.scene}/visualization/ ç›®å½•")
        print("")
        print("2. è®­ç»ƒç½‘ç»œï¼š")
        print(f"   python training/train_mobile_inpainting.py \\")
        print(f"     --data-root {args.output_dir} \\")
        print(f"     --split-file {args.output_dir}/{args.scene}_splits.json")
        print("")
        print("3. æ£€æŸ¥è®­ç»ƒæ•°æ®ï¼š")
        print(f"   åŠ è½½ {args.output_dir}/{args.scene}/training_data/*.npy æ–‡ä»¶")
        print("="*80)
        
    except Exception as e:
        print(f"\nâŒ é¢„å¤„ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1
    
    return 0


if __name__ == "__main__":
    exit(main())