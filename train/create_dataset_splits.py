#!/usr/bin/env python3
"""
@file create_dataset_splits.py  
@brief åˆ›å»ºNoiseBaseæ•°æ®é›†åˆ†å‰²æ–‡ä»¶

åŠŸèƒ½æè¿°ï¼š
- åˆ†æé¢„å¤„ç†åçš„NoiseBaseæ•°æ®
- åˆ›å»ºè®­ç»ƒ/éªŒè¯/æµ‹è¯•åˆ†å‰²
- ç”Ÿæˆé€‚é…datasetç±»çš„åˆ†å‰²æ–‡ä»¶æ ¼å¼
- è€ƒè™‘æ•°æ®è´¨é‡è¿›è¡Œæ™ºèƒ½åˆ†å‰²

@author AIç®—æ³•å›¢é˜Ÿ
@date 2025-07-28
@version 1.0
"""

import os
import json
import numpy as np
from pathlib import Path
from typing import Dict, List, Tuple
import argparse


class DatasetSplitCreator:
    """æ•°æ®é›†åˆ†å‰²åˆ›å»ºå™¨"""
    
    def __init__(self, data_root: str, scene_name: str):
        """
        åˆå§‹åŒ–åˆ†å‰²åˆ›å»ºå™¨
        
        Args:
            data_root: é¢„å¤„ç†æ•°æ®æ ¹ç›®å½•
            scene_name: åœºæ™¯åç§°
        """
        self.data_root = Path(data_root)
        self.scene_name = scene_name
        self.scene_path = self.data_root / scene_name
        
        # åˆ†å‰²æ¯”ä¾‹
        self.train_ratio = 0.7
        self.val_ratio = 0.2  
        self.test_ratio = 0.1
        
        # è´¨é‡é˜ˆå€¼
        self.min_quality_score = 0.3
        self.max_hole_ratio = 0.4
        self.min_motion_diversity = 0.1
        
    def analyze_frame_quality(self, frame_idx: int) -> Dict:
        """
        åˆ†æå•å¸§æ•°æ®è´¨é‡
        
        Args:
            frame_idx: å¸§ç´¢å¼•
            
        Returns:
            quality_info: è´¨é‡ä¿¡æ¯å­—å…¸
        """
        frame_name = f"frame_{frame_idx:04d}"
        
        # åŠ è½½è®­ç»ƒæ•°æ®
        training_data_path = self.scene_path / 'training_data' / f"{frame_name}.npy"
        
        if not training_data_path.exists():
            return {'valid': False, 'reason': 'missing_training_data'}
        
        try:
            training_data = np.load(training_data_path)  # [6, H, W]
            
            # åˆ†ç¦»å„é€šé“
            rgb = training_data[:3]        # RGBé€šé“
            mask = training_data[3:4]      # æ©ç é€šé“  
            residual_mv = training_data[4:6]  # æ®‹å·®MVé€šé“
            
            # è´¨é‡è¯„ä¼°
            quality_info = {
                'valid': True,
                'frame_idx': frame_idx,
                'shape': training_data.shape
            }
            
            # 1. RGBè´¨é‡æ£€æŸ¥
            rgb_std = np.std(rgb)
            rgb_range_valid = np.all((rgb >= -1.1) & (rgb <= 1.1))
            quality_info['rgb_std'] = float(rgb_std)
            quality_info['rgb_range_valid'] = bool(rgb_range_valid)
            
            # 2. æ©ç è´¨é‡æ£€æŸ¥
            hole_ratio = np.mean(mask)
            quality_info['hole_ratio'] = float(hole_ratio)
            quality_info['hole_valid'] = hole_ratio <= self.max_hole_ratio
            
            # 3. è¿åŠ¨çŸ¢é‡è´¨é‡æ£€æŸ¥
            mv_magnitude = np.sqrt(residual_mv[0]**2 + residual_mv[1]**2)
            mv_avg_magnitude = np.mean(mv_magnitude)
            mv_std = np.std(mv_magnitude)
            quality_info['mv_magnitude'] = float(mv_avg_magnitude)
            quality_info['mv_diversity'] = float(mv_std)
            quality_info['mv_valid'] = mv_std >= self.min_motion_diversity
            
            # 4. ç»¼åˆè´¨é‡è¯„åˆ†
            quality_factors = []
            
            # RGBå¯¹æ¯”åº¦è¯„åˆ†
            contrast_score = min(rgb_std / 0.3, 1.0) if rgb_range_valid else 0.0
            quality_factors.append(contrast_score)
            
            # æ©ç è¯„åˆ†ï¼ˆé€‚ä¸­çš„ç©ºæ´æ¯”ä¾‹å¾—åˆ†æ›´é«˜ï¼‰
            if 0.05 <= hole_ratio <= 0.25:
                mask_score = 1.0
            else:
                mask_score = max(0.2, 1.0 - abs(hole_ratio - 0.15) * 3)
            quality_factors.append(mask_score)
            
            # è¿åŠ¨å¤šæ ·æ€§è¯„åˆ†
            diversity_score = min(mv_std / 1.0, 1.0)
            quality_factors.append(diversity_score)
            
            quality_score = np.mean(quality_factors)
            quality_info['quality_score'] = float(quality_score)
            quality_info['high_quality'] = quality_score >= self.min_quality_score
            
            return quality_info
            
        except Exception as e:
            return {'valid': False, 'reason': f'analysis_error: {e}'}
    
    def scan_available_frames(self) -> List[Dict]:
        """
        æ‰«ææ‰€æœ‰å¯ç”¨å¸§å¹¶åˆ†æè´¨é‡
        
        Returns:
            frame_infos: å¸§ä¿¡æ¯åˆ—è¡¨
        """
        print(f"ğŸ” æ‰«æåœºæ™¯ {self.scene_name} çš„å¯ç”¨å¸§...")
        
        training_data_dir = self.scene_path / 'training_data'
        if not training_data_dir.exists():
            raise FileNotFoundError(f"Training data directory not found: {training_data_dir}")
        
        # è·å–æ‰€æœ‰è®­ç»ƒæ•°æ®æ–‡ä»¶
        training_files = sorted(training_data_dir.glob("frame_*.npy"))
        
        frame_infos = []
        for file_path in training_files:
            # ä»æ–‡ä»¶åæå–å¸§ç´¢å¼•
            frame_name = file_path.stem
            frame_idx = int(frame_name.split('_')[1])
            
            # åˆ†æå¸§è´¨é‡
            quality_info = self.analyze_frame_quality(frame_idx)
            frame_infos.append(quality_info)
        
        print(f"âœ… æ‰«æå®Œæˆï¼Œæ‰¾åˆ° {len(frame_infos)} ä¸ªæ•°æ®æ–‡ä»¶")
        
        # ç»Ÿè®¡è´¨é‡ä¿¡æ¯
        valid_frames = [info for info in frame_infos if info.get('valid', False)]
        high_quality_frames = [info for info in valid_frames if info.get('high_quality', False)]
        
        print(f"ğŸ“Š æœ‰æ•ˆå¸§: {len(valid_frames)}")
        print(f"ğŸ“Š é«˜è´¨é‡å¸§: {len(high_quality_frames)}")
        
        if len(valid_frames) > 0:
            avg_quality = np.mean([info['quality_score'] for info in valid_frames])
            avg_hole_ratio = np.mean([info['hole_ratio'] for info in valid_frames])
            avg_mv_magnitude = np.mean([info['mv_magnitude'] for info in valid_frames])
            
            print(f"ğŸ“Š å¹³å‡è´¨é‡è¯„åˆ†: {avg_quality:.3f}")
            print(f"ğŸ“Š å¹³å‡ç©ºæ´æ¯”ä¾‹: {avg_hole_ratio:.3f}") 
            print(f"ğŸ“Š å¹³å‡è¿åŠ¨å¹…åº¦: {avg_mv_magnitude:.3f}")
        
        return valid_frames
    
    def create_balanced_splits(self, frame_infos: List[Dict]) -> Dict[str, List[int]]:
        """
        åˆ›å»ºå‡è¡¡çš„æ•°æ®åˆ†å‰²
        
        Args:
            frame_infos: å¸§ä¿¡æ¯åˆ—è¡¨
            
        Returns:
            splits: åˆ†å‰²å­—å…¸
        """
        print(f"ğŸ“‹ åˆ›å»ºæ•°æ®é›†åˆ†å‰²...")
        
        # è¿‡æ»¤æœ‰æ•ˆå¸§
        valid_frames = [info for info in frame_infos if info.get('valid', False)]
        
        if len(valid_frames) == 0:
            raise ValueError("No valid frames found for splitting")
        
        # æŒ‰è´¨é‡æ’åº
        valid_frames.sort(key=lambda x: x['quality_score'], reverse=True)
        
        # è®¡ç®—åˆ†å‰²å¤§å°
        total_frames = len(valid_frames)
        train_size = int(total_frames * self.train_ratio)
        val_size = int(total_frames * self.val_ratio)
        test_size = total_frames - train_size - val_size
        
        print(f"ğŸ“Š åˆ†å‰²è®¡åˆ’: è®­ç»ƒ{train_size}, éªŒè¯{val_size}, æµ‹è¯•{test_size}")
        
        # ç­–ç•¥ï¼šä¿è¯å„ä¸ªåˆ†å‰²éƒ½æœ‰é«˜ä¸­ä½è´¨é‡çš„æ ·æœ¬
        frame_indices = [info['frame_idx'] for info in valid_frames]
        
        # äº¤é”™åˆ†é…ä»¥ä¿è¯è´¨é‡åˆ†å¸ƒå‡åŒ€
        train_indices = []
        val_indices = []
        test_indices = []
        
        for i, frame_idx in enumerate(frame_indices):
            if i % 10 < 7:  # 70%ç”¨äºè®­ç»ƒ
                train_indices.append(frame_idx)
            elif i % 10 < 9:  # 20%ç”¨äºéªŒè¯
                val_indices.append(frame_idx)
            else:  # 10%ç”¨äºæµ‹è¯•
                test_indices.append(frame_idx)
        
        # å¦‚æœåˆ†å‰²å¤§å°ä¸ç¬¦åˆé¢„æœŸï¼Œè¿›è¡Œè°ƒæ•´
        while len(train_indices) < train_size and (len(val_indices) > val_size or len(test_indices) > test_size):
            if len(val_indices) > val_size:
                train_indices.append(val_indices.pop())
            elif len(test_indices) > test_size:
                train_indices.append(test_indices.pop())
        
        splits = {
            'train': sorted(train_indices),
            'val': sorted(val_indices), 
            'test': sorted(test_indices)
        }
        
        print(f"âœ… å®é™…åˆ†å‰²: è®­ç»ƒ{len(splits['train'])}, éªŒè¯{len(splits['val'])}, æµ‹è¯•{len(splits['test'])}")
        
        return splits
    
    def create_split_file(self, splits: Dict[str, List[int]], frame_infos: List[Dict]) -> str:
        """
        åˆ›å»ºåˆ†å‰²æ–‡ä»¶
        
        Args:
            splits: åˆ†å‰²å­—å…¸
            frame_infos: å¸§ä¿¡æ¯åˆ—è¡¨
            
        Returns:
            split_file_path: åˆ†å‰²æ–‡ä»¶è·¯å¾„
        """
        # åˆ›å»ºè¯¦ç»†çš„åˆ†å‰²ä¿¡æ¯
        split_data = {
            'dataset_info': {
                'scene_name': self.scene_name,
                'data_root': str(self.data_root),
                'total_frames': len(frame_infos),
                'creation_date': str(np.datetime64('today'))
            },
            'splits': splits,
            'statistics': {
                'train_samples': len(splits['train']),
                'val_samples': len(splits['val']),
                'test_samples': len(splits['test']),
                'ratios': {
                    'train': self.train_ratio,
                    'val': self.val_ratio,
                    'test': self.test_ratio
                }
            },
            'quality_thresholds': {
                'min_quality_score': self.min_quality_score,
                'max_hole_ratio': self.max_hole_ratio,
                'min_motion_diversity': self.min_motion_diversity
            }
        }
        
        # æ·»åŠ æ¯ä¸ªåˆ†å‰²çš„è´¨é‡ç»Ÿè®¡
        for split_name, indices in splits.items():
            split_frame_infos = [info for info in frame_infos if info['frame_idx'] in indices]
            
            if split_frame_infos:
                split_stats = { 
                    'avg_quality_score': float(np.mean([info['quality_score'] for info in split_frame_infos])),
                    'avg_hole_ratio': float(np.mean([info['hole_ratio'] for info in split_frame_infos])),
                    'avg_mv_magnitude': float(np.mean([info['mv_magnitude'] for info in split_frame_infos])),
                    'high_quality_count': sum(1 for info in split_frame_infos if info.get('high_quality', False))
                }
                split_data['statistics'][f'{split_name}_quality'] = split_stats
        
        # ä¿å­˜åˆ†å‰²æ–‡ä»¶
        split_file_path = self.data_root / f"{self.scene_name}_splits.json"
        
        with open(split_file_path, 'w', encoding='utf-8') as f:
            json.dump(split_data, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ’¾ åˆ†å‰²æ–‡ä»¶å·²ä¿å­˜: {split_file_path}")
        
        return str(split_file_path)
    
    def create_splits(self) -> str:
        """
        åˆ›å»ºå®Œæ•´çš„æ•°æ®é›†åˆ†å‰²
        
        Returns:
            split_file_path: åˆ†å‰²æ–‡ä»¶è·¯å¾„
        """
        print("="*60)
        print(f"ğŸ¯ ä¸ºåœºæ™¯ {self.scene_name} åˆ›å»ºæ•°æ®é›†åˆ†å‰²")
        print("="*60)
        
        # 1. æ‰«æå¯ç”¨å¸§
        frame_infos = self.scan_available_frames()
        
        if len(frame_infos) == 0:
            raise ValueError(f"No valid frames found in scene {self.scene_name}")
        
        # 2. åˆ›å»ºåˆ†å‰²
        splits = self.create_balanced_splits(frame_infos)
        
        # 3. ç”Ÿæˆåˆ†å‰²æ–‡ä»¶
        split_file_path = self.create_split_file(splits, frame_infos)
        
        print("="*60)
        print("ğŸ‰ æ•°æ®é›†åˆ†å‰²åˆ›å»ºå®Œæˆ!")
        print("="*60)
        
        return split_file_path


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='Create NoiseBase Dataset Splits')
    parser.add_argument('--data-root', type=str, required=True,
                       help='Preprocessed data root directory')
    parser.add_argument('--scene', type=str, default='bistro1',
                       help='Scene name (bistro1, kitchen)')
    parser.add_argument('--train-ratio', type=float, default=0.7,
                       help='Training set ratio')
    parser.add_argument('--val-ratio', type=float, default=0.2,
                       help='Validation set ratio')
    parser.add_argument('--test-ratio', type=float, default=0.1,
                       help='Test set ratio')
    
    args = parser.parse_args()
    
    # éªŒè¯æ¯”ä¾‹
    if abs(args.train_ratio + args.val_ratio + args.test_ratio - 1.0) > 1e-6:
        print("âŒ åˆ†å‰²æ¯”ä¾‹ä¹‹å’Œå¿…é¡»ç­‰äº1.0")
        return 1
    
    try:
        # åˆ›å»ºåˆ†å‰²å™¨
        splitter = DatasetSplitCreator(args.data_root, args.scene)
        splitter.train_ratio = args.train_ratio
        splitter.val_ratio = args.val_ratio
        splitter.test_ratio = args.test_ratio
        
        # åˆ›å»ºåˆ†å‰²
        split_file_path = splitter.create_splits()
        
        print(f"\nğŸ“– ä½¿ç”¨æ–¹æ³•:")
        print(f"python training/train_mobile_inpainting.py \\")
        print(f"  --data-root {args.data_root} \\")
        print(f"  --split-file {split_file_path}")
        
        return 0
        
    except Exception as e:
        print(f"âŒ åˆ†å‰²åˆ›å»ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    exit(main())