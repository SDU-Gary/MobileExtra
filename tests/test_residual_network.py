#!/usr/bin/env python3
"""
æ®‹å·®MVå¼•å¯¼ç½‘ç»œæµ‹è¯•è„šæœ¬
éªŒè¯æ®‹å·®å­¦ä¹ æ¶æ„çš„æ­£ç¡®æ€§å’Œæœ‰æ•ˆæ€§
"""

import torch
import torch.nn as nn
import yaml
import numpy as np
import sys
import time
from pathlib import Path
from typing import Dict, Tuple, List

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent
sys.path.append(str(project_root))
sys.path.append(str(project_root / "src"))
sys.path.append(str(project_root / "train"))

def load_test_modules():
    """åŠ è½½æµ‹è¯•æ‰€éœ€çš„æ¨¡å—"""
    try:
        from src.npu.networks.residual_mv_guided_network import create_residual_mv_guided_network, ResidualMVGuidedNetwork
        from train.residual_inpainting_loss import create_residual_inpainting_loss
        
        print("âœ… æ®‹å·®MVå¼•å¯¼ç½‘ç»œæ¨¡å—å¯¼å…¥æˆåŠŸ")
        return True
    except ImportError as e:
        print(f"âŒ æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
        return False

def create_realistic_test_data(batch_size: int = 1, height: int = 270, width: int = 480) -> Tuple[torch.Tensor, torch.Tensor]:
    """
    åˆ›å»ºæ¥è¿‘çœŸå®åœºæ™¯çš„æµ‹è¯•æ•°æ®
    æ¨¡æ‹Ÿwarpedå›¾åƒè¡¥æ´ä»»åŠ¡çš„è¾“å…¥ç‰¹ç‚¹
    """
    
    # åˆ›å»º7é€šé“è¾“å…¥æ•°æ®
    input_data = torch.zeros(batch_size, 7, height, width, dtype=torch.float32)
    
    # 1. warped RGB (é€šé“0-2) - æ¨¡æ‹Ÿæœ‰warpè¯¯å·®çš„RGBå›¾åƒ
    base_rgb = torch.rand(batch_size, 3, height, width) * 0.8 + 0.1
    
    # åœ¨æŸäº›åŒºåŸŸæ·»åŠ warpè¯¯å·®ï¼ˆäº®åº¦å˜åŒ–å’Œåç§»ï¼‰
    center_h, center_w = height // 2, width // 2
    warp_error_region = torch.zeros_like(base_rgb)
    
    # è®¡ç®—warpè¯¯å·®åŒºåŸŸçš„å®‰å…¨è¾¹ç•Œ
    warp_h_start = max(0, center_h-30)
    warp_h_end = min(height, center_h+30)
    warp_w_start = max(0, center_w-40)
    warp_w_end = min(width, center_w+40)
    
    if warp_h_end > warp_h_start and warp_w_end > warp_w_start:
        warp_error_region[:, :, warp_h_start:warp_h_end, warp_w_start:warp_w_end] = 0.3
    
    warped_rgb = base_rgb + warp_error_region
    input_data[:, 0:3, :, :] = warped_rgb
    
    # 2. holes mask (é€šé“3) - ç©ºæ´æ©ç 
    holes_mask = torch.zeros(batch_size, 1, height, width)
    # åœ¨å›¾åƒä¸­åˆ›å»ºä¸€äº›ä¸è§„åˆ™ç©ºæ´ - å®‰å…¨è¾¹ç•Œæ£€æŸ¥
    hole1_h_start, hole1_h_end = max(0, center_h-15), min(height, center_h+15)
    hole1_w_start, hole1_w_end = max(0, center_w-25), min(width, center_w+25)
    if hole1_h_end > hole1_h_start and hole1_w_end > hole1_w_start:
        holes_mask[:, :, hole1_h_start:hole1_h_end, hole1_w_start:hole1_w_end] = 1.0
    
    hole2_h_start, hole2_h_end = max(0, center_h+40), min(height, center_h+60)
    hole2_w_start, hole2_w_end = max(0, center_w-10), min(width, center_w+10)
    if hole2_h_end > hole2_h_start and hole2_w_end > hole2_w_start:
        holes_mask[:, :, hole2_h_start:hole2_h_end, hole2_w_start:hole2_w_end] = 1.0
    input_data[:, 3:4, :, :] = holes_mask
    
    # 3. occlusion mask (é€šé“4) - é®æŒ¡æ©ç 
    occlusion_mask = torch.zeros(batch_size, 1, height, width)
    # æ¨¡æ‹Ÿé®æŒ¡åŒºåŸŸ - å®‰å…¨è¾¹ç•Œæ£€æŸ¥
    occ_h_start, occ_h_end = max(0, center_h-50), min(height, center_h-20)
    occ_w_start, occ_w_end = max(0, center_w+20), min(width, center_w+50)
    if occ_h_end > occ_h_start and occ_w_end > occ_w_start:
        occlusion_mask[:, :, occ_h_start:occ_h_end, occ_w_start:occ_w_end] = 1.0
    input_data[:, 4:5, :, :] = occlusion_mask
    
    # 4. æ®‹å·®è¿åŠ¨å‘é‡ (é€šé“5-6) - æ¨¡æ‹Ÿwarpè¯¯å·®ä¿®æ­£å‘é‡
    residual_mv_x = torch.zeros(batch_size, 1, height, width)
    residual_mv_y = torch.zeros(batch_size, 1, height, width)
    
    # è®¡ç®—å®é™…çš„åŒºåŸŸå°ºå¯¸
    mv_region_h = min(60, height - max(0, center_h-30))  # ç¡®ä¿ä¸è¶…å‡ºè¾¹ç•Œ
    mv_region_w = min(80, width - max(0, center_w-40))   # ç¡®ä¿ä¸è¶…å‡ºè¾¹ç•Œ
    
    # è®¡ç®—å®é™…çš„åˆ‡ç‰‡èŒƒå›´
    mv_start_h = max(0, center_h-30)
    mv_end_h = mv_start_h + mv_region_h
    mv_start_w = max(0, center_w-40) 
    mv_end_w = mv_start_w + mv_region_w
    
    # åœ¨æœ‰warpè¯¯å·®çš„åŒºåŸŸæ·»åŠ æ®‹å·®MV
    if mv_region_h > 0 and mv_region_w > 0:
        residual_mv_x[:, :, mv_start_h:mv_end_h, mv_start_w:mv_end_w] = torch.randn(batch_size, 1, mv_region_h, mv_region_w) * 5.0
        residual_mv_y[:, :, mv_start_h:mv_end_h, mv_start_w:mv_end_w] = torch.randn(batch_size, 1, mv_region_h, mv_region_w) * 5.0
    
    input_data[:, 5:6, :, :] = residual_mv_x
    input_data[:, 6:7, :, :] = residual_mv_y
    
    # 5. åˆ›å»ºç›®æ ‡çœŸå®å›¾åƒï¼ˆæ¨¡æ‹Ÿå®Œç¾ä¿®å¤åçš„ç»“æœï¼‰
    target_data = base_rgb.clone()  # åŸºç¡€RGBä½œä¸ºç›®æ ‡
    
    # åœ¨ç©ºæ´å’Œé®æŒ¡åŒºåŸŸå¡«å……åˆç†çš„å†…å®¹ - ä½¿ç”¨å®‰å…¨çš„å°ºå¯¸
    # ç©ºæ´åŒºåŸŸ1
    if hole1_h_end > hole1_h_start and hole1_w_end > hole1_w_start:
        hole1_h, hole1_w = hole1_h_end - hole1_h_start, hole1_w_end - hole1_w_start
        target_data[:, :, hole1_h_start:hole1_h_end, hole1_w_start:hole1_w_end] = torch.rand(batch_size, 3, hole1_h, hole1_w) * 0.6 + 0.2
    
    # ç©ºæ´åŒºåŸŸ2
    if hole2_h_end > hole2_h_start and hole2_w_end > hole2_w_start:
        hole2_h, hole2_w = hole2_h_end - hole2_h_start, hole2_w_end - hole2_w_start
        target_data[:, :, hole2_h_start:hole2_h_end, hole2_w_start:hole2_w_end] = torch.rand(batch_size, 3, hole2_h, hole2_w) * 0.6 + 0.2
    
    # é®æŒ¡åŒºåŸŸ
    if occ_h_end > occ_h_start and occ_w_end > occ_w_start:
        occ_h, occ_w = occ_h_end - occ_h_start, occ_w_end - occ_w_start
        target_data[:, :, occ_h_start:occ_h_end, occ_w_start:occ_w_end] = torch.rand(batch_size, 3, occ_h, occ_w) * 0.6 + 0.2
    
    return input_data, target_data

def test_residual_mv_guided_network(device: torch.device) -> bool:
    """æµ‹è¯•æ®‹å·®MVå¼•å¯¼ç½‘ç»œçš„åŸºæœ¬åŠŸèƒ½"""
    
    print("\nğŸ§ª æµ‹è¯•æ®‹å·®MVå¼•å¯¼ç½‘ç»œåŸºæœ¬åŠŸèƒ½")
    print("-" * 50)
    
    try:
        from src.npu.networks.residual_mv_guided_network import create_residual_mv_guided_network
        
        # åˆ›å»ºæµ‹è¯•é…ç½®
        test_config = {
            'model': {
                'architecture': 'residual_mv_guided',
                'input_channels': 7,
                'output_channels': 3,
                'residual_mv_config': {
                    'encoder_channels': [32, 64, 128, 256, 512],
                    'mv_feature_channels': 32,
                    'use_gated_conv': True,
                    'attention_config': {
                        'use_gated_attention': True,
                        'mv_sensitivity': 0.05
                    },
                    'residual_learning': {
                        'enable_residual_composition': True,
                        'clamp_mv_range': [-100, 100],
                        'mv_normalization_factor': 100.0
                    }
                },
                'dropout_rate': 0.1
            }
        }
        
        # åˆ›å»ºç½‘ç»œ
        model = create_residual_mv_guided_network(test_config)
        model = model.to(device)
        model.eval()
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        input_data, target_data = create_realistic_test_data(batch_size=1, height=64, width=64)
        input_data = input_data.to(device)
        target_data = target_data.to(device)
        
        # åŸºæœ¬å‰å‘ä¼ æ’­æµ‹è¯•
        with torch.no_grad():
            start_time = time.time()
            output = model(input_data)
            forward_time = (time.time() - start_time) * 1000
        
        # ç½‘ç»œä¿¡æ¯
        param_count = model.get_parameter_count()
        memory_info = model.get_memory_usage(input_data.shape)
        
        print(f"âœ… ç½‘ç»œåˆ›å»ºå’Œå‰å‘ä¼ æ’­æˆåŠŸ")
        print(f"ğŸ“Š å‚æ•°æ•°é‡: {param_count:,}")
        print(f"ğŸ“Š è¾“å…¥å½¢çŠ¶: {input_data.shape}")
        print(f"ğŸ“Š è¾“å‡ºå½¢çŠ¶: {output.shape}")
        print(f"ğŸ“Š å‰å‘æ—¶é—´: {forward_time:.2f} ms")
        print(f"ğŸ“Š é¢„ä¼°å†…å­˜: {memory_info['total_estimated_mb']:.1f} MB")
        print(f"ğŸ“Š è¾“å‡ºèŒƒå›´: [{output.min():.3f}, {output.max():.3f}]")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ®‹å·®MVå¼•å¯¼ç½‘ç»œæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_residual_learning_functionality(device: torch.device) -> bool:
    """æµ‹è¯•æ®‹å·®å­¦ä¹ åŠŸèƒ½"""
    
    print("\nğŸ”¬ æµ‹è¯•æ®‹å·®å­¦ä¹ åŠŸèƒ½")
    print("-" * 50)
    
    try:
        from src.npu.networks.residual_mv_guided_network import create_residual_mv_guided_network
        
        # åˆ›å»ºé…ç½®
        test_config = {
            'model': {
                'residual_mv_config': {
                    'encoder_channels': [32, 64, 128, 256],
                    'mv_feature_channels': 32,
                    'use_gated_conv': True
                }
            }
        }
        
        model = create_residual_mv_guided_network(test_config)
        model = model.to(device)
        model.eval()
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        input_data, target_data = create_realistic_test_data(batch_size=1, height=64, width=64)
        input_data = input_data.to(device)
        target_data = target_data.to(device)
        
        # æå–warped_rgb
        warped_rgb = input_data[:, 0:3, :, :]
        
        # å‰å‘ä¼ æ’­
        with torch.no_grad():
            output = model(input_data)
            
            # éªŒè¯æ®‹å·®å­¦ä¹ ï¼šoutputåº”è¯¥ = warped_rgb + correction
            predicted_residual = output - warped_rgb
            target_residual = target_data - warped_rgb
            
            # è·å–ä¸­é—´è¾“å‡º
            if hasattr(model, 'get_intermediate_outputs'):
                intermediate = model.get_intermediate_outputs(input_data)
                
                print("ğŸ“Š ä¸­é—´è¾“å‡ºåˆ†æ:")
                for key, tensor in intermediate.items():
                    print(f"   {key}: {tensor.shape}, èŒƒå›´=[{tensor.min():.3f}, {tensor.max():.3f}]")
                
                # éªŒè¯æ®‹å·®ç»„åˆ
                if 'correction_residual' in intermediate:
                    correction = intermediate['correction_residual']
                    composed_output = warped_rgb + correction
                    
                    composition_error = torch.abs(output - composed_output).mean()
                    print(f"ğŸ“Š æ®‹å·®ç»„åˆéªŒè¯è¯¯å·®: {composition_error:.6f}")
                    
                    if composition_error < 1e-5:
                        print("âœ… æ®‹å·®ç»„åˆéªŒè¯é€šè¿‡")
                    else:
                        print("âš ï¸  æ®‹å·®ç»„åˆéªŒè¯å¤±è´¥")
        
        # æ®‹å·®ç»Ÿè®¡åˆ†æ
        residual_mse = torch.mean((predicted_residual - target_residual)**2)
        residual_magnitude = torch.mean(torch.abs(predicted_residual))
        
        print(f"ğŸ“Š æ®‹å·®å­¦ä¹ åˆ†æ:")
        print(f"   é¢„æµ‹æ®‹å·®å¹…åº¦: {residual_magnitude:.6f}")
        print(f"   æ®‹å·®MSEæŸå¤±: {residual_mse:.6f}")
        print(f"   è¾“å‡ºå˜åŒ–ç¨‹åº¦: {torch.mean(torch.abs(output - warped_rgb)):.6f}")
        
        print("âœ… æ®‹å·®å­¦ä¹ åŠŸèƒ½éªŒè¯å®Œæˆ")
        return True
        
    except Exception as e:
        print(f"âŒ æ®‹å·®å­¦ä¹ åŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_residual_inpainting_loss(device: torch.device) -> bool:
    """æµ‹è¯•æ®‹å·®è¡¥æ´æŸå¤±å‡½æ•°"""
    
    print("\nğŸ¯ æµ‹è¯•æ®‹å·®è¡¥æ´æŸå¤±å‡½æ•°")
    print("-" * 50)
    
    try:
        from train.residual_inpainting_loss import create_residual_inpainting_loss
        
        # åˆ›å»ºæµ‹è¯•é…ç½®
        test_config = {
            'loss': {
                'residual_mse_weight': 1.2,
                'residual_l1_weight': 0.6,
                'spatial_weighted_weight': 1.0,
                'preservation_weight': 0.5,
                'edge_preservation_weight': 0.3,
                'perceptual_weight': 0.15
            }
        }
        
        # åˆ›å»ºæŸå¤±å‡½æ•°
        loss_fn = create_residual_inpainting_loss(test_config, device)
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        input_data, target_data = create_realistic_test_data(batch_size=1, height=64, width=64)
        input_data = input_data.to(device)
        target_data = target_data.to(device)
        
        # æ¨¡æ‹Ÿç½‘ç»œè¾“å‡ºï¼ˆåœ¨warped_rgbåŸºç¡€ä¸Šæ·»åŠ ä¸€äº›ä¿®æ­£ï¼‰
        warped_rgb = input_data[:, 0:3, :, :]
        correction = torch.randn_like(warped_rgb) * 0.1
        predicted_output = warped_rgb + correction
        
        # è®¡ç®—æŸå¤±
        total_loss, loss_dict = loss_fn(predicted_output, target_data, input_data)
        
        print(f"âœ… æ®‹å·®è¡¥æ´æŸå¤±å‡½æ•°æµ‹è¯•æˆåŠŸ")
        print(f"ğŸ“Š æ€»æŸå¤±: {total_loss.item():.6f}")
        print(f"ğŸ“Š æŸå¤±åˆ†è§£:")
        for key, value in loss_dict.items():
            print(f"   {key}: {value:.6f}")
        
        # éªŒè¯æŸå¤±æƒé‡
        weights = loss_fn.get_loss_weights()
        print(f"ğŸ“Š æŸå¤±æƒé‡:")
        for key, value in weights.items():
            print(f"   {key}: {value}")
        
        print("âœ… æ®‹å·®è¡¥æ´æŸå¤±å‡½æ•°éªŒè¯å®Œæˆ")
        return True
        
    except Exception as e:
        print(f"âŒ æ®‹å·®è¡¥æ´æŸå¤±å‡½æ•°æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_spatial_attention_mechanism(device: torch.device) -> bool:
    """æµ‹è¯•ç©ºé—´æ³¨æ„åŠ›æœºåˆ¶"""
    
    print("\nğŸ¯ æµ‹è¯•ç©ºé—´æ³¨æ„åŠ›æœºåˆ¶")
    print("-" * 50)
    
    try:
        from src.npu.networks.residual_mv_guided_network import SpatialAttentionGenerator
        
        # åˆ›å»ºç©ºé—´æ³¨æ„åŠ›ç”Ÿæˆå™¨
        attention_gen = SpatialAttentionGenerator(use_gated_conv=True)
        attention_gen = attention_gen.to(device)
        attention_gen.eval()
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        batch_size, height, width = 1, 64, 64
        holes_mask = torch.zeros(batch_size, 1, height, width, device=device)
        occlusion_mask = torch.zeros(batch_size, 1, height, width, device=device)
        residual_mv = torch.randn(batch_size, 2, height, width, device=device) * 10.0
        
        # æ·»åŠ ä¸€äº›ç©ºæ´å’Œé®æŒ¡
        holes_mask[:, :, 20:40, 20:40] = 1.0
        occlusion_mask[:, :, 10:30, 40:60] = 1.0
        
        # ç”Ÿæˆç©ºé—´æ³¨æ„åŠ›
        with torch.no_grad():
            spatial_attention, mv_urgency = attention_gen(holes_mask, occlusion_mask, residual_mv)
        
        print(f"ğŸ“Š ç©ºé—´æ³¨æ„åŠ›åˆ†æ:")
        print(f"   æ³¨æ„åŠ›å½¢çŠ¶: {spatial_attention.shape}")
        print(f"   æ³¨æ„åŠ›èŒƒå›´: [{spatial_attention.min():.3f}, {spatial_attention.max():.3f}]")
        print(f"   MVç´§æ€¥ç¨‹åº¦å½¢çŠ¶: {mv_urgency.shape}")
        print(f"   MVç´§æ€¥ç¨‹åº¦èŒƒå›´: [{mv_urgency.min():.3f}, {mv_urgency.max():.3f}]")
        
        # éªŒè¯æ³¨æ„åŠ›åœ¨æ©ç åŒºåŸŸæ˜¯å¦æ›´é«˜
        holes_bool = holes_mask.bool().squeeze()
        occlusion_bool = occlusion_mask.bool().squeeze()
        combined_mask = holes_bool | occlusion_bool  # ç»„åˆæ‰€æœ‰éœ€è¦ä¿®å¤çš„åŒºåŸŸ
        
        if combined_mask.any():  # ç¡®ä¿æœ‰æ©ç åŒºåŸŸ
            mask_attention = spatial_attention.squeeze()[combined_mask].mean()
            non_mask_attention = spatial_attention.squeeze()[~combined_mask].mean()
            
            print(f"   æ©ç åŒºåŸŸæ³¨æ„åŠ›: {mask_attention:.3f}")
            print(f"   éæ©ç åŒºåŸŸæ³¨æ„åŠ›: {non_mask_attention:.3f}")
            print(f"   æ³¨æ„åŠ›å·®å¼‚: {(mask_attention - non_mask_attention):.3f}")
            
            # æ‰“å°ä¸€äº›ç»Ÿè®¡ä¿¡æ¯å¸®åŠ©è°ƒè¯•
            print(f"   æ©ç åŒºåŸŸåƒç´ æ•°: {combined_mask.sum().item()}")
            print(f"   éæ©ç åŒºåŸŸåƒç´ æ•°: {(~combined_mask).sum().item()}")
            print(f"   MVå¹³å‡å¼ºåº¦: {mv_urgency.mean():.3f}")
            
            if mask_attention > non_mask_attention + 0.01:  # å¢åŠ ä¸€ä¸ªå°çš„é˜ˆå€¼
                print("âœ… ç©ºé—´æ³¨æ„åŠ›æœºåˆ¶å·¥ä½œæ­£å¸¸")
            else:
                print("âš ï¸  ç©ºé—´æ³¨æ„åŠ›æœºåˆ¶å¯èƒ½éœ€è¦è°ƒæ•´")
                # æä¾›è°ƒè¯•ä¿¡æ¯
                print("ğŸ’¡ è°ƒè¯•å»ºè®®:")
                print("   - æ£€æŸ¥MVçµæ•åº¦å‚æ•° (mv_sensitivity)")
                print("   - éªŒè¯é—¨æ§å·ç§¯çš„æƒé‡åˆå§‹åŒ–")
                print("   - è€ƒè™‘å¢åŠ è®­ç»ƒè¿­ä»£ä»¥å­¦ä¹ æ›´å¥½çš„æ³¨æ„åŠ›æ¨¡å¼")
        else:
            print("âš ï¸  æµ‹è¯•æ•°æ®ä¸­æ²¡æœ‰æ©ç åŒºåŸŸï¼Œæ— æ³•éªŒè¯ç©ºé—´æ³¨æ„åŠ›")
        
        return True
        
    except Exception as e:
        print(f"âŒ ç©ºé—´æ³¨æ„åŠ›æœºåˆ¶æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_gated_convolution(device: torch.device) -> bool:
    """æµ‹è¯•é—¨æ§å·ç§¯åŠŸèƒ½"""
    
    print("\nğŸšª æµ‹è¯•é—¨æ§å·ç§¯åŠŸèƒ½")
    print("-" * 50)
    
    try:
        from src.npu.networks.residual_mv_guided_network import GatedConv2d
        
        # åˆ›å»ºé—¨æ§å·ç§¯å±‚
        gated_conv = GatedConv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)
        gated_conv = gated_conv.to(device)
        gated_conv.eval()
        
        # åˆ›å»ºæµ‹è¯•è¾“å…¥
        test_input = torch.randn(1, 3, 32, 32, device=device)
        
        # å‰å‘ä¼ æ’­
        with torch.no_grad():
            output = gated_conv(test_input)
        
        print(f"ğŸ“Š é—¨æ§å·ç§¯æµ‹è¯•:")
        print(f"   è¾“å…¥å½¢çŠ¶: {test_input.shape}")
        print(f"   è¾“å‡ºå½¢çŠ¶: {output.shape}")
        print(f"   è¾“å‡ºèŒƒå›´: [{output.min():.3f}, {output.max():.3f}]")
        
        # éªŒè¯è¾“å‡ºä¸æ˜¯ç®€å•çš„å·ç§¯ç»“æœ
        # é—¨æ§æœºåˆ¶åº”è¯¥äº§ç”Ÿä¸æ™®é€šå·ç§¯ä¸åŒçš„è¾“å‡º
        normal_conv = nn.Conv2d(3, 16, 3, padding=1).to(device)
        with torch.no_grad():
            normal_output = normal_conv(test_input)
        
        difference = torch.mean(torch.abs(output - normal_output))
        print(f"   ä¸æ™®é€šå·ç§¯å·®å¼‚: {difference:.3f}")
        
        if difference > 0.1:
            print("âœ… é—¨æ§å·ç§¯åŠŸèƒ½æ­£å¸¸")
        else:
            print("âš ï¸  é—¨æ§å·ç§¯å¯èƒ½é€€åŒ–ä¸ºæ™®é€šå·ç§¯")
        
        return True
        
    except Exception as e:
        print(f"âŒ é—¨æ§å·ç§¯æµ‹è¯•å¤±è´¥: {e}")
        return False

def comprehensive_architecture_test() -> bool:
    """ç»¼åˆæ¶æ„æµ‹è¯•"""
    
    print("ğŸ”§ æ®‹å·®MVå¼•å¯¼ç½‘ç»œç»¼åˆæµ‹è¯•")
    print("=" * 60)
    
    # è®¾å¤‡è®¾ç½®
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ–¥ï¸  ä½¿ç”¨è®¾å¤‡: {device}")
    
    # æ£€æŸ¥æ¨¡å—å¯¼å…¥
    if not load_test_modules():
        return False
    
    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    tests = [
        test_residual_mv_guided_network,
        test_residual_learning_functionality,
        test_residual_inpainting_loss,
        test_spatial_attention_mechanism,
        test_gated_convolution
    ]
    
    results = []
    for test_func in tests:
        try:
            result = test_func(device)
            results.append(result)
        except Exception as e:
            print(f"âŒ æµ‹è¯• {test_func.__name__} å¤±è´¥: {e}")
            results.append(False)
    
    # æ€»ç»“
    print("\n" + "=" * 60)
    print("ğŸ¯ æµ‹è¯•æ€»ç»“:")
    print(f"ğŸ“Š æ€»æµ‹è¯•æ•°: {len(results)}")
    print(f"âœ… æˆåŠŸ: {sum(results)}")
    print(f"âŒ å¤±è´¥: {len(results) - sum(results)}")
    
    if all(results):
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ®‹å·®MVå¼•å¯¼ç½‘ç»œå‡†å¤‡å°±ç»ª")
        print("\nğŸ’¡ å…³é”®éªŒè¯å®Œæˆ:")
        print("   âœ… ç½‘ç»œæ¶æ„æ­£ç¡®å®ç°")
        print("   âœ… æ®‹å·®å­¦ä¹ æœºåˆ¶æ­£å¸¸")
        print("   âœ… æŸå¤±å‡½æ•°åŠŸèƒ½å®Œæ•´")
        print("   âœ… ç©ºé—´æ³¨æ„åŠ›æœ‰æ•ˆ")
        print("   âœ… é—¨æ§å·ç§¯å·¥ä½œæ­£å¸¸")
        
        print("\nğŸš€ å¯åŠ¨æ®‹å·®MVå¼•å¯¼ç½‘ç»œè®­ç»ƒ:")
        print("   python train/ultra_safe_train.py --config configs/residual_mv_guided_config.yaml")
        
    else:
        print("\nâš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç›¸å…³é—®é¢˜")
        failed_tests = [i for i, result in enumerate(results) if not result]
        print(f"å¤±è´¥çš„æµ‹è¯•ç´¢å¼•: {failed_tests}")
    
    return all(results)

if __name__ == "__main__":
    comprehensive_architecture_test()